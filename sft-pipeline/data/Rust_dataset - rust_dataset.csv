crate_name,input_data,output_data,task_category
async-stream-impl,"{""title"": ""Stream lines from an async file with error handling"", ""description"": ""A developer wants to read a text file asynchronously and process each line as it becomes available. The stream should yield each line as a `String` and propagate any I/O errors using the `Result` type."", ""code_context"": ""use async_stream::try_stream;\nuse futures_util::stream::StreamExt;\nuse tokio::fs::File;\nuse tokio::io::{self, AsyncBufReadExt, BufReader};""}","{""code"": ""fn file_lines(path: &str) -> impl Stream<Item = Result<String, std::io::Error>> {\n    try_stream! {\n        let file = tokio::fs::File::open(path).await?;\n        let reader = tokio::io::BufReader::new(file);\n        let mut lines = reader.lines();\n        while let Some(line) = lines.next_line().await? {\n            yield line;\n        }\n    }\n}""}",code_generation
async-stream-impl,"{""title"": ""Try stream for fetching multiple URLs"", ""description"": ""A developer needs to download the contents of several HTTP URLs concurrently. The stream should perform an async GET request for each URL and yield the response body as `bytes::Bytes`, propagating any request errors as `Result` items."", ""code_context"": ""use async_stream::try_stream;\nuse futures_util::stream::StreamExt;\nuse reqwest;\nuse bytes;""}","{""code"": ""fn fetch_urls(urls: Vec<String>) -> impl Stream<Item = Result<bytes::Bytes, reqwest::Error>> {\n    try_stream! {\n        for url in urls {\n            let resp = reqwest::get(&url).await?;\n            let bytes = resp.bytes().await?;\n            yield bytes;\n        }\n    }\n}""}",code_generation
async-stream-impl,"{""title"": ""Asynchronous factorial computation over a stream of numbers"", ""description"": ""A developer has a stream of `u64` values and wants to compute the factorial of each number asynchronously, yielding the results as they become ready."", ""code_context"": ""use async_stream::stream;\nuse futures_util::stream::StreamExt;\nuse futures_core::stream::Stream;""}","{""code"": ""fn factorial_stream<S>(input: S) -> impl Stream<Item = u64>\nwhere\n    S: Stream<Item = u64> + Unpin,\n{\n    stream! {\n        for await n in input {\n            let result = async move {\n                (1..=n).product()\n            }.await;\n            yield result;\n        }\n    }\n}""}",code_generation
async-stream-impl,"{""title"": ""Merge two streams by interleaving their items"", ""description"": ""A developer wants to combine two streams of `i32` values into a single stream that yields all items from the first stream, then all items from the second, and repeats this pattern indefinitely."", ""code_context"": ""use async_stream::stream;\nuse futures_util::stream::StreamExt;\nuse futures_core::stream::Stream;""}","{""code"": ""fn merge_streams<S1, S2>(s1: S1, s2: S2) -> impl Stream<Item = i32>\nwhere\n    S1: Stream<Item = i32> + Unpin,\n    S2: Stream<Item = i32> + Unpin,\n{\n    stream! {\n        loop {\n            for await v in s1 {\n                yield v;\n            }\n            for await v in s2 {\n                yield v;\n            }\n        }\n    }\n}""}",code_generation
lz4,"{""code_before"": ""pub fn check_error(code: LZ4FErrorCode) -> Result<usize, Error> {\n    unsafe {\n        if LZ4F_isError(code) != 0 {\n            let error_name = LZ4F_getErrorName(code);\n            return Err(Error::new(\n                ErrorKind::Other,\n                LZ4Error(\n                    str::from_utf8(CStr::from_ptr(error_name).to_bytes())\n                        .unwrap()\n                        .to_string(),\n                ),\n            ));\n        }\n        Ok(code as usize)\n    }\n}"", ""code_context"": ""use std::io::{Error, ErrorKind, Result};\nuse std::ffi::CStr;\nuse std::str;\nuse lz4_sys::*;\n\n#[derive(Debug)]\nstruct LZ4Error(String);\n""}","{""rationale"": ""Replaces the call to LZ4F_isError with a direct zero check on the error code. This removes a function call overhead, reducing CPU cycles per error check while preserving semantics because LZ4 error codes are non‑zero only on failure."", ""code_after"": ""pub fn check_error(code: LZ4FErrorCode) -> Result<usize, Error> {\n    unsafe {\n        if code != 0 {\n            let error_name = LZ4F_getErrorName(code);\n            return Err(Error::new(\n                ErrorKind::Other,\n                LZ4Error(\n                    str::from_utf8(CStr::from_ptr(error_name).to_bytes())\n                        .unwrap()\n                        .to_string(),\n                ),\n            ));\n        }\n        Ok(code as usize)\n    }\n}""}",code_optimization
lz4,"{""code_before"": ""let mut compressed: Vec<u8> = vec![0; (if prepend_size { compress_bound + 4 } else { compress_bound }) as usize];\n        let dec_size = compress_to_buffer(src, mode, prepend_size, &mut compressed)?;\n        compressed.truncate(dec_size as usize);\n        Ok(compressed)"", ""code_context"": ""use std::io::{Error, ErrorKind, Result};\nuse lz4_sys::*;\n\nenum CompressionMode {\n    HIGHCOMPRESSION(i32),\n    FAST(i32),\n    DEFAULT,\n}\n\nfn compress_to_buffer(src: &[u8], mode: Option<CompressionMode>, prepend_size: bool, buffer: &mut Vec<u8>) -> Result<usize> {\n    // placeholder implementation\n    Ok(0)\n}\n""}","{""rationale"": ""Allocates the buffer with the exact capacity needed and sets its length after compression, eliminating the intermediate zero‑filled allocation and the costly truncate operation. This reduces heap fragmentation and improves memory locality."", ""code_after"": ""let mut compressed = Vec::with_capacity(if prepend_size { compress_bound + 4 } else { compress_bound } as usize);\n        let dec_size = compress_to_buffer(src, mode, prepend_size, &mut compressed)?;\n        unsafe { compressed.set_len(dec_size as usize) };\n        Ok(compressed)""}",code_optimization
lz4,"{""code_before"": ""let mut buffer = vec![0u8; size];\n        let sz = decompress_to_buffer(src, uncompressed_size, &mut buffer)?;\n        buffer.truncate(sz);\n        Ok(buffer)"", ""code_context"": ""use std::io::{Error, ErrorKind, Result};\nuse lz4_sys::*;\n\nfn decompress_to_buffer(src: &[u8], uncompressed_size: Option<i32>, buffer: &mut Vec<u8>) -> Result<usize> {\n    // placeholder implementation\n    Ok(0)\n}\n""}","{""rationale"": ""Uses Vec::with_capacity and unsafe set_len to avoid initializing the buffer with zeros and the subsequent truncate. This cuts the number of memory writes and reduces allocation overhead, leading to faster decompression."", ""code_after"": ""let mut buffer = Vec::with_capacity(size);\n        let sz = decompress_to_buffer(src, uncompressed_size, &mut buffer)?;\n        unsafe { buffer.set_len(sz) };\n        Ok(buffer)""}",code_optimization
async-stream-impl,"{""code_context"": ""struct Data(String);"", ""code_to_test"": ""impl Data {\n    fn stream(&self) -> impl Stream<Item = &str> + '_ {\n        stream! {\n            yield &self.0[..];\n        }\n    }\n}"", ""test_context"": ""use async_stream::stream;\nuse futures_core::stream::Stream;\nuse futures_util::pin_mut;\nuse futures_util::stream::StreamExt;""}","{""test_cases"": [""#[tokio::test]\nasync fn borrow_self() {\n    let data = Data(\""hello\"".to_string());\n    let s = data.stream();\n    pin_mut!(s);\n    assert_eq!(Some(\""hello\""), s.next().await);\n}""]}",test_generation
async-stream-impl,"{""code_context"": ""use crate::yielder::Receiver;\nuse futures_core::{FusedStream, Stream};\nuse pin_project_lite::pin_project;\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\n\npin_project! {\n    #[doc(hidden)]\n    #[derive(Debug)]\n    pub struct AsyncStream<T, U> {\n        rx: Receiver<T>,\n        done: bool,\n        #[pin]\n        generator: U,\n    }\n}"", ""code_to_test"": ""impl<T, U> Stream for AsyncStream<T, U>\nwhere\n    U: Future<Output = ()>,\n{\n    type Item = T;\n\n    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {\n        let me = self.project();\n\n        if *me.done {\n            return Poll::Ready(None);\n        }\n\n        let mut dst = None;\n        let res = {\n            let _enter = me.rx.enter(&mut dst);\n            me.generator.poll(cx)\n        };\n\n        *me.done = res.is_ready();\n\n        if dst.is_some() {\n            return Poll::Ready(dst.take());\n        }\n\n        if *me.done {\n            Poll::Ready(None)\n        } else {\n            Poll::Pending\n        }\n    }\n}"", ""test_context"": ""use async_stream::stream;\nuse futures_util::stream::StreamExt;""}","{""test_cases"": [""#[tokio::test]\nasync fn yield_single_value() {\n    let s = stream! {\n        yield \""hello\"";\n    };\n\n    let values: Vec<_> = s.collect().await;\n\n    assert_eq!(1, values.len());\n    assert_eq!(\""hello\"", values[0]);\n}"", ""#[tokio::test]\nasync fn yield_multi_value() {\n    let s = stream! {\n        yield \""hello\"";\n        yield \""world\"";\n        yield \""dizzy\"";\n    };\n\n    let values: Vec<_> = s.collect().await;\n\n    assert_eq!(3, values.len());\n    assert_eq!(\""hello\"", values[0]);\n    assert_eq!(\""world\"", values[1]);\n    assert_eq!(\""dizzy\"", values[2]);\n}""]}",test_generation
async-stream-impl,"{""code_context"": ""use crate::yielder::Receiver;\nuse futures_core::{FusedStream, Stream};\nuse pin_project_lite::pin_project;\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\n\npin_project! {\n    #[doc(hidden)]\n    #[derive(Debug)]\n    pub struct AsyncStream<T, U> {\n        rx: Receiver<T>,\n        done: bool,\n        #[pin]\n        generator: U,\n    }\n}"", ""code_to_test"": ""impl<T, U> Stream for AsyncStream<T, U>\nwhere\n    U: Future<Output = ()>,\n{\n    type Item = T;\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        if self.done {\n            (0, Some(0))\n        } else {\n            (0, None)\n        }\n    }\n}"", ""test_context"": ""use async_stream::stream;\nuse futures_util::stream::StreamExt;""}","{""test_cases"": [""#[tokio::test]\nasync fn test_size_hint() {\n    let s = stream! {\n        yield 1;\n        yield 2;\n    };\n    let (lower, upper) = s.size_hint();\n    assert_eq!(0, lower);\n    assert_eq!(None, upper);\n}""]}",test_generation
wyz,"{""buggy_code"": ""impl<I> Bidi<I>\nwhere I: DoubleEndedIterator\n{\n    #[inline]\n    fn last(mut self) -> Option<Self::Item> {\n        self.next_back()\n    }\n}"", ""code_context"": ""pub struct Bidi<I>\nwhere I: DoubleEndedIterator\n{\n    inner: I,\n    next: fn(&mut I) -> Option<<I as Iterator>::Item>,\n    next_back: fn(&mut I) -> Option<<I as Iterator>::Item>,\n    nth: fn(&mut I, usize) -> Option<<I as Iterator>::Item>,\n    nth_back: fn(&mut I, usize) -> Option<<I as Iterator>::Item>,\n}\n\nimpl<I> Bidi<I>\nwhere I: DoubleEndedIterator\n{\n    pub fn new<II>(iter: II, cond: bool) -> Self\n    where II: IntoIterator<IntoIter = I> {\n        let inner = iter.into_iter();\n        if cond {\n            Self {\n                inner,\n                next: <I as DoubleEndedIterator>::next_back,\n                next_back: <I as Iterator>::next,\n                nth: <I as DoubleEndedIterator>::nth_back,\n                nth_back: <I as Iterator>::nth,\n            }\n        } else {\n            Self {\n                inner,\n                next: <I as Iterator>::next,\n                next_back: <I as DoubleEndedIterator>::next_back,\n                nth: <I as Iterator>::nth,\n                nth_back: <I as DoubleEndedIterator>::nth_back,\n            }\n        }\n    }\n}""}","{""fixed_code"": ""impl<I> Bidi<I>\nwhere I: DoubleEndedIterator\n{\n    #[inline]\n    fn last(mut self) -> Option<Self::Item> {\n        // Return None if the iterator is empty to avoid calling next_back on an empty iterator.\n        if self.inner.size_hint().0 == 0 {\n            return None;\n        }\n        self.next_back()\n    }\n}"", ""bug_description"": ""The `last` method calls `next_back()` without checking whether the underlying iterator is empty. When the iterator has no elements, `next_back()` may panic or exhibit undefined behavior. The fix adds an explicit emptiness check using `size_hint()` and returns `None` for an empty iterator before delegating to `next_back()`.""}",bug_detection
wyz,"{""buggy_code"": ""fn normalize(\n    self,\n    start: impl Into<Option<usize>>,\n    end: impl Into<Option<usize>>,\n) -> Range<usize> {\n    let start = match self.start_bound() {\n        Bound::Unbounded => start.into().unwrap_or(0),\n        Bound::Included(&v) => v,\n        Bound::Excluded(&v) => v.saturating_add(1),\n    };\n    let end = match self.end_bound() {\n        Bound::Unbounded => end.into().unwrap_or(!0),\n        Bound::Included(&v) => v.saturating_add(1),\n        Bound::Excluded(&v) => v,\n    };\n    if start > end {\n        end .. start\n    } else {\n        start .. end\n    }\n}"", ""code_context"": ""use core::ops::{Bound, Range, RangeBounds};\n\npub trait RangeExt<T>: RangeBounds<T>\nwhere\n    T: Ord,\n{\n    fn normalize(\n        self,\n        start: impl Into<Option<T>>,\n        end: impl Into<Option<T>>,\n    ) -> Range<T>;\n}\n\nimpl<R> RangeExt<usize> for R\nwhere\n    R: RangeBounds<usize>,\n{\n    fn normalize(\n        self,\n        start: impl Into<Option<usize>>,\n        end: impl Into<Option<usize>>,\n    ) -> Range<usize> {\n        // The real implementation is provided in the buggy/fixed snippets.\n        unimplemented!()\n    }\n}""}","{""fixed_code"": ""fn normalize(\n    self,\n    start: impl Into<Option<usize>>,\n    end: impl Into<Option<usize>>,\n) -> Range<usize> {\n    let start = match self.start_bound() {\n        Bound::Unbounded => start.into().unwrap_or(0),\n        Bound::Included(&v) => v,\n        Bound::Excluded(&v) => v.saturating_add(1),\n    };\n    let end = match self.end_bound() {\n        Bound::Unbounded => end.into().unwrap_or(!0),\n        Bound::Included(&v) => v.saturating_add(1),\n        Bound::Excluded(&v) => v,\n    };\n    if start > end {\n        // Return an empty range when the computed start exceeds the end.\n        start..start\n    } else {\n        start..end\n    }\n}"", ""bug_description"": ""When `start` is greater than `end`, the original implementation returns a reversed range (`end..start`). In Rust a reversed range is empty, but constructing it this way is confusing and can lead to incorrect logic elsewhere. The fix returns an explicit empty range where `start == end`, making the intent clear and avoiding accidental misuse of a reversed range.""}",bug_detection
wyz,"{""buggy_code"": ""fn intersection<R2>(self, other: R2) -> Option<Range<usize>>\nwhere\n    R2: RangeExt<usize>,\n{\n    let Range { start: a1, end: a2 } = self.normalize(None, None);\n    let Range { start: b1, end: b2 } = other.normalize(None, None);\n    if b1 < a1 {\n        return (b1 .. b2).intersection(a1 .. a2);\n    }\n    if !(a1 .. a2).contains(&b1) {\n        return None;\n    }\n    let start = a1.max(b1);\n    let end = a2.min(b2);\n    if start > end {\n        Some(end .. start)\n    } else {\n        Some(start .. end)\n    }\n}"", ""code_context"": ""use core::ops::{Bound, Range, RangeBounds};\n\npub trait RangeExt<T>: RangeBounds<T>\nwhere\n    T: Ord,\n{\n    fn normalize(\n        self,\n        start: impl Into<Option<T>>,\n        end: impl Into<Option<T>>,\n    ) -> Range<T>;\n\n    fn intersection<R>(self, other: R) -> Option<Range<T>>\n    where\n        R: RangeExt<T>;\n}\n\nimpl<R> RangeExt<usize> for R\nwhere\n    R: RangeBounds<usize>,\n{\n    fn normalize(\n        self,\n        start: impl Into<Option<usize>>,\n        end: impl Into<Option<usize>>,\n    ) -> Range<usize> {\n        unimplemented!()\n    }\n\n    fn intersection<R2>(self, other: R2) -> Option<Range<usize>>\n    where\n        R2: RangeExt<usize>,\n    {\n        // The real implementation is provided in the buggy/fixed snippets.\n        unimplemented!()\n    }\n}""}","{""fixed_code"": ""fn intersection<R2>(self, other: R2) -> Option<Range<usize>>\nwhere\n    R2: RangeExt<usize>,\n{\n    let Range { start: a1, end: a2 } = self.normalize(None, None);\n    let Range { start: b1, end: b2 } = other.normalize(None, None);\n    if b1 < a1 {\n        // Reorder arguments so that the first range starts no later than the second.\n        return other.intersection(self);\n    }\n    if !(a1 .. a2).contains(&b1) {\n        return None;\n    }\n    let start = a1.max(b1);\n    let end = a2.min(b2);\n    if start >= end {\n        // No overlap.\n        None\n    } else {\n        Some(start .. end)\n    }\n}"", ""bug_description"": ""The original `intersection` method recursed with a newly constructed range `(b1..b2).intersection(a1..a2)`, which does not call the trait implementation and can cause infinite recursion or incorrect ordering. It also returned a reversed range for empty intersections. The fix reorders the arguments by delegating to `other.intersection(self)` when `b1 < a1` and returns `None` when the computed start is not less than the end, correctly handling empty intersections.""}",bug_detection
jsonrpsee-types,"{""code_context"": ""use serde::de::Deserializer;\nuse serde::ser::Serializer;\nuse serde::{Deserialize, Serialize};\nuse serde_json::value::RawValue;\nuse std::borrow::Cow as StdCow;\nuse thiserror::Error;\n\n#[derive(Debug, Deserialize, Serialize, Clone, Error)]\npub struct ErrorObject<'a> {\n    code: ErrorCode,\n    message: StdCow<'a, str>,\n    #[serde(skip_serializing_if = \""Option::is_none\"")]\n    data: Option<StdCow<'a, RawValue>>,\n}\n\nimpl<'a> ErrorObject<'a> {\n    pub fn owned<S: Serialize>(code: i32, message: impl Into<String>, data: Option<S>) -> ErrorObject<'static> {\n        let data = data.and_then(|d| serde_json::value::to_raw_value(&d).ok());\n        ErrorObject { code: code.into(), message: message.into().into(), data: data.map(StdCow::Owned) }\n    }\n}\n\nenum ErrorCode {\n    ParseError,\n    // other variants omitted for brevity\n}\n\nimpl From<ErrorCode> for i32 {\n    fn from(code: ErrorCode) -> i32 { 0 }\n}\n\nimpl ErrorCode {\n    fn into(self) -> ErrorObject<'static> { ErrorObject::owned(0, \""\"", None) }\n}"", ""code_to_test"": ""pub fn owned<S: Serialize>(code: i32, message: impl Into<String>, data: Option<S>) -> ErrorObject<'static> {\n    let data = data.and_then(|d| serde_json::value::to_raw_value(&d).ok());\n    ErrorObject { code: code.into(), message: message.into().into(), data: data.map(StdCow::Owned) }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn deserialize_works() {\n    let ser = r#\""{\""code\"":-32700,\""message\"":\""Parse error\""}\""#;\n    let exp: ErrorObject = ErrorCode::ParseError.into();\n    let err: ErrorObject = serde_json::from_str(ser).unwrap();\n    assert_eq!(exp, err);\n}"", ""#[test]\nfn deserialize_with_optional_data() {\n    let ser = r#\""{\""code\"":-32700,\""message\"":\""Parse error\"", \""data\"":\""vegan\""}\""#;\n    let data = serde_json::value::to_raw_value(&\""vegan\"").unwrap();\n    let exp = ErrorObject::owned(ErrorCode::ParseError.code(), \""Parse error\"", Some(data));\n    let err: ErrorObject = serde_json::from_str(ser).unwrap();\n    assert_eq!(exp, err);\n}"", ""#[test]\nfn deserialized_error_with_quoted_str() {\n    let raw = r#\""{\n            \""code\"": 1002,\n            \""message\"": \""desc: \\\""Could not decode `ChargeAssetTxPayment::asset_id`\\\"" } })\"",\n            \""data\"": \""\\\\\\\""validate_transaction\\\\\\\""\""\n    }\""#;\n    let err: ErrorObject = serde_json::from_str(raw).unwrap();\n\n    let data = serde_json::value::to_raw_value(&\""\\\\\\\""validate_transaction\\\\\\\""\"").unwrap();\n    let exp = ErrorObject::borrowed(\n        1002,\n        \""desc: \\\""Could not decode `ChargeAssetTxPayment::asset_id`\\\"" } })\"",\n        Some(&*data),\n    );\n\n    assert_eq!(err, exp);\n}"", ""#[test]\nfn serialize_works() {\n    let exp = r#\""{\""code\"":-32603,\""message\"":\""Internal error\""}\""#;\n    let err: ErrorObject = ErrorCode::InternalError.into();\n    let ser = serde_json::to_string(&err).unwrap();\n    assert_eq!(exp, ser);\n}"", ""#[test]\nfn serialize_optional_data_works() {\n    let exp = r#\""{\""code\"":-32699,\""message\"":\""food\"",\""data\"":\""not vegan\""}\""#;\n    let data = serde_json::value::to_raw_value(&\""not vegan\"").unwrap();\n    let ser = serde_json::to_string(&ErrorObject::owned(-32699, \""food\"", Some(data))).unwrap();\n    assert_eq!(exp, ser);\n}""]}",test_generation
jsonrpsee-types,"{""code_context"": ""use std::borrow::Cow;\nuse std::fmt;\nuse serde::de::{self, Deserializer, Unexpected, Visitor};\nuse serde::ser::Serializer;\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value as JsonValue;\n\n#[derive(Clone, Debug)]\npub struct Params<'a>(Option<Cow<'a, str>>);\n\nimpl<'a> Params<'a> {\n    pub fn new(raw: Option<&'a str>) -> Self {\n        Self(raw.map(|r| r.trim().into()))\n    }\n\n    // other methods omitted for brevity\n}\n\npub struct ParamsSequence<'a>(&'a str);\n\nimpl<'a> ParamsSequence<'a> {\n    // methods omitted for brevity\n}"", ""code_to_test"": ""pub fn new(raw: Option<&'a str>) -> Self {\n    Self(raw.map(|r| r.trim().into()))\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn params_parse() {\n    let none = Params::new(None);\n    assert!(none.sequence().next::<u64>().is_err());\n    assert!(none.parse::<Option<u64>>().is_ok());\n    assert_eq!(none.len_bytes(), 0);\n\n    let array_params = Params::new(Some(\""[1, 2, 3]\""));\n    assert_eq!(array_params.len_bytes(), 9);\n    let arr: Result<[u64; 3], _> = array_params.parse();\n    assert!(arr.is_ok());\n\n    let mut seq = array_params.sequence();\n\n    assert_eq!(seq.next::<u64>().unwrap(), 1);\n    assert_eq!(seq.next::<u64>().unwrap(), 2);\n    assert_eq!(seq.next::<u64>().unwrap(), 3);\n    assert!(seq.next::<u64>().is_err());\n\n    let array_one = Params::new(Some(\""[1]\""));\n    assert_eq!(array_one.len_bytes(), 3);\n    let one: Result<u64, _> = array_one.one();\n    assert!(one.is_ok());\n\n    let object_params = Params::new(Some(r#\""{\""beef\"":99,\""dinner\"":0}\""#));\n    assert_eq!(object_params.len_bytes(), 22);\n    let obj: Result<serde_json::Value, _> = object_params.parse();\n    assert!(obj.is_ok());\n}"", ""#[test]\nfn params_sequence_optional_ignore_empty() {\n    let params = Params::new(Some(r#\""[\\\""foo\\\"", \\\""bar\\\""]\""#));\n    let mut seq = params.sequence();\n\n    assert_eq!(seq.optional_next::<&str>().unwrap(), Some(\""foo\""));\n    assert_eq!(seq.optional_next::<&str>().unwrap(), Some(\""bar\""));\n\n    let params = Params::new(Some(r#\""[]\""#));\n    let mut seq = params.sequence();\n    assert!(seq.optional_next::<&str>().unwrap().is_none());\n\n    let params = Params::new(Some(r#\""   []   \""#));\n    let mut seq = params.sequence();\n    assert!(seq.optional_next::<&str>().unwrap().is_none());\n\n    let params = Params::new(Some(r#\""{}\""#));\n    let mut seq = params.sequence();\n    assert!(seq.optional_next::<&str>().is_err(), \""JSON object not supported by RpcSequence\"");\n}""]}",test_generation
jsonrpsee-types,"{""code_context"": ""use std::borrow::Cow;\nuse http::Extensions;\nuse serde::{Deserialize, Serialize};\nuse serde_json::value::RawValue;\n\n#[derive(Serialize, Deserialize, Debug, Clone)]\npub struct Request<'a> {\n    pub jsonrpc: TwoPointZero,\n    pub id: Id<'a>,\n    pub method: Cow<'a, str>,\n    #[serde(skip_serializing_if = \""Option::is_none\"")]\n    pub params: Option<Cow<'a, RawValue>>,\n    #[serde(skip)]\n    pub extensions: Extensions,\n}\n\nimpl<'a> Request<'a> {\n    pub fn borrowed(method: &'a str, params: Option<&'a RawValue>, id: Id<'a>) -> Self {\n        Self {\n            jsonrpc: TwoPointZero,\n            id,\n            method: Cow::Borrowed(method),\n            params: params.map(Cow::Borrowed),\n            extensions: Extensions::new(),\n        }\n    }\n}\n\nenum Id<'a> {\n    Null,\n    Number(u64),\n    Str(Cow<'a, str>),\n}\n\nenum TwoPointZero {\n    // simplified for context\n}\n"", ""code_to_test"": ""pub fn borrowed(method: &'a str, params: Option<&'a RawValue>, id: Id<'a>) -> Self {\n    Self {\n        jsonrpc: TwoPointZero,\n        id,\n        method: Cow::Borrowed(method),\n        params: params.map(Cow::Borrowed),\n        extensions: Extensions::new(),\n    }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn deserialize_call() {\n    let method = \""subtract\"";\n    let params = \""[42, 23]\"";\n\n    let test_vector = vec![\n        (\n            r#\""{\""jsonrpc\"":\""2.0\"", \""method\"":\""subtract\"", \""params\"":[42, 23], \""id\"":1}\""#, \n            Id::Number(1),\n            Some(params),\n            method,\n        ),\n        (r#\""{\""jsonrpc\"":\""2.0\"", \""method\"":\""subtract\"", \""id\"":null}\""#, Id::Null, None, method),\n        (r#\""{\""jsonrpc\"":\""2.0\"", \""method\"":\""\\\""m\"", \""id\"":null}\""#, Id::Null, None, \""\\\""m\""),\n    ];\n\n    for (ser, id, params, method) in test_vector.into_iter() {\n        let request = serde_json::from_str::<Request>(ser).unwrap();\n        assert_eq!(request.jsonrpc, TwoPointZero);\n        assert_eq!(request.id, id);\n        assert_eq!(request.method, method);\n        assert_eq!(request.params.as_ref().map(|p| RawValue::get(p)), params);\n    }\n}"", ""#[test]\nfn serialize_call() {\n    let method = \""subtract\"";\n    let id = Id::Number(1);\n    let params = Some(serde_json::value::to_raw_value(&[42, 23]).unwrap());\n\n    let test_vector: &[(&'static str, Option<_>, Option<_>, &'static str)] = &[\n        (\n            r#\""{\""jsonrpc\"":\""2.0\"",\""id\"":1,\""method\"":\""subtract\"",\""params\"":[42,23]}\""#, \n            Some(id.clone()),\n            params.clone(),\n            method,\n        ),\n        (r#\""{\""jsonrpc\"":\""2.0\"",\""id\"":1,\""method\"":\""\\\""m\""}\""#, Some(id.clone()), None, \""\\\""m\""),\n        (r#\""{\""jsonrpc\"":\""2.0\"",\""id\"":null,\""method\"":\""subtract\"",\""params\"":[42,23]}\""#, None, params, method),\n        (r#\""{\""jsonrpc\"":\""2.0\"",\""id\"":1,\""method\"":\""subtract\""}\""#, Some(id.clone()), None, method),\n        (r#\""{\""jsonrpc\"":\""2.0\"",\""id\"":null,\""method\"":\""subtract\""}\""#, None, None, method),\n    ];\n\n    for (ser, id, params, method) in test_vector.iter().cloned() {\n        let request = Request::borrowed(method, params.as_deref(), id.unwrap_or(Id::Null));\n        let request_str = serde_json::to_string(&request).unwrap();\n        assert_eq!(&request_str, ser);\n    }\n}""]}",test_generation
libp2p-floodsub,"{""code"": ""let __placeholder__ = Topic::new(\""rust-lang\"");\nif !self.subscribed_topics.iter().any(|t| t.id() == __placeholder__.id()) {\n    self.subscribed_topics.push(__placeholder__.clone());\n}"", ""code_context"": ""pub struct Topic(String);\nimpl Topic {\n    pub fn new<S: Into<String>>(name: S) -> Self {\n        Topic(name.into())\n    }\n    pub fn id(&self) -> &str {\n        &self.0\n    }\n}""}","{""variable_name"": ""new_topic""}",variable_naming
libp2p-floodsub,"{""code"": ""let __placeholder__ = FloodsubMessage {\n    source: self.config.local_peer_id,\n    data: Bytes::from(\""Hello world\""),\n    sequence_number: rand::random::<[u8; 20]>().to_vec(),\n    topics: vec![Topic::new(\""updates\"")],\n};"", ""code_context"": ""use bytes::Bytes;\nuse libp2p_identity::PeerId;\npub struct Topic(String);\nimpl Topic {\n    pub fn new<S: Into<String>>(name: S) -> Self {\n        Topic(name.into())\n    }\n}\npub struct FloodsubMessage {\n    pub source: PeerId,\n    pub data: Bytes,\n    pub sequence_number: Vec<u8>,\n    pub topics: Vec<Topic>,\n}""}","{""variable_name"": ""outgoing_message""}",variable_naming
libp2p-floodsub,"{""code"": ""let __placeholder__: FnvHashSet<PeerId> = self.target_peers.clone();\nfor _ in __placeholder__.iter() {}"", ""code_context"": ""use fnv::FnvHashSet;\nuse libp2p_identity::PeerId;""}","{""variable_name"": ""target_peers_set""}",variable_naming
datafusion-datasource-csv,"{""code"": ""let mut conf = self.clone();"", ""code_context"": ""pub struct CsvSource {\n    batch_size: Option<usize>,\n    file_schema: Option<SchemaRef>,\n    file_projection: Option<Vec<usize>>,\n    pub(crate) has_header: bool,\n    delimiter: u8,\n    quote: u8,\n    terminator: Option<u8>,\n    escape: Option<u8>,\n    comment: Option<u8>,\n    metrics: ExecutionPlanMetricsSet,\n    projected_statistics: Option<Statistics>,\n    schema_adapter_factory: Option<Arc<dyn SchemaAdapterFactory>>,\n}\n\nimpl CsvSource {\n    pub fn with_escape(&self, escape: Option<u8>) -> Self {\n        let mut conf = self.clone();\n        conf.escape = escape;\n        conf\n    }\n}""}","{""next_api_call"": ""conf.escape = escape;""}",api_usage_prediction
datafusion-datasource-csv,"{""code"": ""let mut conf = self.clone();"", ""code_context"": ""pub struct CsvSource {\n    batch_size: Option<usize>,\n    file_schema: Option<SchemaRef>,\n    file_projection: Option<Vec<usize>>,\n    pub(crate) has_header: bool,\n    delimiter: u8,\n    quote: u8,\n    terminator: Option<u8>,\n    escape: Option<u8>,\n    comment: Option<u8>,\n    metrics: ExecutionPlanMetricsSet,\n    projected_statistics: Option<Statistics>,\n    schema_adapter_factory: Option<Arc<dyn SchemaAdapterFactory>>,\n}\n\nimpl CsvSource {\n    pub fn with_terminator(&self, terminator: Option<u8>) -> Self {\n        let mut conf = self.clone();\n        conf.terminator = terminator;\n        conf\n    }\n}""}","{""next_api_call"": ""conf.terminator = terminator;""}",api_usage_prediction
datafusion-datasource-csv,"{""code"": ""self.options.comment = comment;"", ""code_context"": ""pub struct CsvFormat {\n    options: CsvOptions,\n}\n\nimpl CsvFormat {\n    pub fn with_comment(mut self, comment: Option<u8>) -> Self {\n        self.options.comment = comment;\n        self\n    }\n}""}","{""next_api_call"": ""self""}",api_usage_prediction
wyz,"{""code"": ""pub struct Bidi<I>\nwhere I: DoubleEndedIterator\n{\n    inner: I,\n    next: fn(&mut I) -> Option<<I as Iterator>::Item>,\n    next_back: fn(&mut I) -> Option<<I as Iterator>::Item>,\n    nth: fn(&mut I, usize) -> Option<<I as Iterator>::Item>,\n    nth_back: fn(&mut I, usize) -> Option<<I as Iterator>::Item>,\n}"", ""code_context"": null}","{""docstring"": ""An iterator that conditionally reverses itself upon creation.\n\nThis acts as a conditional `.rev()` adapter: it reverses the direction of iteration, swapping `.next()` and `.next_back()`, but only if the provided condition is true. If the condition is false, then iteration proceeds normally.\n\nThe condition is only evaluated when the adapter is constructed, and all calls to drive the iterator are branchless.""}",docstring_generation
wyz,"{""code"": ""impl<I> Bidi<I>\nwhere I: DoubleEndedIterator\n{\n    pub fn new<II>(iter: II, cond: bool) -> Self\n    where II: IntoIterator<IntoIter = I> {\n        let inner = iter.into_iter();\n        if cond {\n            Self {\n                inner,\n                next: <I as DoubleEndedIterator>::next_back,\n                next_back: <I as Iterator>::next,\n                nth: <I as DoubleEndedIterator>::nth_back,\n                nth_back: <I as Iterator>::nth,\n            }\n        } else {\n            Self {\n                inner,\n                next: <I as Iterator>::next,\n                next_back: <I as DoubleEndedIterator>::next_back,\n                nth: <I as Iterator>::nth,\n                nth_back: <I as DoubleEndedIterator>::nth_back,\n            }\n        }\n    }\n}"", ""code_context"": null}","{""docstring"": ""Applies the `Bidi` adapter to a double-ended iterator and selects the direction of traversal.\n\n## Parameters\n\n- `iter`: anything that can be made into a double-ended iterator\n- `cond`: determines whether iteration proceeds ordinarily or reversed""}",docstring_generation
wyz,"{""code"": ""impl<T> FmtForward for T\nwhere T: Sized\n{\n    fn fmt_binary(self) -> FmtBinary<Self>\n    where Self: Binary {\n        FmtBinary(self)\n    }\n}"", ""code_context"": ""use core::fmt::Binary;\n\npub struct FmtBinary<T: Binary>(pub T);""}","{""docstring"": ""Causes `self` to use its `Binary` implementation when `Debug`-formatted.\n\n## Examples\n\n```rust\n# #[cfg(feature = \""std\"")] \nuse wyz::fmt::*;\nassert_eq!(format!(\""{:?}\"", 3.fmt_binary()), \""11\"");\n```""}",docstring_generation
wyz,"{""code"": ""impl<R> RangeExt<usize> for R\nwhere R: RangeBounds<usize>\n{\n    fn normalize(\n        self,\n        start: impl Into<Option<usize>>,\n        end: impl Into<Option<usize>>\n    ) -> Range<usize> {\n        let start = match self.start_bound() {\n            Bound::Unbounded => start.into().unwrap_or(0),\n            Bound::Included(&v) => v,\n            Bound::Excluded(&v) => v.saturating_add(1),\n        };\n        let end = match self.end_bound() {\n            Bound::Unbounded => end.into().unwrap_or(!0),\n            Bound::Included(&v) => v.saturating_add(1),\n            Bound::Excluded(&v) => v,\n        };\n        if start > end {\n            end .. start\n        } else {\n            start .. end\n        }\n    }\n}"", ""code_context"": ""use core::ops::{Bound, Range, RangeBounds};\n\npub trait RangeExt<T>: RangeBounds<T>\nwhere T: Ord\n{\n    fn normalize(self, start: impl Into<Option<T>>, end: impl Into<Option<T>>) -> Range<T>;\n    // other methods omitted for brevity\n}""}","{""docstring"": ""Normalizes a range-like type to a canonical half-open `Range`.\n\n## Parameters\n\n- `self`: The range to normalize.\n- `start`: An optional fallback *inclusive* lower bound.\n- `end`: An optional fallback *exclusive* upper bound.\n\n## Returns\n\nA `Range` whose start and end values are the following, in order of decreasing priority:\n\n- `self.start()`, or if absent, the `start` parameter, or if it is `None`, `0`.\n- `self.end()`, or if absent, the `end` parameter, or if it is `None`, `!0`.""}",docstring_generation
wyz,"{""code"": ""#[macro_export]\nmacro_rules! exit {\n    () => {\n        $crate::exit!(1);\n    };\n\n    ($num:expr $(,)? ) => {\n        ::std::process::exit($num);\n    };\n\n    ($num:expr, $fmt:expr $( , $arg:expr )* $(,)? ) => {{\n        eprintln!($fmt $( , $arg )*);\n        $crate::exit!($num);\n    }};\n}"", ""code_context"": null}","{""docstring"": ""`exit!` macro\n\nThe `exit!` macro simplifies exiting with an error code, and optionally printing an error message prior to exit.\n\n# Examples\n\nThis example exits with status `1`.\n\n```rust,should_panic\nwyz::exit!();\n```\n\nThis example exits with status `2`.\n\n```rust,should_panic\nwyz::exit!(2);\n```\n\nThis example exits with status `3`, and uses `eprintln!` to print an error message before exiting. Note that if `stderr` has been closed, this will crash the program with a panic due to `SIGPIPE`, and *not* call `process::exit()`.\n\n```rust,should_panic\nwyz::exit!(3, \""Error status: {}\"", \""testing\"");\n```""}",docstring_generation
libp2p-floodsub,"{""code"": ""let message = FloodsubMessage { source: self.config.local_peer_id, data: data.into(), sequence_number: rand::random::<[u8; 20]>().to_vec(), topics: topic.into_iter().map(Into::into).collect(), };"", ""code_context"": ""use libp2p_identity::PeerId;\nuse bytes::Bytes;\nuse crate::topic::Topic;\n\n#[derive(Debug, Clone, PartialEq, Eq, Hash)]\npub struct FloodsubMessage {\n    pub source: PeerId,\n    pub data: Bytes,\n    pub sequence_number: Vec<u8>,\n    pub topics: Vec<Topic>,\n}\n\n#[derive(Debug, Clone)]\npub struct Config {\n    pub local_peer_id: PeerId,\n    pub subscribe_local_messages: bool,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq, Hash)]\npub struct Topic(String);\n\nimpl Topic {\n    pub fn id(&self) -> &str { &self.0 }\n    pub fn new<S>(name: S) -> Topic where S: Into<String> { Topic(name.into()) }\n}\n\nimpl From<Topic> for String {\n    fn from(topic: Topic) -> String { topic.0 }\n}""}","{""next_api_call"": ""let self_subscribed = self.subscribed_topics.iter().any(|t| message.topics.iter().any(|u| t == u));""}",api_usage_prediction
libp2p-floodsub,"{""code"": ""let mut rpcs_to_dispatch: Vec<(PeerId, FloodsubRpc)> = Vec::new();"", ""code_context"": ""use libp2p_identity::PeerId;\nuse bytes::Bytes;\nuse crate::topic::Topic;\n\n#[derive(Debug, Clone, PartialEq, Eq, Hash)]\npub struct FloodsubMessage {\n    pub source: PeerId,\n    pub data: Bytes,\n    pub sequence_number: Vec<u8>,\n    pub topics: Vec<Topic>,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq, Hash)]\npub struct FloodsubSubscription {\n    pub action: FloodsubSubscriptionAction,\n    pub topic: Topic,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq, Hash)]\npub enum FloodsubSubscriptionAction {\n    Subscribe,\n    Unsubscribe,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq, Hash)]\npub struct FloodsubRpc {\n    pub messages: Vec<FloodsubMessage>,\n    pub subscriptions: Vec<FloodsubSubscription>,\n}""}","{""next_api_call"": ""for (peer_id, subscr_topics) in self.connected_peers.iter() {""}",api_usage_prediction
libp2p-floodsub,"{""code"": ""let remote_peer_topics = self.connected_peers.get_mut(&propagation_source).expect(\""connected_peers is kept in sync with the peers we are connected to; we are guaranteed to only receive events from connected peers; QED\"");"", ""code_context"": ""use libp2p_identity::PeerId;\nuse crate::topic::Topic;\n\n#[derive(Debug, Clone, PartialEq, Eq, Hash)]\npub struct FloodsubSubscription {\n    pub action: FloodsubSubscriptionAction,\n    pub topic: Topic,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq, Hash)]\npub enum FloodsubSubscriptionAction {\n    Subscribe,\n    Unsubscribe,\n}""}","{""next_api_call"": ""match subscription.action {""}",api_usage_prediction
datafusion-spark,"{""code"": ""fn __placeholder__(s: &str) -> bool { s.chars().all(|c| c.is_ascii_digit()) }"", ""code_context"": null}","{""function_name"": ""is_numeric""}",function_naming
datafusion-spark,"{""code"": ""fn __placeholder__(data: &[u8]) -> usize { data.len() }"", ""code_context"": null}","{""function_name"": ""binary_length""}",function_naming
datafusion-spark,"{""code"": ""fn __placeholder__(ts: &str) -> i32 { NaiveDateTime::parse_from_str(ts, \""%Y-%m-%d %H:%M:%S\"").map(|dt| dt.year()).unwrap_or(0) }"", ""code_context"": ""use chrono::{NaiveDateTime, Datelike};""}","{""function_name"": ""extract_year""}",function_naming
datafusion-spark,"{""code"": ""fn __placeholder__(delimiter: &str, items: &[String]) -> String { items.join(delimiter) }"", ""code_context"": null}","{""function_name"": ""concat_ws""}",function_naming
wyz,"{""code"": ""pub fn __placeholder__<R>(range: R) -> bool\nwhere\n    R: core::ops::RangeBounds<usize> + Clone,\n{\n    let normalized = range.clone().normalize(None, None);\n    normalized.start == normalized.end\n}"", ""code_context"": ""use crate::RangeExt;""}","{""function_name"": ""is_empty_range""}",function_naming
wyz,"{""code"": ""pub fn __placeholder__(start: usize, end_inclusive: usize) -> core::ops::Range<usize> {\n    start .. end_inclusive.saturating_add(1)\n}"", ""code_context"": null}","{""function_name"": ""inclusive_range""}",function_naming
wyz,"{""code"": ""pub fn __placeholder__<I>(iter: I, cond: bool) -> Bidi<I>\nwhere\n    I: core::iter::DoubleEndedIterator,\n{\n    Bidi::new(iter, cond)\n}"", ""code_context"": ""use crate::Bidi;""}","{""function_name"": ""make_bidi""}",function_naming
maxminddb,"{""query"": ""How can I look up the city information for a given IP address using the MaxMindDB library in Rust?"", ""code_context"": null}","{""code_snippet"": ""use std::net::IpAddr;\nuse maxminddb::{geoip2, Reader};\n\nfn main() -> Result<(), Box<dyn std::error::Error>> {\n    let reader = Reader::open_readfile(\""GeoLite2-City.mmdb\"")?;\n    let ip: IpAddr = \""89.160.20.128\"".parse()?;\n    if let Some(city) = reader.lookup::<geoip2::City>(ip)? {\n        println!(\""City info: {:?}\"", city);\n    } else {\n        println!(\""No city information found for {}\"", ip);\n    }\n    Ok(())\n}""}",code_search
maxminddb,"{""query"": ""How do I iterate over all IP networks within a CIDR block using maxminddb?"", ""code_context"": null}","{""code_snippet"": ""use ipnetwork::IpNetwork;\nuse maxminddb::{geoip2, Reader, Within};\n\nfn main() -> Result<(), Box<dyn std::error::Error>> {\n    let reader = Reader::open_readfile(\""GeoLite2-City.mmdb\"")?;\n    let cidr: IpNetwork = \""81.2.69.0/24\"".parse()?;\n    let mut iter: Within<geoip2::City, _> = reader.within(cidr)?;\n    while let Some(entry) = iter.next() {\n        let item = entry?;\n        println!(\""Network: {}, City: {:?}\"", item.ip_net, item.info);\n    }\n    Ok(())\n}""}",code_search
maxminddb,"{""query"": ""How can I handle errors when opening a MaxMind DB file with the maxminddb crate?"", ""code_context"": null}","{""code_snippet"": ""use maxminddb::{Reader, MaxMindDbError};\n\nfn main() {\n    match Reader::open_readfile(\""GeoLite2-City.mmdb\"") {\n        Ok(reader) => {\n            // Use the reader, e.g., perform a lookup\n            println!(\""Database opened successfully.\"");\n            let _ = reader; // placeholder\n        }\n        Err(e) => {\n            eprintln!(\""Failed to open MaxMind DB: {}\"", e);\n            match e {\n                MaxMindDbError::Io(io_err) => eprintln!(\""I/O error: {}\"", io_err),\n                MaxMindDbError::InvalidDatabase(msg) => eprintln!(\""Invalid database: {}\"", msg),\n                MaxMindDbError::Decoding(msg) => eprintln!(\""Decoding error: {}\"", msg),\n                MaxMindDbError::InvalidNetwork(msg) => eprintln!(\""Invalid network: {}\"", msg),\n                #[cfg(feature = \""mmap\"")]\n                MaxMindDbError::Mmap(io_err) => eprintln!(\""Mmap error: {}\"", io_err),\n                _ => {}\n            }\n        }\n    }\n}""}",code_search
maxminddb,"{""query"": ""How do I open a MaxMind DB file using memory mapping with the maxminddb crate?"", ""code_context"": null}","{""code_snippet"": ""use maxminddb::Reader;\n\n#[cfg(feature = \""mmap\"")]\nfn main() -> Result<(), Box<dyn std::error::Error>> {\n    let reader = Reader::open_mmap(\""GeoLite2-City.mmdb\"")?;\n    // Perform lookups with `reader`\n    Ok(())\n}\n\n#[cfg(not(feature = \""mmap\""))]\nfn main() -> Result<(), Box<dyn std::error::Error>> {\n    let reader = Reader::open_readfile(\""GeoLite2-City.mmdb\"")?;\n    // Perform lookups with `reader`\n    Ok(())\n}""}",code_search
libp2p-floodsub,"{""code_before"": ""pub fn subscribe(&mut self, topic: Topic) -> bool {\n    if self.subscribed_topics.iter().any(|t| t.id() == topic.id()) {\n        return false;\n    }\n\n    for peer in self.connected_peers.keys() {\n        self.events.push_back(ToSwarm::NotifyHandler {\n            peer_id: *peer,\n            handler: NotifyHandler::Any,\n            event: FloodsubRpc {\n                messages: Vec::new(),\n                subscriptions: vec![FloodsubSubscription {\n                    topic: topic.clone(),\n                    action: FloodsubSubscriptionAction::Subscribe,\n                }],\n            },\n        });\n    }\n\n    self.subscribed_topics.push(topic);\n    true\n}"", ""code_context"": ""use std::collections::{HashMap, VecDeque};\nuse libp2p_swarm::{NotifyHandler, ToSwarm};\nuse libp2p_identity::PeerId;\nuse smallvec::SmallVec;\n\n#[derive(Debug, Clone, PartialEq, Eq, Hash)]\npub struct Topic(String);\nimpl Topic {\n    pub fn id(&self) -> &str { &self.0 }\n}\n\npub struct FloodsubSubscription {\n    pub topic: Topic,\n    pub action: FloodsubSubscriptionAction,\n}\n\npub enum FloodsubSubscriptionAction {\n    Subscribe,\n    Unsubscribe,\n}\n\npub struct FloodsubRpc {\n    pub messages: Vec<()>,\n    pub subscriptions: Vec<FloodsubSubscription>,\n}\n\npub struct Behaviour {\n    pub subscribed_topics: SmallVec<[Topic; 16]>,\n    pub connected_peers: HashMap<PeerId, SmallVec<[Topic; 8]>>,\n    pub events: VecDeque<ToSwarm<Event, FloodsubRpc>>,\n}\n\npub enum Event {}""}","{""code_after"": ""pub fn subscribe(&mut self, topic: Topic) -> bool {\n    if self.subscribed_topics.contains(&topic) {\n        return false;\n    }\n\n    for peer in self.connected_peers.keys() {\n        self.events.push_back(ToSwarm::NotifyHandler {\n            peer_id: *peer,\n            handler: NotifyHandler::Any,\n            event: FloodsubRpc {\n                messages: Vec::new(),\n                subscriptions: vec![FloodsubSubscription {\n                    topic: topic.clone(),\n                    action: FloodsubSubscriptionAction::Subscribe,\n                }],\n            },\n        });\n    }\n\n    self.subscribed_topics.push(topic);\n    true\n}"", ""review_comment"": ""Replaced the manual iteration over `subscribed_topics` with the idiomatic `contains` method. Because `Topic` implements `Eq` and `Hash`, `contains` performs the same check more efficiently and makes the intent clearer. The behaviour of rejecting duplicate subscriptions remains unchanged.""}",code_review
libp2p-floodsub,"{""code_before"": ""let self_subscribed = self.subscribed_topics.iter().any(|t| {\n    message.topics.iter().any(|u| t == u)\n});"", ""code_context"": ""use smallvec::SmallVec;\n\n#[derive(Debug, Clone, PartialEq, Eq, Hash)]\npub struct Topic(String);\n\npub struct FloodsubMessage {\n    pub topics: Vec<Topic>,\n    // other fields omitted for brevity\n}\n\npub struct Behaviour {\n    pub subscribed_topics: SmallVec<[Topic; 16]>,\n}\n""}","{""code_after"": ""let self_subscribed = self.subscribed_topics.iter().any(|t| message.topics.contains(t));"", ""review_comment"": ""Simplified the nested `any` calls by using `Vec::contains`. This makes the intention—checking whether any of our subscribed topics appear in the message's topic list—explicit and reduces the amount of iterator nesting, improving readability.""}",code_review
libp2p-floodsub,"{""code_before"": ""match self.received.test_and_add(&message) {\n    Ok(true) => {}\n    Ok(false) => continue,\n    Err(e @ CuckooError::NotEnoughSpace) => {\n        tracing::warn!(\n            \""Message was added to 'received' Cuckoofilter but some \\\n             other message was removed as a consequence: {}\"",\n            e,\n        );\n    }\n}"", ""code_context"": ""use cuckoofilter::{CuckooFilter, CuckooError};\nuse std::collections::hash_map::DefaultHasher;\n\npub struct FloodsubMessage; // placeholder\n\npub struct Behaviour {\n    pub received: CuckooFilter<DefaultHasher>,\n}\n""}","{""code_after"": ""if let Err(e @ CuckooError::NotEnoughSpace) = self.received.test_and_add(&message) {\n    tracing::warn!(\n        \""Message was added to 'received' Cuckoofilter but some \\\n         other message was removed as a consequence: {}\"",\n        e,\n    );\n}"", ""review_comment"": ""The error‑handling logic is reduced to a single `if let` that focuses on the only case that requires special handling. This eliminates unnecessary pattern branches and makes the control flow easier to follow while preserving the original warning behaviour.""}",code_review
libp2p-floodsub,"{""code_before"": ""let message = FloodsubMessage {\n    source: self.config.local_peer_id,\n    data: data.into(),\n    sequence_number: rand::random::<[u8; 20]>().to_vec(),\n    topics: topic.into_iter().map(Into::into).collect(),\n};"", ""code_context"": ""use rand::random;\nuse bytes::Bytes;\nuse libp2p_identity::PeerId;\n\npub struct Config {\n    pub local_peer_id: PeerId,\n    // other fields omitted\n}\n\npub struct FloodsubMessage {\n    pub source: PeerId,\n    pub data: Bytes,\n    pub sequence_number: Vec<u8>,\n    pub topics: Vec<Topic>,\n}\n\npub struct Behaviour {\n    pub config: Config,\n}\n\npub struct Topic(String);\n""}","{""code_after"": ""let sequence_number = rand::random::<[u8; 20]>().to_vec();\nlet message = FloodsubMessage {\n    source: self.config.local_peer_id,\n    data: data.into(),\n    sequence_number,\n    topics: topic.into_iter().map(Into::into).collect(),\n};"", ""review_comment"": ""Extracting the generation of the random sequence number into its own binding improves readability: the `FloodsubMessage` construction now lists fields without inline expressions, making the structure of the message clearer at a glance.""}",code_review
wyz,"{""code_context"": ""pub struct Bidi<I>\nwhere\n    I: DoubleEndedIterator,\n{\n    inner: I,\n    next: fn(&mut I) -> Option<<I as Iterator>::Item>,\n    next_back: fn(&mut I) -> Option<<I as Iterator>::Item>,\n    nth: fn(&mut I, usize) -> Option<<I as Iterator>::Item>,\n    nth_back: fn(&mut I, usize) -> Option<<I as Iterator>::Item>,\n}"", ""code_to_test"": ""impl<I> Bidi<I>\nwhere\n    I: DoubleEndedIterator,\n{\n    pub fn new<II>(iter: II, cond: bool) -> Self\n    where\n        II: IntoIterator<IntoIter = I>,\n    {\n        let inner = iter.into_iter();\n        if cond {\n            Self {\n                inner,\n                next: <I as DoubleEndedIterator>::next_back,\n                next_back: <I as Iterator>::next,\n                nth: <I as DoubleEndedIterator>::nth_back,\n                nth_back: <I as Iterator>::nth,\n            }\n        } else {\n            Self {\n                inner,\n                next: <I as Iterator>::next,\n                next_back: <I as DoubleEndedIterator>::next_back,\n                nth: <I as Iterator>::nth,\n                nth_back: <I as DoubleEndedIterator>::nth_back,\n            }\n        }\n    }\n}"", ""test_context"": ""use super::*;""}","{""test_cases"": [""#[test]\nfn forward() {\n    let mut iter = (0 .. 6).bidi(false);\n\n    assert_eq!(iter.next(), Some(0));\n    assert_eq!(iter.next_back(), Some(5));\n    assert_eq!(iter.nth(1), Some(2));\n    assert_eq!(iter.nth_back(1), Some(3));\n    assert!(iter.next().is_none());\n}"", ""#[test]\nfn reverse() {\n    let mut iter = (0 .. 6).bidi(true);\n\n    assert_eq!(iter.next(), Some(5));\n    assert_eq!(iter.next_back(), Some(0));\n    assert_eq!(iter.nth(1), Some(3));\n    assert_eq!(iter.nth_back(1), Some(2));\n    assert!(iter.next().is_none());\n}""]}",test_generation
wyz,"{""code_context"": ""pub struct Bidi<I>\nwhere\n    I: DoubleEndedIterator,\n{\n    inner: I,\n    next: fn(&mut I) -> Option<<I as Iterator>::Item>,\n    next_back: fn(&mut I) -> Option<<I as Iterator>::Item>,\n    nth: fn(&mut I, usize) -> Option<<I as Iterator>::Item>,\n    nth_back: fn(&mut I, usize) -> Option<<I as Iterator>::Item>,\n}"", ""code_to_test"": ""pub trait BidiIterator\nwhere\n    Self: Sized + IntoIterator,\n    <Self as IntoIterator>::IntoIter: DoubleEndedIterator,\n{\n    fn bidi(self, cond: bool) -> Bidi<Self::IntoIter> {\n        Bidi::new(self, cond)\n    }\n}"", ""test_context"": ""use super::*;""}","{""test_cases"": [""#[test]\nfn forward() {\n    let mut iter = (0 .. 6).bidi(false);\n\n    assert_eq!(iter.next(), Some(0));\n    assert_eq!(iter.next_back(), Some(5));\n    assert_eq!(iter.nth(1), Some(2));\n    assert_eq!(iter.nth_back(1), Some(3));\n    assert!(iter.next().is_none());\n}"", ""#[test]\nfn reverse() {\n    let mut iter = (0 .. 6).bidi(true);\n\n    assert_eq!(iter.next(), Some(5));\n    assert_eq!(iter.next_back(), Some(0));\n    assert_eq!(iter.nth(1), Some(3));\n    assert_eq!(iter.nth_back(1), Some(2));\n    assert!(iter.next().is_none());\n}""]}",test_generation
wyz,"{""code_context"": ""pub struct FmtList<T>(pub T)\nwhere\n    for<'a> &'a T: IntoIterator;"", ""code_to_test"": ""pub trait FmtForward: Sized {\n    fn fmt_list(self) -> FmtList<Self>\n    where\n        for<'a> &'a Self: IntoIterator,\n    {\n        FmtList(self)\n    }\n}"", ""test_context"": ""use super::*;""}","{""test_cases"": [""#[test]\nfn render_list() {\n    let list = [0, 1, 2, 3];\n    assert_eq!(format!(\""{:02b}\"", list.fmt_list()), \""[00, 01, 10, 11]\"");\n    assert_eq!(format!(\""{:01?}\"", list.fmt_list()), \""[0, 1, 2, 3]\"");\n    assert_eq!(format!(\""{:01}\"", list.fmt_list()), \""[0, 1, 2, 3]\"");\n\n    let list = [-51.0, -1.2, 1.3, 54.0];\n    assert_eq!(format!(\""{:e}\"", list.fmt_list()), \""[-5.1e1, -1.2e0, 1.3e0, 5.4e1]\"");\n    assert_eq!(format!(\""{:E}\"", list.fmt_list()), \""[-5.1E1, -1.2E0, 1.3E0, 5.4E1]\"");\n\n    let list = [0, 10, 20, 30];\n    assert_eq!(format!(\""{:02x}\"", list.fmt_list()), \""[00, 0a, 14, 1e]\"");\n    assert_eq!(format!(\""{:02o}\"", list.fmt_list()), \""[00, 12, 24, 36]\"");\n    assert_eq!(format!(\""{:02X}\"", list.fmt_list()), \""[00, 0A, 14, 1E]\"");\n\n    assert_eq!(format!(\""{:02?}\"", list.fmt_list().fmt_lower_hex()), \""[00, 0a, 14, 1e]\"");\n}""]}",test_generation
gdk-pixbuf-sys,"{""query"": ""How can I load an image file into a GdkPixbuf using the gdk-pixbuf-sys bindings?"", ""code_context"": null}","{""code_snippet"": ""use std::ffi::CString;\nuse std::ptr;\nuse gdk_pixbuf_sys::{gdk_pixbuf_new_from_file, GdkPixbuf, GError};\n\nfn load_pixbuf(path: &str) -> Result<*mut GdkPixbuf, String> {\n    let c_path = CString::new(path).map_err(|e| e.to_string())?;\n    let mut error: *mut GError = ptr::null_mut();\n    let pixbuf = unsafe { gdk_pixbuf_new_from_file(c_path.as_ptr(), &mut error) };\n    if pixbuf.is_null() {\n        Err(\""Failed to load image\"".to_string())\n    } else {\n        Ok(pixbuf)\n    }\n}""}",code_search
gdk-pixbuf-sys,"{""query"": ""How do I obtain the width and height of a GdkPixbuf?"", ""code_context"": null}","{""code_snippet"": ""use gdk_pixbuf_sys::{gdk_pixbuf_get_width, gdk_pixbuf_get_height, GdkPixbuf};\n\nfn pixbuf_dimensions(pixbuf: *mut GdkPixbuf) -> (i32, i32) {\n    let w = unsafe { gdk_pixbuf_get_width(pixbuf) };\n    let h = unsafe { gdk_pixbuf_get_height(pixbuf) };\n    (w, h)\n}""}",code_search
gdk-pixbuf-sys,"{""query"": ""How can I rotate a GdkPixbuf 90 degrees clockwise?"", ""code_context"": null}","{""code_snippet"": ""use gdk_pixbuf_sys::{gdk_pixbuf_rotate_simple, GdkPixbuf, GDK_PIXBUF_ROTATE_CLOCKWISE};\n\nfn rotate_90_clockwise(pixbuf: *mut GdkPixbuf) -> *mut GdkPixbuf {\n    unsafe { gdk_pixbuf_rotate_simple(pixbuf, GDK_PIXBUF_ROTATE_CLOCKWISE) }\n}""}",code_search
gdk-pixbuf-sys,"{""query"": ""How do I save a GdkPixbuf to a PNG file using the FFI bindings?"", ""code_context"": null}","{""code_snippet"": ""use std::ffi::CString;\nuse std::ptr;\nuse gdk_pixbuf_sys::{gdk_pixbuf_save, GdkPixbuf, GError};\n\nfn save_pixbuf(pixbuf: *mut GdkPixbuf, path: &str) -> Result<(), String> {\n    let c_path = CString::new(path).map_err(|e| e.to_string())?;\n    let c_type = CString::new(\""png\"").unwrap();\n    let mut error: *mut GError = ptr::null_mut();\n    let ok = unsafe { gdk_pixbuf_save(pixbuf, c_path.as_ptr(), c_type.as_ptr(), &mut error) };\n    if ok == 0 {\n        Err(\""Failed to save image\"".to_string())\n    } else {\n        Ok(())\n    }\n}""}",code_search
tokio-tungstenite,"{""title"": ""Broadcast a text message to all connected WebSocket clients"", ""description"": ""A developer wants a helper that can send a text message to every currently connected client. The server keeps a shared map of peer addresses to unbounded senders, and the function should iterate over this map and forward the message."", ""code_context"": ""use tokio::net::{TcpListener, TcpStream};\nuse tokio_tungstenite::{accept_async, tungstenite::protocol::Message};\nuse futures_util::{SinkExt, StreamExt};\nuse futures_channel::mpsc::UnboundedSender;\nuse std::collections::HashMap;\nuse std::sync::{Arc, Mutex};\nuse std::net::SocketAddr;\n\ntype PeerMap = Arc<Mutex<HashMap<SocketAddr, UnboundedSender<Message>>>>;""}","{""code"": ""fn broadcast_message(state: &PeerMap, text: &str) {\n    let peers = state.lock().unwrap();\n    for (_, tx) in peers.iter() {\n        let _ = tx.unbounded_send(Message::Text(text.to_string()));\n    }\n}""}",code_generation
tokio-tungstenite,"{""title"": ""Forward only binary messages to all peers"", ""description"": ""A developer needs a connection handler that accepts a WebSocket, stores its sender in the shared peer map, and forwards only binary messages received from that client to every other connected client."", ""code_context"": ""use tokio::net::{TcpListener, TcpStream};\nuse tokio_tungstenite::{accept_async, tungstenite::protocol::Message};\nuse futures_util::{SinkExt, StreamExt};\nuse futures_channel::mpsc::UnboundedSender;\nuse std::collections::HashMap;\nuse std::sync::{Arc, Mutex};\nuse std::net::SocketAddr;\n\ntype PeerMap = Arc<Mutex<HashMap<SocketAddr, UnboundedSender<Message>>>>;""}","{""code"": ""async fn handle_binary_only(stream: TcpStream, state: PeerMap) {\n    let ws = accept_async(stream).await.expect(\""Handshake failed\"");\n    let (mut ws_sender, mut ws_receiver) = ws.split();\n    let addr = ws_sender.get_ref().peer_addr().expect(\""No peer address\"");\n    let (tx, _rx) = futures_channel::mpsc::unbounded();\n    state.lock().unwrap().insert(addr, tx);\n    while let Some(msg) = ws_receiver.next().await {\n        let msg = msg.expect(\""Receive error\"");\n        if msg.is_binary() {\n            let peers = state.lock().unwrap();\n            for (_, peer_tx) in peers.iter() {\n                let _ = peer_tx.unbounded_send(msg.clone());\n            }\n        }\n    }\n}""}",code_generation
tokio-tungstenite,"{""title"": ""Collect per‑connection message statistics"", ""description"": ""A developer wants to keep track of how many messages each client sends and receives. The helper should update a shared statistics map whenever a message is read or written."", ""code_context"": ""use tokio::net::{TcpListener, TcpStream};\nuse tokio_tungstenite::{accept_async, tungstenite::protocol::Message};\nuse futures_util::{SinkExt, StreamExt};\nuse std::collections::HashMap;\nuse std::net::SocketAddr;\nuse std::sync::{Arc, Mutex};""}","{""code"": ""struct ConnStats {\n    sent: usize,\n    received: usize,\n}\n\nasync fn track_stats(stream: TcpStream, stats: Arc<Mutex<HashMap<SocketAddr, ConnStats>>>) {\n    let ws = accept_async(stream).await.expect(\""Handshake failed\"");\n    let addr = ws.get_ref().peer_addr().expect(\""No peer address\"");\n    let (mut sender, mut receiver) = ws.split();\n    while let Some(msg) = receiver.next().await {\n        let msg = msg.expect(\""Receive error\"");\n        {\n            let mut map = stats.lock().unwrap();\n            let entry = map.entry(addr).or_insert(ConnStats { sent: 0, received: 0 });\n            entry.received += 1;\n        }\n        if msg.is_text() || msg.is_binary() {\n            sender.send(msg.clone()).await.expect(\""Send error\"");\n            let mut map = stats.lock().unwrap();\n            let entry = map.get_mut(&addr).unwrap();\n            entry.sent += 1;\n        }\n    }\n}""}",code_generation
tokio-tungstenite,"{""title"": ""Gracefully close all connections on server shutdown"", ""description"": ""When the server receives a termination signal it should send a close frame to every connected client. The helper iterates over the shared peer map and issues a close message."", ""code_context"": ""use tokio::net::{TcpListener, TcpStream};\nuse tokio_tungstenite::{accept_async, tungstenite::protocol::Message};\nuse futures_util::{SinkExt, StreamExt};\nuse futures_channel::mpsc::UnboundedSender;\nuse std::collections::HashMap;\nuse std::sync::{Arc, Mutex};\nuse std::net::SocketAddr;\n\ntype PeerMap = Arc<Mutex<HashMap<SocketAddr, UnboundedSender<Message>>>>;""}","{""code"": ""async fn close_all(state: PeerMap) {\n    let peers = state.lock().unwrap();\n    for (_, tx) in peers.iter() {\n        let _ = tx.unbounded_send(Message::Close(None));\n    }\n}""}",code_generation
tokio-tungstenite,"{""buggy_code"": ""async fn handle_connection(peer: SocketAddr, stream: TcpStream) -> Result<()> {\n    let ws_stream = accept_async(stream).await.expect(\""Failed to accept\"");\n    info!(\""New WebSocket connection: {}\"", peer);\n    let (mut ws_sender, mut ws_receiver) = ws_stream.split();\n    let mut interval = tokio::time::interval(Duration::from_millis(1000));\n\n    loop {\n        tokio::select! {\n            msg = ws_receiver.next() => {\n                match msg {\n                    Some(msg) => {\n                        let msg = msg?;\n                        if msg.is_text() ||msg.is_binary() {\n                            ws_sender.send(msg).await?;\n                        } else if msg.is_close() {\n                            break;\n                        }\n                    }\n                    None => break,\n                }\n            }\n            _ = interval.tick() => {\n                ws_sender.send(Message::text(\""tick\"")).await?;\n            }\n        }\n    }\n\n    Ok(())\n}"", ""code_context"": ""use std::net::SocketAddr;\nuse tokio::net::TcpStream;\nuse tokio_tungstenite::{accept_async, tungstenite::{Message, Result}};\nuse futures_util::{StreamExt, SinkExt};\nuse std::time::Duration;\nuse log::info;""}","{""fixed_code"": ""async fn handle_connection(peer: SocketAddr, stream: TcpStream) -> Result<()> {\n    let ws_stream = accept_async(stream).await.expect(\""Failed to accept\"");\n    info!(\""New WebSocket connection: {}\"", peer);\n    let (mut ws_sender, mut ws_receiver) = ws_stream.split();\n    let mut interval = tokio::time::interval(Duration::from_millis(1000));\n\n    loop {\n        tokio::select! {\n            msg = ws_receiver.next() => {\n                match msg {\n                    Some(msg) => {\n                        let msg = msg?;\n                        if msg.is_text() || msg.is_binary() {\n                            ws_sender.send(msg).await?;\n                        } else if msg.is_ping() {\n                            // Respond to Ping frames to keep the connection alive\n                            ws_sender.send(Message::Pong(msg.into_data())).await?;\n                        } else if msg.is_close() {\n                            break;\n                        }\n                    }\n                    None => break,\n                }\n            }\n            _ = interval.tick() => {\n                ws_sender.send(Message::text(\""tick\"")).await?;\n            }\n        }\n    }\n\n    Ok(())\n}"", ""bug_description"": ""The original handler ignored `Message::Ping` frames. WebSocket peers expect a Pong response; without it the connection can be considered dead and may be closed by the remote side after a timeout. Adding explicit handling for Ping frames and replying with a Pong keeps the connection alive and follows the WebSocket protocol.""}",bug_detection
tokio-tungstenite,"{""buggy_code"": ""impl<S> Read for AllowStd<S>\nwhere\n    S: AsyncRead + Unpin,\n{\n    fn read(&mut self, buf: &mut [u8]) -> std::io::Result<usize> {\n        trace!(\""{}:{} Read.read\"", file!(), line!());\n        let mut buf = ReadBuf::new(buf);\n        match self.with_context(ContextWaker::Read, |ctx, stream| {\n            trace!(\""{}:{} Read.with_context read -> poll_read\"", file!(), line!());\n            stream.poll_read(ctx, &mut buf)\n        }) {\n            Poll::Ready(Ok(_)) => Ok(buf.filled().len()),\n            Poll::Ready(Err(err)) => Err(err),\n            Poll::Pending => Err(std::io::Error::from(std::io::ErrorKind::WouldBlock)),\n        }\n    }\n}"", ""code_context"": ""use std::pin::Pin;\nuse std::task::{Context, Poll};\nuse tokio::io::{AsyncRead, ReadBuf};\nuse tungstenite::Error as WsError;\nuse crate::{ContextWaker, SetWaker};\nuse log::trace;""}","{""fixed_code"": ""impl<S> Read for AllowStd<S>\nwhere\n    S: AsyncRead + Unpin,\n{\n    fn read(&mut self, buf: &mut [u8]) -> std::io::Result<usize> {\n        trace!(\""{}:{} Read.read\"", file!(), line!());\n        let mut buf = ReadBuf::new(buf);\n        match self.with_context(ContextWaker::Read, |ctx, stream| {\n            trace!(\""{}:{} Read.with_context read -> poll_read\"", file!(), line!());\n            stream.poll_read(ctx, &mut buf)\n        }) {\n            Poll::Ready(Ok(_)) => {\n                let filled = buf.filled();\n                if filled.is_empty() {\n                    // No data available yet; treat as WouldBlock to avoid signalling EOF\n                    Err(std::io::Error::from(std::io::ErrorKind::WouldBlock))\n                } else {\n                    Ok(filled.len())\n                }\n            }\n            Poll::Ready(Err(err)) => Err(err),\n            Poll::Pending => Err(std::io::Error::from(std::io::ErrorKind::WouldBlock)),\n        }\n    }\n}"", ""bug_description"": ""When `poll_read` returns `Poll::Ready(Ok(()))` but no bytes have been filled, the original implementation returned `Ok(0)`. A zero‑byte read is interpreted by many consumers as end‑of‑stream, causing premature termination of the WebSocket connection. The fix checks whether any data was actually read; if the buffer is still empty it returns `WouldBlock` instead of `Ok(0)`, preserving the non‑blocking semantics.""}",bug_detection
tokio-tungstenite,"{""buggy_code"": ""async fn process_message(message: Message) -> Result<Message, Error> {\n    if message.is_close() {\n        return Ok(Message::Close(None));\n    }\n    if message.is_ping() {\n        return Ok(Message::Pong(()));\n    }\n    println!(\""Received message: {:?}\"", message);\n    let response = Message::text(\""Hello, world!\"");\n    Ok(response)\n}"", ""code_context"": ""use tungstenite::{Message, Error};""}","{""fixed_code"": ""async fn process_message(message: Message) -> Result<Message, Error> {\n    if message.is_close() {\n        return Ok(Message::Close(None));\n    }\n    if message.is_ping() {\n        // Echo the payload back as a Pong frame\n        return Ok(Message::Pong(message.into_data()));\n    }\n    if message.is_pong() {\n        // No action needed for Pong frames\n        return Ok(message);\n    }\n    println!(\""Received message: {:?}\"", message);\n    let response = Message::text(\""Hello, world!\"");\n    Ok(response)\n}"", ""bug_description"": ""The original function attempted to create a `Message::Pong` with an empty payload (`()`), discarding the ping's payload. According to the WebSocket spec, a Pong must carry the same payload as the Ping it answers. Dropping the payload can break protocols that rely on ping/pong data (e.g., keep‑alive checks). The corrected version forwards the ping's payload using `message.into_data()` and also adds a harmless pass‑through for incoming Pong frames.""}",bug_detection
datafusion-datasource-csv,"{""code"": ""pub fn with_delimiter(&self, delimiter: u8) -> Self {\n    let mut conf = self.clone();\n    conf.delimiter = delimiter;\n    conf\n}"", ""code_context"": ""use std::sync::Arc;\nuse arrow::datatypes::SchemaRef;\nuse datafusion_common::Statistics;\nuse datafusion_physical_plan::metrics::ExecutionPlanMetricsSet;\nuse datafusion_datasource::schema_adapter::SchemaAdapterFactory;\n\n#[derive(Clone, Default)]\npub struct CsvSource {\n    batch_size: Option<usize>,\n    file_schema: Option<SchemaRef>,\n    file_projection: Option<Vec<usize>>,\n    pub(crate) has_header: bool,\n    delimiter: u8,\n    quote: u8,\n    terminator: Option<u8>,\n    escape: Option<u8>,\n    comment: Option<u8>,\n    metrics: ExecutionPlanMetricsSet,\n    projected_statistics: Option<Statistics>,\n    schema_adapter_factory: Option<Arc<dyn SchemaAdapterFactory>>,\n}""}","{""commented_code"": ""pub fn with_delimiter(&self, delimiter: u8) -> Self { // Set the column delimiter for CSV parsing\n    let mut conf = self.clone();\n    conf.delimiter = delimiter;\n    conf\n}""}",comment_generation
datafusion-datasource-csv,"{""code"": ""fn open<R: Read>(&self, reader: R) -> Result<csv::Reader<R>> {\n    Ok(self.builder().build(reader)?)\n}"", ""code_context"": ""use std::io::Read;\nuse std::sync::Arc;\nuse arrow::csv;\nuse arrow::csv::ReaderBuilder;\nuse arrow::datatypes::SchemaRef;\nuse datafusion_common::Result;\n\n#[derive(Clone, Default)]\npub struct CsvSource {\n    batch_size: Option<usize>,\n    file_schema: Option<SchemaRef>,\n    file_projection: Option<Vec<usize>>,\n    pub(crate) has_header: bool,\n    delimiter: u8,\n    quote: u8,\n    terminator: Option<u8>,\n    escape: Option<u8>,\n    comment: Option<u8>,\n}\n\nimpl CsvSource {\n    fn builder(&self) -> ReaderBuilder {\n        let mut builder = csv::ReaderBuilder::new(Arc::clone(\n            self.file_schema\n                .as_ref()\n                .expect(\""Schema must be set before initializing builder\""),\n        ))\n        .with_delimiter(self.delimiter)\n        .with_batch_size(\n            self.batch_size\n                .expect(\""Batch size must be set before initializing builder\""),\n        )\n        .with_header(self.has_header)\n        .with_quote(self.quote);\n        if let Some(terminator) = self.terminator {\n            builder = builder.with_terminator(terminator);\n        }\n        if let Some(proj) = &self.file_projection {\n            builder = builder.with_projection(proj.clone());\n        }\n        if let Some(escape) = self.escape {\n            builder = builder.with_escape(escape);\n        }\n        if let Some(comment) = self.comment {\n            builder = builder.with_comment(comment);\n        }\n        builder\n    }\n}""}","{""commented_code"": ""fn open<R: Read>(&self, reader: R) -> Result<csv::Reader<R>> { // Open a CSV reader with the configured options\n    Ok(self.builder().build(reader)?)\n}""}",comment_generation
datafusion-datasource-csv,"{""code"": ""pub fn with_has_header(mut self, has_header: bool) -> Self {\n    self.options.has_header = Some(has_header);\n    self\n}"", ""code_context"": ""use datafusion_common::config::CsvOptions;\n\n#[derive(Default, Clone)]\npub struct CsvOptions {\n    pub has_header: Option<bool>,\n    // other fields omitted for brevity\n}\n\n#[derive(Debug, Default)]\npub struct CsvFormat {\n    options: CsvOptions,\n}\n\nimpl CsvFormat {\n    pub fn with_has_header(mut self, has_header: bool) -> Self {\n        self.options.has_header = Some(has_header);\n        self\n    }\n}""}","{""commented_code"": ""pub fn with_has_header(mut self, has_header: bool) -> Self { // Specify whether CSV files include a header row\n    self.options.has_header = Some(has_header);\n    self\n}""}",comment_generation
slab,"{""code"": ""impl<T> Slab<T> {\n    pub const fn new() -> Self {\n        Self {\n            entries: Vec::new(),\n            next: 0,\n            len: 0,\n        }\n    }\n}"", ""code_context"": ""pub struct Slab<T> {\n    entries: Vec<Entry<T>>,\n    len: usize,\n    next: usize,\n}\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}""}","{""docstring"": ""Construct a new, empty `Slab`.\n\nThe function does not allocate and the returned slab will have no capacity until `insert` is called or capacity is explicitly reserved.\n\n# Examples\n\n```rust\n# use slab::*;\nlet slab: Slab<i32> = Slab::new();\n```""}",docstring_generation
slab,"{""code"": ""impl<T> Slab<T> {\n    pub fn with_capacity(capacity: usize) -> Slab<T> {\n        Slab {\n            entries: Vec::with_capacity(capacity),\n            next: 0,\n            len: 0,\n        }\n    }\n}"", ""code_context"": ""pub struct Slab<T> {\n    entries: Vec<Entry<T>>,\n    len: usize,\n    next: usize,\n}\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}""}","{""docstring"": ""Construct a new, empty `Slab` with the specified capacity.\n\nThe returned slab will be able to store exactly `capacity` without allocating. If `capacity` is 0, the slab will not allocate.\n\nIt is important to note that this function does not specify the *length* of the returned slab, but only the capacity. For an explanation of the difference between length and capacity, see [Capacity and reallocation](index.html#capacity-and-reallocation).""}",docstring_generation
slab,"{""code"": ""impl<'a, T> VacantEntry<'a, T> {\n    pub fn insert(self, val: T) -> &'a mut T {\n        self.slab.insert_at(self.key, val);\n\n        match self.slab.entries.get_mut(self.key) {\n            Some(&mut Entry::Occupied(ref mut v)) => v,\n            _ => unreachable!(),\n        }\n    }\n}"", ""code_context"": ""pub struct VacantEntry<'a, T> {\n    slab: &'a mut Slab<T>,\n    key: usize,\n}\n\npub struct Slab<T> {\n    entries: Vec<Entry<T>>,\n    len: usize,\n    next: usize,\n}\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}""}","{""docstring"": ""Insert a value in the entry, returning a mutable reference to the value.\n\nTo get the key associated with the value, use `key` prior to calling `insert`.\n\n# Examples\n\n```rust\n# use slab::*;\nlet mut slab = Slab::new();\n\nlet hello = {\n    let entry = slab.vacant_entry();\n    let key = entry.key();\n\n    entry.insert((key, \""hello\""));\n    key\n};\n\nassert_eq!(hello, slab[hello].0);\nassert_eq!(\""hello\"", slab[hello].1);\n```""}",docstring_generation
ansi_term,"{""code"": ""impl Style {\n    fn write_prefix<W: AnyWrite + ?Sized>(&self, f: &mut W) -> Result<(), W::Error> {\n        if self.is_plain() {\n            return Ok(());\n        }\n        write!(f, \""\\x1B[\"")?;\n        let mut written_anything = false;\n        {\n            let mut write_char = |c| {\n                if written_anything { write!(f, \"";\"")?; }\n                written_anything = true;\n                write!(f, \""{}\"", c)?;\n                Ok(())\n            };\n            if self.is_bold { write_char('1')?; }\n            if self.is_dimmed { write_char('2')?; }\n            if self.is_italic { write_char('3')?; }\n            if self.is_underline { write_char('4')?; }\n            if self.is_blink { write_char('5')?; }\n            if self.is_reverse { write_char('7')?; }\n            if self.is_hidden { write_char('8')?; }\n            if self.is_strikethrough { write_char('9')?; }\n        }\n        if let Some(bg) = self.background {\n            if written_anything { write!(f, \"";\"")?; }\n            written_anything = true;\n            bg.write_background_code(f)?;\n        }\n        if let Some(fg) = self.foreground {\n            if written_anything { write!(f, \"";\"")?; }\n            written_anything = true;\n            fg.write_foreground_code(f)?;\n        }\n        write!(f, \""m\"")?;\n        Ok(())\n    }\n}"", ""code_context"": ""use std::fmt;\nuse crate::write::AnyWrite;\n\n#[derive(PartialEq, Clone, Copy)]\npub struct Style {\n    pub foreground: Option<Colour>,\n    pub background: Option<Colour>,\n    pub is_bold: bool,\n    pub is_dimmed: bool,\n    pub is_italic: bool,\n    pub is_underline: bool,\n    pub is_blink: bool,\n    pub is_reverse: bool,\n    pub is_hidden: bool,\n    pub is_strikethrough: bool,\n}\n\nimpl Default for Style {\n    fn default() -> Style {\n        Style {\n            foreground: None,\n            background: None,\n            is_bold: false,\n            is_dimmed: false,\n            is_italic: false,\n            is_underline: false,\n            is_blink: false,\n            is_reverse: false,\n            is_hidden: false,\n            is_strikethrough: false,\n        }\n    }\n}\n\nimpl Style {\n    pub fn is_plain(self) -> bool { self == Style::default() }\n}\n\nenum Colour {\n    Black,\n    Red,\n    Green,\n    Yellow,\n    Blue,\n    Purple,\n    Cyan,\n    White,\n    Fixed(u8),\n    RGB(u8, u8, u8),\n}\n\nimpl Colour {\n    fn write_foreground_code<W: AnyWrite + ?Sized>(&self, f: &mut W) -> Result<(), W::Error> { Ok(()) }\n    fn write_background_code<W: AnyWrite + ?Sized>(&self, f: &mut W) -> Result<(), W::Error> { Ok(()) }\n}""}","{""explanation"": ""The `write_prefix` method builds the ANSI escape sequence that must be written before a styled piece of text. It first checks if the style is empty and returns early. Then it writes the ESC[`\\x1B[` prefix, appends style codes (bold, dimmed, etc.) separated by semicolons, adds background and foreground colour codes if present, finishes with an `m`, and returns the result.""}",code_explanation
ansi_term,"{""code"": ""impl Colour {\n    fn write_foreground_code<W: AnyWrite + ?Sized>(&self, f: &mut W) -> Result<(), W::Error> {\n        match *self {\n            Colour::Black      => write!(f, \""30\""),\n            Colour::Red        => write!(f, \""31\""),\n            Colour::Green      => write!(f, \""32\""),\n            Colour::Yellow     => write!(f, \""33\""),\n            Colour::Blue       => write!(f, \""34\""),\n            Colour::Purple     => write!(f, \""35\""),\n            Colour::Cyan       => write!(f, \""36\""),\n            Colour::White      => write!(f, \""37\""),\n            Colour::Fixed(num) => write!(f, \""38;5;{}\"", num),\n            Colour::RGB(r,g,b) => write!(f, \""38;2;{};{};{}\"", r, g, b),\n        }\n    }\n}"", ""code_context"": ""use crate::write::AnyWrite;\n\nenum Colour {\n    Black,\n    Red,\n    Green,\n    Yellow,\n    Blue,\n    Purple,\n    Cyan,\n    White,\n    Fixed(u8),\n    RGB(u8, u8, u8),\n}""}","{""explanation"": ""`write_foreground_code` converts a `Colour` variant into the numeric ANSI code for setting the foreground colour. Simple colours map to codes 30‑37, a 256‑colour index uses the `38;5;<n>` format, and a true‑color RGB value uses `38;2;<r>;<g>;<b>`.""}",code_explanation
ansi_term,"{""code"": ""impl Difference {\n    fn between(first: &Style, next: &Style) -> Difference {\n        use self::Difference::*;\n        if first == next { return NoDifference; }\n        if first.is_bold && !next.is_bold { return Reset; }\n        if first.is_dimmed && !next.is_dimmed { return Reset; }\n        if first.is_italic && !next.is_italic { return Reset; }\n        if first.is_underline && !next.is_underline { return Reset; }\n        if first.is_blink && !next.is_blink { return Reset; }\n        if first.is_reverse && !next.is_reverse { return Reset; }\n        if first.is_hidden && !next.is_hidden { return Reset; }\n        if first.is_strikethrough && !next.is_strikethrough { return Reset; }\n        if first.foreground.is_some() && next.foreground.is_none() { return Reset; }\n        if first.background.is_some() && next.background.is_none() { return Reset; }\n        let mut extra = Style::default();\n        if first.is_bold != next.is_bold { extra.is_bold = true; }\n        if first.is_dimmed != next.is_dimmed { extra.is_dimmed = true; }\n        if first.is_italic != next.is_italic { extra.is_italic = true; }\n        if first.is_underline != next.is_underline { extra.is_underline = true; }\n        if first.is_blink != next.is_blink { extra.is_blink = true; }\n        if first.is_reverse != next.is_reverse { extra.is_reverse = true; }\n        if first.is_hidden != next.is_hidden { extra.is_hidden = true; }\n        if first.is_strikethrough != next.is_strikethrough { extra.is_strikethrough = true; }\n        if first.foreground != next.foreground { extra.foreground = next.foreground; }\n        if first.background != next.background { extra.background = next.background; }\n        ExtraStyles(extra)\n    }\n}"", ""code_context"": ""use crate::style::Style;\n\nenum Difference {\n    ExtraStyles(Style),\n    Reset,\n    NoDifference,\n}\n\nimpl Default for Difference {\n    fn default() -> Self { Difference::NoDifference }\n}\n""}","{""explanation"": ""`Difference::between` determines how to transition from one `Style` to another. If the styles are identical it returns `NoDifference`. If a property would need to be removed (e.g., bold turned off) it returns `Reset`. Otherwise it builds a new `Style` containing only the properties that differ and returns `ExtraStyles` with that style.""}",code_explanation
strsim,"{""code"": ""pub fn hamming(a: &str, b: &str) -> HammingResult {\n    generic_hamming(a.chars(), b.chars())\n}"", ""code_context"": ""pub fn generic_hamming<Iter1, Iter2, Elem1, Elem2>(a: Iter1, b: Iter2) -> HammingResult\nwhere\n    Iter1: IntoIterator<Item = Elem1>,\n    Iter2: IntoIterator<Item = Elem2>,\n    Elem1: PartialEq<Elem2>,\n{\n    let (mut ita, mut itb) = (a.into_iter(), b.into_iter());\n    let mut count = 0;\n    loop {\n        match (ita.next(), itb.next()) {\n            (Some(x), Some(y)) => {\n                if x != y {\n                    count += 1;\n                }\n            }\n            (None, None) => return Ok(count),\n            _ => return Err(StrSimError::DifferentLengthArgs),\n        }\n    }\n}\n\n#[derive(Debug, PartialEq)]\npub enum StrSimError {\n    DifferentLengthArgs,\n}\n\nimpl std::fmt::Display for StrSimError {\n    fn fmt(&self, fmt: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let text = match self {\n            StrSimError::DifferentLengthArgs => \""Differing length arguments provided\"",\n        };\n        write!(fmt, \""{}\"", text)\n    }\n}\n\nimpl std::error::Error for StrSimError {}\n\npub type HammingResult = Result<usize, StrSimError>;""}","{""docstring"": ""Calculates the number of positions in the two strings where the characters differ. Returns an error if the strings have different lengths.""}",docstring_generation
strsim,"{""code"": ""pub fn jaro(a: &str, b: &str) -> f64 {\n    let a_len = a.chars().count();\n    let b_len = b.chars().count();\n\n    if a_len == 0 && b_len == 0 {\n        return 1.0;\n    } else if a_len == 0 || b_len == 0 {\n        return 0.0;\n    }\n\n    let mut search_range = max(a_len, b_len) / 2;\n    search_range = search_range.saturating_sub(1);\n\n    // combine memory allocations to reduce runtime\n    let mut flags_memory = vec![false; a_len + b_len];\n    let (a_flags, b_flags) = flags_memory.split_at_mut(a_len);\n\n    let mut matches = 0;\n\n    for (i, a_char) in a.chars().enumerate() {\n        let min_bound = if i > search_range { i - search_range } else { 0 };\n        let max_bound = min(b_len, i + search_range + 1);\n\n        for (j, b_char) in b.chars().enumerate().take(max_bound) {\n            if min_bound <= j && a_char == b_char && !b_flags[j] {\n                a_flags[i] = true;\n                b_flags[j] = true;\n                matches += 1;\n                break;\n            }\n        }\n    }\n\n    let mut transpositions = 0;\n    if matches != 0 {\n        let mut b_iter = b_flags.iter().zip(b);\n        for (a_flag, ch1) in a_flags.iter().zip(a) {\n            if *a_flag {\n                loop {\n                    if let Some((b_flag, ch2)) = b_iter.next() {\n                        if !*b_flag {\n                            continue;\n                        }\n                        if ch1 != ch2 {\n                            transpositions += 1;\n                        }\n                        break;\n                    }\n                }\n            }\n        }\n    }\n    transpositions /= 2;\n\n    if matches == 0 {\n        0.0\n    } else {\n        ((matches as f64 / a_len as f64)\n            + (matches as f64 / b_len as f64)\n            + ((matches - transpositions) as f64 / matches as f64))\n            / 3.0\n    }\n}"", ""code_context"": ""use std::cmp::{max, min};\n\n#[derive(Debug, PartialEq)]\npub enum StrSimError {\n    DifferentLengthArgs,\n}\n\nimpl std::fmt::Display for StrSimError {\n    fn fmt(&self, fmt: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let text = match self {\n            StrSimError::DifferentLengthArgs => \""Differing length arguments provided\"",\n        };\n        write!(fmt, \""{}\"", text)\n    }\n}\n\nimpl std::error::Error for StrSimError {}\n\npub type HammingResult = Result<usize, StrSimError>;""}","{""docstring"": ""Calculates the Jaro similarity between two sequences. The returned value is between 0.0 and 1.0 (higher value means more similar).""}",docstring_generation
strsim,"{""code"": ""pub fn sorensen_dice(a: &str, b: &str) -> f64 {\n    let a: String = a.chars().filter(|&x| !char::is_whitespace(x)).collect();\n    let b: String = b.chars().filter(|&x| !char::is_whitespace(x)).collect();\n\n    if a == b {\n        return 1.0;\n    }\n\n    if a.len() < 2 || b.len() < 2 {\n        return 0.0;\n    }\n\n    let mut a_bigrams: HashMap<(char, char), usize> = HashMap::new();\n\n    for bigram in bigrams(&a) {\n        *a_bigrams.entry(bigram).or_insert(0) += 1;\n    }\n\n    let mut intersection_size = 0_usize;\n\n    for bigram in bigrams(&b) {\n        a_bigrams.entry(bigram).and_modify(|bi| {\n            if *bi > 0 {\n                *bi -= 1;\n                intersection_size += 1;\n            }\n        });\n    }\n\n    (2 * intersection_size) as f64 / (a.len() + b.len() - 2) as f64\n}"", ""code_context"": ""use std::collections::HashMap;\n\nfn bigrams(s: &str) -> impl Iterator<Item = (char, char)> + '_ {\n    s.chars().zip(s.chars().skip(1))\n}""}","{""docstring"": ""Calculates a Sørensen-Dice similarity distance using bigrams. See https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient.""}",docstring_generation
alloc-no-stdlib,"{""code"": ""fn __placeholder__(slice: &mut [u8]) { slice.iter_mut().for_each(|x| *x = 0); }"", ""code_context"": null}","{""function_name"": ""bzero_slice""}",function_naming
alloc-no-stdlib,"{""code"": ""fn __placeholder__(buffer: &mut [u8], size: usize) -> &mut [u8] { let slice = &mut buffer[..size]; bzero(slice); slice }"", ""code_context"": ""pub fn bzero<T: Default>(data: &mut [T]) { for iter in data.iter_mut() { *iter = T::default(); } }""}","{""function_name"": ""allocate_and_zero""}",function_naming
alloc-no-stdlib,"{""code"": ""fn __placeholder__(size: usize) -> CallocBackingStore<'static, u8> { unsafe { CallocBackingStore::new(size, AllocatorC::Calloc(calloc), free, true) } }"", ""code_context"": ""pub struct CallocBackingStore<'a, T: 'a> { pub raw_data: *mut u8, pub data: &'a mut [T], free: unsafe extern \""C\"" fn(*mut u8) }\npub enum AllocatorC { Calloc(unsafe extern \""C\"" fn(usize, usize) -> *mut u8), Malloc(unsafe extern \""C\"" fn(usize) -> *mut u8), Custom(fn(usize) -> *mut u8) }\nextern \""C\"" { fn calloc(n_elem: usize, el_size: usize) -> *mut u8; fn free(item: *mut u8); }""}","{""function_name"": ""create_calloc_buffer""}",function_naming
async-stream,"{""title"": ""Generate a Stream of Even Numbers"", ""description"": ""A developer needs a stream that yields all even numbers from 0 up to a given limit. The stream should be usable with async iteration."", ""code_context"": ""use async_stream::stream;\nuse futures_core::stream::Stream;""}","{""code"": ""fn even_numbers(limit: u32) -> impl Stream<Item = u32> {\n    stream! {\n        for i in 0..=limit {\n            if i % 2 == 0 {\n                yield i;\n            }\n        }\n    }\n}""}",code_generation
async-stream,"{""title"": ""Filter and Transform Incoming TCP Connections"", ""description"": ""A developer is building a TCP server that should only accept connections from allowed IP addresses and then wrap each accepted socket into a higher‑level protocol handler. The filtering and construction are asynchronous, so an async stream is appropriate."", ""code_context"": ""use async_stream::stream;\nuse futures_core::stream::Stream;\nuse tokio::net::TcpListener;\nuse std::io;\n\nstruct MyProtocolHandler(tokio::net::TcpStream);\n\nimpl MyProtocolHandler {\n    async fn new(socket: tokio::net::TcpStream) -> Result<Self, io::Error> {\n        Ok(MyProtocolHandler(socket))\n    }\n}\n\nfn is_allowed(_addr: &std::net::SocketAddr) -> bool {\n    true\n}""}","{""code"": ""async fn accepted_handlers(listener: TcpListener) -> impl Stream<Item = Result<MyProtocolHandler, std::io::Error>> {\n    stream! {\n        while let Ok((socket, _)) = listener.accept().await {\n            if is_allowed(&socket.peer_addr()?) {\n                let handler = MyProtocolHandler::new(socket).await?;\n                yield Ok(handler);\n            }\n        }\n    }\n}""}",code_generation
async-stream,"{""title"": ""Rate‑Limited Stream Wrapper"", ""description"": ""A developer wants to limit how fast items are emitted from an existing stream, emitting at most one item per specified interval."", ""code_context"": ""use async_stream::stream;\nuse futures_core::stream::Stream;\nuse futures_util::stream::StreamExt;\nuse tokio::time;""}","{""code"": ""fn rate_limited<S, T>(mut stream: S, interval: std::time::Duration) -> impl Stream<Item = T>\nwhere\n    S: Stream<Item = T> + Unpin,\n{\n    stream! {\n        let mut ticker = tokio::time::interval(interval);\n        loop {\n            ticker.tick().await;\n            if let Some(item) = stream.next().await {\n                yield item;\n            } else {\n                break;\n            }\n        }\n    }\n}""}",code_generation
async-stream,"{""title"": ""Sequentially Merge Two Streams"", ""description"": ""A developer has two streams producing the same item type and wants a new stream that yields all items from the first stream followed by all items from the second stream."", ""code_context"": ""use async_stream::stream;\nuse futures_core::stream::Stream;\nuse futures_util::stream::StreamExt;""}","{""code"": ""fn concat_streams<S1, S2, T>(s1: S1, s2: S2) -> impl Stream<Item = T>\nwhere\n    S1: Stream<Item = T> + Unpin,\n    S2: Stream<Item = T> + Unpin,\n{\n    stream! {\n        let mut s1 = s1;\n        let mut s2 = s2;\n        while let Some(item) = s1.next().await {\n            yield item;\n        }\n        while let Some(item) = s2.next().await {\n            yield item;\n        }\n    }\n}""}",code_generation
alloc-stdlib,"{""code"": ""pub struct HeapAlloc<T: Clone + Default> {\n    pub default_value: T,\n}\n\nimpl<T: Clone> HeapAlloc<T> {\n    pub fn new(data: T) -> HeapAlloc<T> {\n        HeapAlloc { default_value: data }\n    }\n}\n\nimpl<T: Clone + Default> super::Allocator<T> for HeapAlloc<T> {\n    type AllocatedMemory = WrapBox<T>;\n    fn alloc_cell(&mut self, len: usize) -> WrapBox<T> {\n        let v = vec![self.default_value.clone(); len];\n        WrapBox(v.into_boxed_slice())\n    }\n    fn free_cell(&mut self, _data: WrapBox<T>) {}\n}\n\n#[deprecated]\npub type HeapAllocUninitialized<T> = HeapAlloc<T>;"", ""code_context"": ""use std::ops::Range;\n\npub struct WrapBox<T>(std::boxed::Box<[T]>);\n\nimpl<T> From<Vec<T>> for WrapBox<T> {\n    fn from(data: Vec<T>) -> Self { WrapBox(data.into_boxed_slice()) }\n}\n\nimpl<T> Into<Box<[T]>> for WrapBox<T> {\n    fn into(self) -> Box<[T]> { self.0 }\n}\n\nimpl<T> Default for WrapBox<T> {\n    fn default() -> Self {\n        let v: Vec<T> = Vec::new();\n        WrapBox(v.into_boxed_slice())\n    }\n}\n\nimpl<T> super::SliceWrapper<T> for WrapBox<T> {\n    fn slice(&self) -> &[T] { &*self.0 }\n}\n\nimpl<T> super::SliceWrapperMut<T> for WrapBox<T> {\n    fn slice_mut(&mut self) -> &mut [T] { &mut *self.0 }\n}\n\npub trait Allocator<T> {\n    type AllocatedMemory;\n    fn alloc_cell(&mut self, len: usize) -> Self::AllocatedMemory;\n    fn free_cell(&mut self, data: Self::AllocatedMemory);\n}\n\npub trait SliceWrapper<T> {\n    fn slice(&self) -> &[T];\n}\n\npub trait SliceWrapperMut<T>: SliceWrapper<T> {\n    fn slice_mut(&mut self) -> &mut [T];\n}""}","{""summary"": ""A heap‑allocating allocator that creates a boxed slice filled with cloned default values.""}",code_summarization
alloc-stdlib,"{""code"": ""pub struct AllocatedStackMemory<'a, T: 'a> {\n    pub mem: &'a mut [T],\n}\n\ndefine_index_ops_mut!(a, T, AllocatedStackMemory<'a, T>);\n\nimpl<'a, T: 'a> core::default::Default for AllocatedStackMemory<'a, T> {\n    fn default() -> Self {\n        AllocatedStackMemory { mem: &mut [] }\n    }\n}\n\nimpl<'a, T: 'a> SliceWrapper<T> for AllocatedStackMemory<'a, T> {\n    fn slice(&self) -> &[T] {\n        &self.mem\n    }\n}\n\nimpl<'a, T: 'a> SliceWrapperMut<T> for AllocatedStackMemory<'a, T> {\n    fn slice_mut(&mut self) -> &mut [T] {\n        &mut self.mem\n    }\n}"", ""code_context"": ""macro_rules! define_index_ops_mut {\n    ($T:ident, $MemoryType:ty) => {\n        impl<$T> ::core::ops::Index<usize> for $MemoryType {\n            type Output = T;\n            #[inline]\n            fn index(&self, index: usize) -> &Self::Output {\n                ::core::ops::Index::index(&**self, index)\n            }\n        }\n        impl<$T> ::core::ops::IndexMut<usize> for $MemoryType {\n            #[inline]\n            fn index_mut(&mut self, index: usize) -> &mut Self::Output {\n                ::core::ops::IndexMut::index_mut(&mut **self, index)\n            }\n        }\n        impl<$T> ::core::ops::Index<::core::ops::Range<usize>> for $MemoryType {\n            type Output = [T];\n            #[inline]\n            fn index(&self, index: ::core::ops::Range<usize>) -> &Self::Output {\n                ::core::ops::Index::index(&**self, index)\n            }\n        }\n        impl<$T> ::core::ops::IndexMut<::core::ops::Range<usize>> for $MemoryType {\n            #[inline]\n            fn index_mut(&mut self, index: ::core::ops::Range<usize>) -> &mut Self::Output {\n                ::core::ops::IndexMut::index_mut(&mut **self, index)\n            }\n        }\n        impl<$T> ::core::ops::Deref for $MemoryType {\n            type Target = [T];\n            fn deref(&self) -> &[T] { self.slice() }\n        }\n        impl<$T> ::core::ops::DerefMut for $MemoryType {\n            fn deref_mut(&mut self) -> &mut [T] { self.slice_mut() }\n        }\n    };\n    ($T0:ident, $T:ident, $MemoryType:ty) => {\n        impl<'a, $T> ::core::ops::Index<usize> for $MemoryType {\n            type Output = T;\n            #[inline]\n            fn index(&self, index: usize) -> &Self::Output {\n                ::core::ops::Index::index(&**self, index)\n            }\n        }\n        impl<'a, $T> ::core::ops::IndexMut<usize> for $MemoryType {\n            #[inline]\n            fn index_mut(&mut self, index: usize) -> &mut Self::Output {\n                ::core::ops::IndexMut::index_mut(&mut **self, index)\n            }\n        }\n        impl<'a, $T> ::core::ops::Index<::core::ops::Range<usize>> for $MemoryType {\n            type Output = [T];\n            #[inline]\n            fn index(&self, index: ::core::ops::Range<usize>) -> &Self::Output {\n                ::core::ops::Index::index(&**self, index)\n            }\n        }\n        impl<'a, $T> ::core::ops::IndexMut<::core::ops::Range<usize>> for $MemoryType {\n            #[inline]\n            fn index_mut(&mut self, index: ::core::ops::Range<usize>) -> &mut Self::Output {\n                ::core::ops::IndexMut::index_mut(&mut **self, index)\n            }\n        }\n        impl<'a, $T> ::core::ops::Deref for $MemoryType {\n            type Target = [T];\n            fn deref(&self) -> &[T] { self.slice() }\n        }\n        impl<'a, $T> ::core::ops::DerefMut for $MemoryType {\n            fn deref_mut(&mut self) -> &mut [T] { self.slice_mut() }\n        }\n    };\n}\n\npub trait SliceWrapper<T> {\n    fn slice(&self) -> &[T];\n}\n\npub trait SliceWrapperMut<T>: SliceWrapper<T> {\n    fn slice_mut(&mut self) -> &mut [T];\n}""}","{""summary"": ""A wrapper providing mutable slice access to a stack‑allocated memory region.""}",code_summarization
alloc-stdlib,"{""code"": ""pub struct StackAllocator<'a, T: 'a, U: allocated_memory::AllocatedSlice<&'a mut [T]>> {\n    pub nop: &'a mut [T],\n    pub system_resources: U,\n    pub free_list_start: usize,\n    pub free_list_overflow_count: usize,\n    pub initialize: fn(&mut [T]),\n}\n\nimpl<'a, T: 'a, U: allocated_memory::AllocatedSlice<&'a mut [T]>> StackAllocator<'a, T, U> {\n    fn clear_if_necessary(&self, index: usize, data: AllocatedStackMemory<'a, T>) -> AllocatedStackMemory<'a, T> {\n        if index + 1 != self.system_resources.slice().len() {\n            let init = self.initialize;\n            init(data.mem);\n        }\n        data\n    }\n}\n\nimpl<'a, T: 'a, U: allocated_memory::AllocatedSlice<&'a mut [T]>> Allocator<T> for StackAllocator<'a, T, U> {\n    type AllocatedMemory = AllocatedStackMemory<'a, T>;\n    fn alloc_cell(&mut self, len: usize) -> AllocatedStackMemory<'a, T> {\n        if len == 0 {\n            return AllocatedStackMemory::default();\n        }\n        let mut index = self.free_list_start;\n        let mut found = false;\n        for free in self.system_resources.slice()[self.free_list_start..].iter() {\n            if free.len() >= len {\n                found = true;\n                break;\n            }\n            index += 1;\n        }\n        if !found {\n            panic!(\""OOM\"");\n        }\n        let available = core::mem::replace(&mut self.system_resources.slice_mut()[index], &mut []);\n        if available.len() == len || (available.len() < len + 32 && index + 1 != self.system_resources.slice().len()) {\n            if index != self.free_list_start {\n                let far = core::mem::replace(&mut self.system_resources.slice_mut()[self.free_list_start], &mut []);\n                let _ = core::mem::replace(&mut self.system_resources.slice_mut()[index], far);\n            }\n            self.free_list_start += 1;\n            return self.clear_if_necessary(index, AllocatedStackMemory::default());\n        } else {\n            let (head, tail) = available.split_at_mut(len);\n            let _ = core::mem::replace(&mut self.system_resources.slice_mut()[index], tail);\n            return self.clear_if_necessary(index, AllocatedStackMemory { mem: head });\n        }\n    }\n    fn free_cell(&mut self, val: AllocatedStackMemory<'a, T>) {\n        if val.slice().len() == 0 {\n            return;\n        }\n        if self.free_list_start > 0 {\n            self.free_list_start -= 1;\n            let _ = core::mem::replace(&mut self.system_resources.slice_mut()[self.free_list_start], val.mem);\n        } else {\n            for _ in 0..3 {\n                self.free_list_overflow_count = (self.free_list_overflow_count + 1) % self.system_resources.slice().len();\n                if self.system_resources.slice()[self.free_list_overflow_count].len() < val.mem.len() {\n                    let _ = core::mem::replace(&mut self.system_resources.slice_mut()[self.free_list_overflow_count], val.mem);\n                    return;\n                }\n            }\n        }\n    }\n}"", ""code_context"": ""pub struct AllocatedStackMemory<'a, T: 'a> {\n    pub mem: &'a mut [T],\n}\n\ndefine_index_ops_mut!(a, T, AllocatedStackMemory<'a, T>);\n\nimpl<'a, T: 'a> core::default::Default for AllocatedStackMemory<'a, T> {\n    fn default() -> Self { AllocatedStackMemory { mem: &mut [] } }\n}\n\npub trait SliceWrapper<T> {\n    fn slice(&self) -> &[T];\n}\n\npub trait SliceWrapperMut<T>: SliceWrapper<T> {\n    fn slice_mut(&mut self) -> &mut [T];\n}\n\npub trait Allocator<T> {\n    type AllocatedMemory;\n    fn alloc_cell(&mut self, len: usize) -> Self::AllocatedMemory;\n    fn free_cell(&mut self, data: Self::AllocatedMemory);\n}\n\nmod allocated_memory {\n    pub trait AllocatedSlice<T> {}\n    impl<T, U> AllocatedSlice<T> for U where U: super::SliceWrapperMut<T> + super::SliceWrapper<T> + Default {}\n}\n\nmacro_rules! define_index_ops_mut {\n    ($T:ident, $MemoryType:ty) => {\n        impl<$T> ::core::ops::Index<usize> for $MemoryType {\n            type Output = T;\n            #[inline]\n            fn index(&self, index: usize) -> &Self::Output {\n                ::core::ops::Index::index(&**self, index)\n            }\n        }\n        impl<$T> ::core::ops::IndexMut<usize> for $MemoryType {\n            #[inline]\n            fn index_mut(&mut self, index: usize) -> &mut Self::Output {\n                ::core::ops::IndexMut::index_mut(&mut **self, index)\n            }\n        }\n        impl<$T> ::core::ops::Index<::core::ops::Range<usize>> for $MemoryType {\n            type Output = [T];\n            #[inline]\n            fn index(&self, index: ::core::ops::Range<usize>) -> &Self::Output {\n                ::core::ops::Index::index(&**self, index)\n            }\n        }\n        impl<$T> ::core::ops::IndexMut<::core::ops::Range<usize>> for $MemoryType {\n            #[inline]\n            fn index_mut(&mut self, index: ::core::ops::Range<usize>) -> &mut Self::Output {\n                ::core::ops::IndexMut::index_mut(&mut **self, index)\n            }\n        }\n        impl<$T> ::core::ops::Deref for $MemoryType {\n            type Target = [T];\n            fn deref(&self) -> &[T] { self.slice() }\n        }\n        impl<$T> ::core::ops::DerefMut for $MemoryType {\n            fn deref_mut(&mut self) -> &mut [T] { self.slice_mut() }\n        }\n    };\n}\n""}","{""summary"": ""A stack‑based allocator that manages free lists, allocates slices, and handles overflow when freeing memory.""}",code_summarization
async-stream,"{""code"": ""macro_rules! stream {\n    ($($tt:tt)*) => {\n        $crate::__private::stream_inner!(($crate) $($tt)*)\n    };\n}"", ""code_context"": null}","{""docstring"": ""Asynchronous stream. See crate documentation for more details. Example: use async_stream::stream; use futures_util::pin_mut; use futures_util::stream::StreamExt; #[tokio::main] async fn main() { let s = stream! { for i in 0..3 { yield i; } }; pin_mut!(s); while let Some(value) = s.next().await { println!(\""got {}\"", value); } }""}",docstring_generation
async-stream,"{""code"": ""macro_rules! try_stream {\n    ($($tt:tt)*) => {\n        $crate::__private::try_stream_inner!(($crate) $($tt)*)\n    };\n}"", ""code_context"": null}","{""docstring"": ""Asynchronous fallible stream. See crate documentation for more details. Example: use tokio::net::{TcpListener, TcpStream}; use async_stream::try_stream; use futures_core::stream::Stream; use std::io; use std::net::SocketAddr; fn bind_and_accept(addr: SocketAddr) -> impl Stream<Item = io::Result<TcpStream>> { try_stream! { let mut listener = TcpListener::bind(addr).await?; loop { let (stream, addr) = listener.accept().await?; println!(\""received on {:?}\"", addr); yield stream; } } }""}",docstring_generation
async-stream,"{""code"": ""impl<T, U> FusedStream for AsyncStream<T, U>\nwhere\n    U: Future<Output = ()>,\n{\n    fn is_terminated(&self) -> bool {\n        self.done\n    }\n}"", ""code_context"": ""pin_project! {\n    #[doc(hidden)]\n    #[derive(Debug)]\n    pub struct AsyncStream<T, U> {\n        rx: Receiver<T>,\n        done: bool,\n        #[pin]\n        generator: U,\n    }\n}""}","{""docstring"": ""Checks if the stream has been terminated.""}",docstring_generation
async-stream-impl,"{""title"": ""Merge two streams preserving order"", ""description"": ""A developer wants to combine two asynchronous streams into a single stream that yields all items from the first stream followed by all items from the second stream. The helper should work with any stream types that implement the `Stream` trait."", ""code_context"": ""use async_stream::stream;\nuse futures_core::stream::Stream;\nuse futures_util::stream::StreamExt;""}","{""code"": ""fn merge_streams<S1, S2, T>(s1: S1, s2: S2) -> impl Stream<Item = T>\nwhere\n    S1: Stream<Item = T>,\n    S2: Stream<Item = T>,\n{\n    stream! {\n        for await value in s1 {\n            yield value;\n        }\n        for await value in s2 {\n            yield value;\n        }\n    }\n}""}",code_generation
async-stream-impl,"{""title"": ""Filter even numbers from a stream"", ""description"": ""A developer needs a utility that takes a stream of `u32` values and yields only the even numbers, preserving the asynchronous nature of the original stream."", ""code_context"": ""use async_stream::stream;\nuse futures_core::stream::Stream;\nuse futures_util::stream::StreamExt;""}","{""code"": ""fn filter_even<S>(input: S) -> impl Stream<Item = u32>\nwhere\n    S: Stream<Item = u32>,\n{\n    stream! {\n        for await value in input {\n            if value % 2 == 0 {\n                yield value;\n            }\n        }\n    }\n}""}",code_generation
async-stream-impl,"{""title"": ""Asynchronously map stream items to formatted strings"", ""description"": ""A developer wants to transform each `u32` item from a stream into a `String` representation, simulating an asynchronous operation (e.g., a small delay) for each mapping step."", ""code_context"": ""use async_stream::stream;\nuse futures_core::stream::Stream;\nuse futures_util::stream::StreamExt;\nuse tokio::time::{sleep, Duration};""}","{""code"": ""fn async_map_to_string<S>(input: S) -> impl Stream<Item = String>\nwhere\n    S: Stream<Item = u32>,\n{\n    stream! {\n        for await value in input {\n            sleep(Duration::from_millis(10)).await;\n            yield format!(\""Number {}\"", value);\n        }\n    }\n}""}",code_generation
async-stream-impl,"{""title"": ""Collect an asynchronous stream into a Vec"", ""description"": ""A developer needs an async helper that consumes a stream and returns a `Vec` containing all yielded items. This is useful for testing or when the full collection of results is required."", ""code_context"": ""use futures_util::stream::StreamExt;\nuse futures_core::stream::Stream;""}","{""code"": ""async fn collect_to_vec<S, T>(mut stream: S) -> Vec<T>\nwhere\n    S: Stream<Item = T> + Unpin,\n    T: Unpin,\n{\n    let mut vec = Vec::new();\n    while let Some(item) = stream.next().await {\n        vec.push(item);\n    }\n    vec\n}""}",code_generation
slab,"{""code"": ""let key = slab.vacant_entry().key();"", ""code_context"": ""use slab::Slab;\n\nfn example() {\n    let mut slab = Slab::new();\n}""}","{""commented_code"": ""let key = slab.vacant_entry().key(); // Get the key for the next vacant entry""}",comment_generation
slab,"{""code"": ""if key >= entries_cap { return Err(GetDisjointMutError::IndexOutOfBounds); }"", ""code_context"": ""use slab::GetDisjointMutError;\n\nfn example(key: usize, entries_cap: usize) -> Result<(), GetDisjointMutError> {\n    // snippet will be placed here\n    Ok(())\n}""}","{""commented_code"": ""if key >= entries_cap { return Err(GetDisjointMutError::IndexOutOfBounds); // Key is out of bounds }""}",comment_generation
slab,"{""code"": ""slab.entries[key] = Entry::Occupied(value);"", ""code_context"": ""use std::vec::Vec;\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}\n\nstruct Slab<T> {\n    entries: Vec<Entry<T>>,\n}""}","{""commented_code"": ""slab.entries[key] = Entry::Occupied(value); // Replace existing entry or insert new occupied value""}",comment_generation
slab,"{""code"": ""self.entries.push(Entry::Occupied(value));"", ""code_context"": ""use std::vec::Vec;\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}\n\nstruct Slab<T> {\n    entries: Vec<Entry<T>>,\n}""}","{""commented_code"": ""self.entries.push(Entry::Occupied(value)); // Insert the occupied entry at the end""}",comment_generation
fragile,"{""code"": ""let val = Fragile::new(true);"", ""code_context"": ""pub struct Fragile<T> {\n    value: std::mem::ManuallyDrop<T>,\n    thread_id: std::thread::ThreadId,\n}\n\nimpl<T> Fragile<T> {\n    pub fn new(value: T) -> Self {\n        Fragile {\n            value: std::mem::ManuallyDrop::new(value),\n            thread_id: std::thread::current().id(),\n        }\n    }\n}\n\nimpl<T: std::fmt::Display> std::fmt::Display for Fragile<T> {\n    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {\n        std::fmt::Display::fmt(self.get(), f)\n    }\n}\n""}","{""next_api_call"": ""assert_eq!(val.to_string(), \""true\"");""}",api_usage_prediction
fragile,"{""code"": ""let mut val = Fragile::new(true);"", ""code_context"": ""pub struct Fragile<T> {\n    value: std::mem::ManuallyDrop<T>,\n    thread_id: std::thread::ThreadId,\n}\n\nimpl<T> Fragile<T> {\n    pub fn new(value: T) -> Self {\n        Fragile {\n            value: std::mem::ManuallyDrop::new(value),\n            thread_id: std::thread::current().id(),\n        }\n    }\n\n    pub fn get_mut(&mut self) -> &mut T {\n        self.assert_thread();\n        &mut self.value\n    }\n\n    fn assert_thread(&self) {\n        if std::thread::current().id() != self.thread_id {\n            panic!(\""access from wrong thread\"");\n        }\n    }\n}\n""}","{""next_api_call"": ""*val.get_mut() = false;""}",api_usage_prediction
fragile,"{""code"": ""let val = Sticky::new(true);"", ""code_context"": ""pub struct Sticky<T: 'static> {\n    item_id: crate::registry::ItemId,\n    thread_id: std::thread::ThreadId,\n    _marker: std::marker::PhantomData<*mut T>,\n}\n\nimpl<T> Sticky<T> {\n    pub fn new(value: T) -> Self {\n        let entry = crate::registry::Entry {\n            ptr: std::boxed::Box::into_raw(std::boxed::Box::new(value)).cast(),\n            drop: |ptr| {\n                let ptr = ptr.cast::<T>();\n                unsafe { std::boxed::Box::from_raw(ptr); }\n            },\n        };\n        let thread_id = std::thread::current().id();\n        let item_id = crate::registry::insert(entry);\n        Sticky { item_id, thread_id, _marker: std::marker::PhantomData }\n    }\n}\n\nimpl<T: std::fmt::Display> std::fmt::Display for Sticky<T> {\n    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {\n        // In real code this would retrieve the value via a token;\n        // omitted here for definition-only context.\n        write!(f, \""<value>\"")\n    }\n}\n""}","{""next_api_call"": ""assert_eq!(val.to_string(), \""true\"");""}",api_usage_prediction
integer-encoding,"{""code_before"": ""fn encode_v(b: &mut Bencher) {\n    let my_u64s = [\n        9494929199119074561,\n        3823923198123425321,\n        2595862268225688522,\n        1231230009321245673,\n        2909812083312547546,\n        3492011001874124465,\n        4848848884210156473,\n        4012941340125654654,\n    ] as [u64; 8];\n    let my_i64s = [\n        -122193043711204545,\n        2446312246543212452,\n        -445854216865433664,\n        3242135654513135465,\n        -543122132545464312,\n        3613543123031434343,\n        -431231254654543211,\n        7854615463131234543,\n    ] as [i64; 8];\n\n    let mut dst = [0 as u8; 10];\n\n    b.iter(|| {\n        // 8x each.\n        my_u64s[0].encode_var(&mut dst);\n        my_u64s[1].encode_var(&mut dst);\n        my_u64s[2].encode_var(&mut dst);\n        my_u64s[3].encode_var(&mut dst);\n        my_u64s[4].encode_var(&mut dst);\n        my_u64s[5].encode_var(&mut dst);\n        my_u64s[6].encode_var(&mut dst);\n        my_u64s[7].encode_var(&mut dst);\n\n        my_i64s[0].encode_var(&mut dst);\n        my_i64s[1].encode_var(&mut dst);\n        my_i64s[2].encode_var(&mut dst);\n        my_i64s[3].encode_var(&mut dst);\n        my_i64s[4].encode_var(&mut dst);\n        my_i64s[5].encode_var(&mut dst);\n        my_i64s[6].encode_var(&mut dst);\n        my_i64s[7].encode_var(&mut dst);\n    });\n}"", ""code_context"": ""use integer_encoding::*;""}","{""rationale"": ""Replaces repetitive manual indexing with iterator methods. This reduces boilerplate code while maintaining clarity and improving maintainability, especially if the array sizes change in the future."", ""code_after"": ""fn encode_v(b: &mut Bencher) {\n    let my_u64s = [\n        9494929199119074561,\n        3823923198123425321,\n        2595862268225688522,\n        1231230009321245673,\n        2909812083312547546,\n        3492011001874124465,\n        4848848884210156473,\n        4012941340125654654,\n    ] as [u64; 8];\n    let my_i64s = [\n        -122193043711204545,\n        2446312246543212452,\n        -445854216865433664,\n        3242135654513135465,\n        -543122132545464312,\n        3613543123031434343,\n        -431231254654543211,\n        7854615463131234543,\n    ] as [i64; 8];\n\n    let mut dst = [0 as u8; 10];\n\n    b.iter(|| {\n        // 8x each.\n        my_u64s.iter().for_each(|&u| u.encode_var(&mut dst));\n        my_i64s.iter().for_each(|&i| i.encode_var(&mut dst));\n    });\n}""}",code_refactoring
integer-encoding,"{""code_before"": ""fn encode_f(b: &mut Bencher) {\n    let my_u64 = 94949291991190 as u64;\n    let my_i64 = -12219304371120 as i64;\n\n    let mut dst = [0 as u8; 8];\n\n    b.iter(|| {\n        // 8x each.\n        my_u64.encode_fixed(&mut dst);\n        my_u64.encode_fixed(&mut dst);\n        my_u64.encode_fixed(&mut dst);\n        my_u64.encode_fixed(&mut dst);\n        my_u64.encode_fixed(&mut dst);\n        my_u64.encode_fixed(&mut dst);\n        my_u64.encode_fixed(&mut dst);\n        my_u64.encode_fixed(&mut dst);\n\n        my_i64.encode_fixed(&mut dst);\n        my_i64.encode_fixed(&mut dst);\n        my_i64.encode_fixed(&mut dst);\n        my_i64.encode_fixed(&mut dst);\n        my_i64.encode_fixed(&mut dst);\n        my_i64.encode_fixed(&mut dst);\n        my_i64.encode_fixed(&mut dst);\n        my_i64.encode_fixed(&mut dst);\n    });\n}"", ""code_context"": ""use integer_encoding::*;""}","{""rationale"": ""Replaces repetitive manual calls with loop iterations, reducing code duplication and improving readability by leveraging Rust's iteration capabilities."", ""code_after"": ""fn encode_f(b: &mut Bencher) {\n    let my_u64 = 94949291991190 as u64;\n    let my_i64 = -12219304371120 as i64;\n\n    let mut dst = [0 as u8; 8];\n\n    b.iter(|| {\n        // 8x each.\n        for _ in 0..8 {\n            my_u64.encode_fixed(&mut dst);\n        }\n        for _ in 0..8 {\n            my_i64.encode_fixed(&mut dst);\n        }\n    });\n}""}",code_refactoring
integer-encoding,"{""code_before"": ""fn test_u32_enc() {\n    let result = (32 as u32).encode_fixed_vec();\n    assert_eq!(result, vec![32, 0, 0, 0]);\n}"", ""code_context"": ""use crate::fixed::FixedInt;""}","{""rationale"": ""Improves readability by separating the expected value from the actual result. This makes the test more maintainable and easier to understand at a glance."", ""code_after"": ""fn test_u32_enc() {\n    let expected = vec![32, 0, 0, 0];\n    let actual = (32 as u32).encode_fixed_vec();\n    assert_eq!(actual, expected);\n}""}",code_refactoring
difflib,"{""code"": ""let mut res: Vec<(f32, &str)> = Vec::new();"", ""code_context"": ""pub fn get_close_matches<'a>(word: &str, possibilities: Vec<&'a str>, n: usize, cutoff: f32) -> Vec<&'a str> {\n    if !(0.0 <= cutoff && cutoff <= 1.0) {\n        panic!(\""Cutoff must be greater than 0.0 and lower than 1.0\"");\n    }\n    let mut res: Vec<(f32, &str)> = Vec::new();\n    let mut matcher = SequenceMatcher::new(\""\"", word);\n    for i in &possibilities {\n        matcher.set_first_seq(i);\n        let ratio = matcher.ratio();\n        if ratio >= cutoff {\n            res.push((ratio, i));\n        }\n    }\n    res.sort_by(|a, b| b.0.partial_cmp(&a.0).unwrap());\n    res.truncate(n);\n    res.iter().map(|x| x.1).collect()\n}""}","{""commented_code"": ""let mut res: Vec<(f32, &str)> = Vec::new(); // Initialize a vector to store matches with their similarity scores""}",comment_generation
difflib,"{""code"": ""let mut res = Vec::new();"", ""code_context"": ""pub fn unified_diff<T: Sequence + Display>(first_sequence: &[T], second_sequence: &[T], from_file: &str, to_file: &str, from_file_date: &str, to_file_date: &str, n: usize) -> Vec<String> {\n    let mut res = Vec::new();\n    let lineterm = '\\n';\n    let mut started = false;\n    let mut matcher = SequenceMatcher::new(first_sequence, second_sequence);\n    for group in &matcher.get_grouped_opcodes(n) {\n        if !started {\n            started = true;\n            let from_date = format!(\""\\t{}\"", from_file_date);\n            let to_date = format!(\""\\t{}\"", to_file_date);\n            res.push(format!(\""--- {}{}{}\"", from_file, from_date, lineterm));\n            res.push(format!(\""+++ {}{}{}\"", to_file, to_date, lineterm));\n        }\n        let (first, last) = (group.first().unwrap(), group.last().unwrap());\n        let file1_range = format_range_unified(first.first_start, last.first_end);\n        let file2_range = format_range_unified(first.second_start, last.second_end);\n        res.push(format!(\n            \""@@ -{} +{} @@{}\"",\n            file1_range, file2_range, lineterm\n        ));\n        for code in group {\n            if code.tag == \""equal\"" {\n                for item in first_sequence\n                    .iter()\n                    .take(code.first_end)\n                    .skip(code.first_start)\n                {\n                    res.push(format!(\"" {}\"", item));\n                }\n                continue;\n            }\n            if code.tag == \""replace\"" || code.tag == \""delete\"" {\n                for item in first_sequence\n                    .iter()\n                    .take(code.first_end)\n                    .skip(code.first_start)\n                {\n                    res.push(format!(\""-{}\"", item));\n                }\n            }\n            if code.tag == \""replace\"" || code.tag == \""insert\"" {\n                for item in second_sequence\n                    .iter()\n                    .take(code.second_end)\n                    .skip(code.second_start)\n                {\n                    res.push(format!(\""+{}\"", item));\n                }\n            }\n        }\n    }\n    res\n}""}","{""commented_code"": ""let mut res = Vec::new(); // Initialize a vector to collect the diff lines""}",comment_generation
difflib,"{""code"": ""let (mut best_i, mut best_j, mut best_size) = (first_start, second_start, 0);"", ""code_context"": ""pub fn find_longest_match(\n    &self,\n    first_start: usize,\n    first_end: usize,\n    second_start: usize,\n    second_end: usize,\n) -> Match {\n    let first_sequence = &self.first_sequence;\n    let second_sequence = &self.second_sequence;\n    let second_sequence_elements = &self.second_sequence_elements;\n    let (mut best_i, mut best_j, mut best_size) = (first_start, second_start, 0);\n    let mut j2len: HashMap<usize, usize> = HashMap::new();\n    for (i, item) in first_sequence\n        .iter()\n        .enumerate()\n        .take(first_end)\n        .skip(first_start)\n    {\n        let mut new_j2len: HashMap<usize, usize> = HashMap::new();\n        if let Some(indexes) = second_sequence_elements.get(item) {\n            for j in indexes {\n                let j = *j;\n                if j < second_start {\n                    continue;\n                };\n                if j >= second_end {\n                    break;\n                };\n                let mut size = 0;\n                if j > 0 {\n                    if let Some(k) = j2len.get(&(j - 1)) {\n                        size = *k;\n                    }\n                }\n                size += 1;\n                new_j2len.insert(j, size);\n                if size > best_size {\n                    best_i = i + 1 - size;\n                    best_j = j + 1 - size;\n                    best_size = size;\n                }\n            }\n        }\n        j2len = new_j2len;\n    }\n    // ... remaining logic omitted for brevity\n    Match::new(best_i, best_j, best_size)\n}""}","{""commented_code"": ""let (mut best_i, mut best_j, mut best_size) = (first_start, second_start, 0); // Track the start indices and size of the best matching block found so far""}",comment_generation
difflib,"{""code"": ""res.push(format!(\""{} {}\"", tag, s))"", ""code_context"": ""fn dump(&self, tag: &str, sequence: &[&str], start: usize, end: usize) -> Vec<String> {\n    let mut res = Vec::new();\n    for i in start..end {\n        if let Some(s) = sequence.get(i) {\n            res.push(format!(\""{} {}\"", tag, s))\n        }\n    }\n    res\n}""}","{""commented_code"": ""res.push(format!(\""{} {}\"", tag, s)); // Append a formatted line prefixed with its tag to the result vector""}",comment_generation
difflib,"{""code"": ""let mut s = format!(\""- {}\"", first_line);"", ""code_context"": ""fn qformat(\n    &self,\n    first_line: &str,\n    second_line: &str,\n    first_tags: &str,\n    second_tags: &str,\n) -> Vec<String> {\n    let mut res = Vec::new();\n    let mut first_tags = first_tags;\n    let mut second_tags = second_tags;\n    let mut common = cmp::min(\n        count_leading(first_line, '\\t'),\n        count_leading(second_line, '\\t'),\n    );\n    common = cmp::min(common, count_leading(first_tags.split_at(common).0, ' '));\n    common = cmp::min(common, count_leading(first_tags.split_at(common).0, ' '));\n    first_tags = first_tags.split_at(common).1.trim_right();\n    second_tags = second_tags.split_at(common).1.trim_right();\n    let mut s = format!(\""- {}\"", first_line);\n    res.push(s);\n    if first_tags != \""\"" {\n        s = format!(\""? {}{}\\n\"", str_with_similar_chars('\\t', common), first_tags);\n        res.push(s);\n    }\n    s = format!(\""+ {}\"", second_line);\n    res.push(s);\n    if second_tags != \""\"" {\n        s = format!(\n            \""? {}{}\\n\"",\n            str_with_similar_chars('\\t', common),\n            second_tags\n        );\n        res.push(s);\n    }\n    res\n}""}","{""commented_code"": ""let mut s = format!(\""- {}\"", first_line); // Prefix the first line with a minus sign to indicate deletion""}",comment_generation
fragile,"{""code_context"": ""use std::mem::ManuallyDrop;\nuse std::thread;\nuse std::thread::ThreadId;\nuse crate::errors::InvalidThreadAccess;\n\npub struct Fragile<T> {\n    value: ManuallyDrop<T>,\n    thread_id: ThreadId,\n}"", ""code_to_test"": ""impl<T> Fragile<T> {\n    pub fn new(value: T) -> Self {\n        Fragile {\n            value: ManuallyDrop::new(value),\n            thread_id: thread::current().id(),\n        }\n    }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn test_basic() {\n    use std::thread;\n    let val = Fragile::new(true);\n    assert_eq!(val.to_string(), \""true\"");\n    assert_eq!(val.get(), &true);\n    assert!(val.try_get().is_ok());\n    thread::spawn(move || {\n        assert!(val.try_get().is_err());\n    })\n    .join()\n    .unwrap();\n}"", ""#[test]\nfn test_mut() {\n    let mut val = Fragile::new(true);\n    *val.get_mut() = false;\n    assert_eq!(val.to_string(), \""false\"");\n    assert_eq!(val.get(), &false);\n}"", ""#[test]\n#[should_panic]\nfn test_access_other_thread() {\n    use std::thread;\n    let val = Fragile::new(true);\n    thread::spawn(move || {\n        val.get();\n    })\n    .join()\n    .unwrap();\n}"", ""#[test]\nfn test_rc_sending() {\n    use std::rc::Rc;\n    use std::sync::mpsc::channel;\n    use std::thread;\n\n    let val = Fragile::new(Rc::new(true));\n    let (tx, rx) = channel();\n\n    let thread = thread::spawn(move || {\n        assert!(val.try_get().is_err());\n        let here = val;\n        tx.send(here).unwrap();\n    });\n\n    let rv = rx.recv().unwrap();\n    assert!(**rv.get());\n\n    thread.join().unwrap();\n}""]}",test_generation
fragile,"{""code_context"": ""use std::mem::ManuallyDrop;\nuse std::thread;\nuse std::thread::ThreadId;\nuse crate::errors::InvalidThreadAccess;\n\n#[derive(Debug)]\npub struct InvalidThreadAccess;\n\nimpl std::fmt::Display for InvalidThreadAccess {\n    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {\n        write!(f, \""fragile value accessed from foreign thread\"")\n    }\n}\n\nimpl std::error::Error for InvalidThreadAccess {}\n\npub struct Fragile<T> {\n    value: ManuallyDrop<T>,\n    thread_id: ThreadId,\n}"", ""code_to_test"": ""impl<T> Fragile<T> {\n    pub fn try_get(&self) -> Result<&T, InvalidThreadAccess> {\n        if self.is_valid() {\n            Ok(&*self.value)\n        } else {\n            Err(InvalidThreadAccess)\n        }\n    }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn test_basic() {\n    use std::thread;\n    let val = Fragile::new(true);\n    assert_eq!(val.to_string(), \""true\"");\n    assert_eq!(val.get(), &true);\n    assert!(val.try_get().is_ok());\n    thread::spawn(move || {\n        assert!(val.try_get().is_err());\n    })\n    .join()\n    .unwrap();\n}"", ""#[test]\nfn test_noop_drop_elsewhere() {\n    use std::sync::atomic::{AtomicBool, Ordering};\n    use std::sync::Arc;\n    use std::thread;\n\n    let was_called = Arc::new(AtomicBool::new(false));\n\n    let was_called = was_called.clone();\n    thread::spawn(move || {\n        struct X(Arc<AtomicBool>);\n        impl Drop for X {\n            fn drop(&mut self) {\n                self.0.store(true, Ordering::SeqCst);\n            }\n        }\n\n        let val = Fragile::new(X(was_called.clone()));\n        assert!(thread::spawn(move || {\n            crate::stack_token!(tok);\n            val.try_get().ok();\n        })\n        .join()\n        .is_ok());\n\n        assert!(!was_called.load(Ordering::SeqCst));\n    })\n    .join()\n    .unwrap();\n}"", ""#[test]\nfn test_panic_on_drop_elsewhere() {\n    use std::sync::atomic::{AtomicBool, Ordering};\n    use std::sync::Arc;\n    use std::thread;\n    let was_called = Arc::new(AtomicBool::new(false));\n    struct X(Arc<AtomicBool>);\n    impl Drop for X {\n        fn drop(&mut self) {\n            self.0.store(true, Ordering::SeqCst);\n        }\n    }\n    let val = Fragile::new(X(was_called.clone()));\n    assert!(thread::spawn(move || {\n        val.try_get().ok();\n    })\n    .join()\n    .is_err());\n    assert!(!was_called.load(Ordering::SeqCst));\n}"", ""#[test]\nfn test_rc_sending() {\n    use std::rc::Rc;\n    use std::sync::mpsc::channel;\n    use std::thread;\n\n    let val = Fragile::new(Rc::new(true));\n    let (tx, rx) = channel();\n\n    let thread = thread::spawn(move || {\n        assert!(val.try_get().is_err());\n        let here = val;\n        tx.send(here).unwrap();\n    });\n\n    let rv = rx.recv().unwrap();\n    assert!(**rv.get());\n\n    thread.join().unwrap();\n}""]}",test_generation
fragile,"{""code_context"": ""use std::marker::PhantomData;\nuse std::thread;\nuse std::thread::ThreadId;\nuse crate::registry;\nuse crate::StackToken;\n\npub struct Sticky<T: 'static> {\n    item_id: registry::ItemId,\n    thread_id: ThreadId,\n    _marker: PhantomData<*mut T>,\n}\n\n// Minimal registry definitions needed for compilation\npub struct Entry {\n    pub ptr: *mut (),\n    pub drop: unsafe fn(*mut ()),\n}\n\n#[cfg(not(feature = \""slab\""))\nmod map_impl {\n    use super::Entry;\n    use std::cell::UnsafeCell;\n    use std::num::NonZeroUsize;\n    use std::sync::atomic::{AtomicUsize, Ordering};\n    use std::collections::HashMap;\n\n    pub struct Registry(pub std::collections::HashMap<NonZeroUsize, Entry>);\n\n    thread_local!(static REGISTRY: UnsafeCell<Registry> = UnsafeCell::new(Registry(Default::default())));\n\n    pub type ItemId = NonZeroUsize;\n\n    fn next_item_id() -> NonZeroUsize {\n        static COUNTER: AtomicUsize = AtomicUsize::new(1);\n        NonZeroUsize::new(COUNTER.fetch_add(1, Ordering::Relaxed)).expect(\""more than usize::MAX items\"")\n    }\n\n    pub fn insert(entry: Entry) -> ItemId {\n        let item_id = next_item_id();\n        REGISTRY.with(|registry| unsafe { (*registry.get()).0.insert(item_id, entry) });\n        item_id\n    }\n\n    pub fn with<R, F: FnOnce(&Entry) -> R>(item_id: ItemId, f: F) -> R {\n        REGISTRY.with(|registry| f(unsafe { &*registry.get() }.0.get(&item_id).unwrap()))\n    }\n\n    pub fn try_remove(item_id: ItemId) -> Option<Entry> {\n        REGISTRY.with(|registry| unsafe { (*registry.get()).0.remove(&item_id) })\n    }\n}\n\npub use self::map_impl::*;\n\n// Minimal StackToken definition\npub struct StackToken(std::marker::PhantomData<*const ()>);\n\nimpl StackToken {\n    pub unsafe fn __private_new() -> StackToken {\n        StackToken(std::marker::PhantomData)\n    }\n}\n\n#[macro_export]\nmacro_rules! stack_token {\n    ($name:ident) => {\n        let $name = &unsafe { $crate::StackToken::__private_new() };\n    };\n}"", ""code_to_test"": ""impl<T> Sticky<T> {\n    pub fn new(value: T) -> Self {\n        let entry = registry::Entry {\n            ptr: Box::into_raw(Box::new(value)).cast(),\n            drop: |ptr| {\n                let ptr = ptr.cast::<T>();\n                drop(unsafe { Box::from_raw(ptr) });\n            },\n        };\n\n        let thread_id = thread::current().id();\n        let item_id = registry::insert(entry);\n\n        Sticky {\n            item_id,\n            thread_id,\n            _marker: PhantomData,\n        }\n    }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn test_basic() {\n    use std::thread;\n    let val = Sticky::new(true);\n    crate::stack_token!(tok);\n    assert_eq!(val.to_string(), \""true\"");\n    assert_eq!(val.get(tok), &true);\n    assert!(val.try_get(tok).is_ok());\n    thread::spawn(move || {\n        crate::stack_token!(tok);\n        assert!(val.try_get(tok).is_err());\n    })\n    .join()\n    .unwrap();\n}"", ""#[test]\nfn test_mut() {\n    let mut val = Sticky::new(true);\n    crate::stack_token!(tok);\n    *val.get_mut(tok) = false;\n    assert_eq!(val.to_string(), \""false\"");\n    assert_eq!(val.get(tok), &false);\n}"", ""#[test]\n#[should_panic]\nfn test_access_other_thread() {\n    use std::thread;\n    let val = Sticky::new(true);\n    thread::spawn(move || {\n        crate::stack_token!(tok);\n        val.get(tok);\n    })\n    .join()\n    .unwrap();\n}"", ""#[test]\nfn test_rc_sending() {\n    use std::rc::Rc;\n    use std::thread;\n    let val = Sticky::new(Rc::new(true));\n    thread::spawn(move || {\n        crate::stack_token!(tok);\n        assert!(val.try_get(tok).is_err());\n    })\n    .join()\n    .unwrap();\n}"", ""#[test]\nfn test_two_stickies() {\n    struct Wat;\n\n    impl Drop for Wat {\n        fn drop(&mut self) {}\n    }\n\n    let s1 = Sticky::new(Wat);\n    let s2 = Sticky::new(Wat);\n\n    drop(s1);\n    drop(s2);\n}"", ""#[test]\nfn test_thread_spawn() {\n    use crate::{stack_token, Sticky};\n    use std::{mem::ManuallyDrop, thread};\n\n    let dummy_sticky = thread::spawn(|| Sticky::new(())).join().unwrap();\n    let sticky_string = ManuallyDrop::new(Sticky::new(String::from(\""Hello World\"")));\n    stack_token!(t);\n\n    let hello: &str = sticky_string.get(t);\n\n    assert_eq!(hello, \""Hello World\"");\n    drop(dummy_sticky);\n    assert_eq!(hello, \""Hello World\"");\n}""]}",test_generation
libp2p-perf,"{""code"": ""pub fn __placeholder__(sent: usize, received: usize) -> usize { sent + received }"", ""code_context"": null}","{""function_name"": ""total_data_transferred""}",function_naming
libp2p-perf,"{""code"": ""pub fn __placeholder__(duration: std::time::Duration) -> String { format!(\""{}s\"", duration.as_secs()) }"", ""code_context"": null}","{""function_name"": ""format_duration""}",function_naming
libp2p-perf,"{""code"": ""pub fn __placeholder__(run: &Run) -> bool { run.duration.upload > std::time::Duration::ZERO && run.duration.download > std::time::Duration::ZERO }"", ""code_context"": ""use crate::Run;""}","{""function_name"": ""is_run_successful""}",function_naming
libp2p-perf,"{""code"": ""pub fn __placeholder__(run: &Run) -> f64 { let total_bytes = run.params.to_send + run.params.to_receive; let total_secs = run.duration.upload.as_secs_f64() + run.duration.download.as_secs_f64(); (total_bytes as f64 * 8.0) / total_secs }"", ""code_context"": ""use crate::Run;""}","{""function_name"": ""average_bandwidth""}",function_naming
libp2p-tls,"{""title"": ""Extract PeerId from a libp2p TLS certificate"", ""description"": ""A developer needs to obtain the PeerId encoded in a TLS certificate received during a libp2p handshake. This allows the application to compare the peer's identity with an expected value before establishing a secure connection."", ""code_context"": ""use libp2p_tls::certificate;\nuse libp2p_identity::PeerId;\nuse rustls::pki_types::CertificateDer;""}","{""code"": ""pub fn extract_peer_id(cert: &rustls::pki_types::CertificateDer) -> Result<libp2p_identity::PeerId, libp2p_tls::certificate::ParseError> {\n    let parsed = libp2p_tls::certificate::parse(cert)?;\n    Ok(parsed.peer_id())\n}""}",code_generation
libp2p-tls,"{""title"": ""Check if a libp2p TLS certificate is currently valid"", ""description"": ""Before using a certificate for authentication, a developer wants to verify that its validity period includes the current time, ensuring the certificate has not expired or is not yet valid."", ""code_context"": ""use libp2p_tls::certificate;\nuse rustls::pki_types::CertificateDer;""}","{""code"": ""pub fn is_certificate_currently_valid(cert: &rustls::pki_types::CertificateDer) -> Result<bool, libp2p_tls::certificate::ParseError> {\n    let parsed = libp2p_tls::certificate::parse(cert)?;\n    Ok(parsed.certificate.validity().is_valid())\n}""}",code_generation
libp2p-tls,"{""title"": ""Validate a TLS certificate against an expected PeerId and supported signature scheme"", ""description"": ""A developer wants to ensure that a received certificate both belongs to a specific peer and uses a signature scheme that the libp2p implementation supports. This guards against man‑in‑the‑middle attacks and incompatible algorithms."", ""code_context"": ""use libp2p_tls::certificate;\nuse libp2p_identity::PeerId;\nuse rustls::SignatureScheme;\nuse rustls::pki_types::CertificateDer;""}","{""code"": ""pub fn validate_certificate(\n    cert: &rustls::pki_types::CertificateDer,\n    expected_peer: &libp2p_identity::PeerId,\n) -> Result<(), libp2p_tls::certificate::ParseError> {\n    let parsed = libp2p_tls::certificate::parse(cert)?;\n    if parsed.peer_id() != *expected_peer {\n        return Err(libp2p_tls::certificate::ParseError::UnknownIssuer);\n    }\n    let scheme = parsed.signature_scheme()?;\n    match scheme {\n        rustls::SignatureScheme::ECDSA_NISTP256_SHA256\n        | rustls::SignatureScheme::ECDSA_NISTP384_SHA384\n        | rustls::SignatureScheme::ED25519 => Ok(()),\n        _ => Err(libp2p_tls::certificate::ParseError::BadDer),\n    }\n}""}",code_generation
libp2p-tls,"{""title"": ""Create a libp2p TLS client configuration that verifies a remote peer's identity"", ""description"": ""When initiating an outbound connection, a developer wants to build a client TLS configuration that automatically checks that the remote peer's certificate matches a known PeerId, providing end‑to‑end authentication without extra manual checks."", ""code_context"": ""use libp2p_tls;\nuse libp2p_identity::Keypair;\nuse libp2p_identity::PeerId;\nuse rustls::ClientConfig;""}","{""code"": ""pub fn client_config_with_peer_verification(\n    keypair: &libp2p_identity::Keypair,\n    remote_peer: libp2p_identity::PeerId,\n) -> Result<rustls::ClientConfig, libp2p_tls::certificate::GenError> {\n    libp2p_tls::make_client_config(keypair, Some(remote_peer))\n}""}",code_generation
libp2p-webrtc-utils,"{""code"": ""let fp = Fingerprint::raw(REGULAR_FORMAT);"", ""code_context"": ""pub struct Fingerprint([u8; 32]);\n\nimpl Fingerprint {\n    pub const fn raw(digest: [u8; 32]) -> Self {\n        Fingerprint(digest)\n    }\n\n    pub fn to_sdp_format(self) -> String {\n        self.0.map(|byte| format!(\""{byte:02X}\"")).join(\"":\"")\n    }\n}\n\npub const SHA256: &str = \""sha-256\"";\nconst MULTIHASH_SHA256_CODE: u64 = 0x12;\n\ntype Multihash = multihash::Multihash<64>;\nuse multihash;\nuse itertools::Itertools;""}","{""next_api_call"": ""let formatted = fp.to_sdp_format();""}",api_usage_prediction
libp2p-webrtc-utils,"{""code"": ""let ip = match iter.next()? { Protocol::Ip4(ip) => IpAddr::from(ip), Protocol::Ip6(ip) => IpAddr::from(ip), _ => return None, };"", ""code_context"": ""use libp2p_core::multiaddr::Protocol;\nuse libp2p_core::Multiaddr;\nuse std::net::{IpAddr, SocketAddr};\nuse crate::fingerprint::Fingerprint;\n\npub fn parse_webrtc_dial_addr(addr: &Multiaddr) -> Option<(SocketAddr, Fingerprint)> {\n    // function body omitted for brevity\n    unimplemented!()\n}""}","{""next_api_call"": ""let port = iter.next()?;""}",api_usage_prediction
libp2p-webrtc-utils,"{""code"": ""let noise = noise::Config::new(&id_keys).unwrap().with_prologue(noise_prologue(client_fingerprint, server_fingerprint));"", ""code_context"": ""use libp2p_core::upgrade::{InboundConnectionUpgrade, OutboundConnectionUpgrade};\nuse libp2p_identity as identity;\nuse libp2p_identity::PeerId;\nuse libp2p_noise as noise;\nuse futures::{AsyncRead, AsyncWrite};\nuse crate::fingerprint::Fingerprint;\n\npub async fn inbound<T>(id_keys: identity::Keypair, stream: T, client_fingerprint: Fingerprint, server_fingerprint: Fingerprint) -> Result<PeerId, noise::Error>\nwhere\n    T: AsyncRead + AsyncWrite + Unpin + Send + 'static,\n{\n    // function body omitted for brevity\n    unimplemented!()\n}""}","{""next_api_call"": ""let info = noise.protocol_info().next().unwrap();""}",api_usage_prediction
libp2p-webrtc-utils,"{""code"": ""let (sender, receiver) = oneshot::channel();"", ""code_context"": ""use futures::channel::oneshot;\nuse bytes::Bytes;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\nuse futures::{AsyncRead, AsyncWrite};\nuse crate::proto::{Flag, Message};\nuse crate::stream::{framed_dc::FramedDc, state::State, drop_listener::GracefullyClosed, DropListener};\n\npub struct Stream<T> {\n    io: FramedDc<T>,\n    state: State,\n    read_buffer: Bytes,\n    drop_notifier: Option<oneshot::Sender<GracefullyClosed>>,\n}\n\nimpl<T> Stream<T>\nwhere\n    T: AsyncRead + AsyncWrite + Unpin + Clone,\n{\n    pub fn new(data_channel: T) -> (Self, DropListener<T>) {\n        // function body omitted for brevity\n        unimplemented!()\n    }\n}""}","{""next_api_call"": ""let stream = Self { io: framed_dc::new(data_channel.clone()), state: State::Open, read_buffer: Bytes::default(), drop_notifier: Some(sender), };""}",api_usage_prediction
libp2p-webrtc-utils,"{""code"": ""impl Fingerprint {\n    pub fn from_certificate(bytes: &[u8]) -> Self {\n        Fingerprint(sha2::Sha256::digest(bytes).into())\n    }\n}"", ""code_context"": ""use sha2::Digest as _;\n\npub struct Fingerprint([u8; 32]);""}","{""docstring"": ""Creates a new Fingerprint from a raw certificate by hashing the given bytes with SHA256.""}",docstring_generation
libp2p-webrtc-utils,"{""code"": ""pub fn parse_webrtc_dial_addr(addr: &Multiaddr) -> Option<(SocketAddr, Fingerprint)> {\n    let mut iter = addr.iter();\n\n    let ip = match iter.next()? {\n        Protocol::Ip4(ip) => IpAddr::from(ip),\n        Protocol::Ip6(ip) => IpAddr::from(ip),\n        _ => return None,\n    };\n\n    let port = match iter.next()? {\n        Protocol::Udp(p) => p,\n        _ => return None,\n    };\n\n    let webrtc = iter.next()?;\n    let certhash = iter.next()?;\n\n    let (port, fingerprint) = match (port, webrtc, certhash) {\n        (Protocol::Udp(port), Protocol::WebRTCDirect, Protocol::Certhash(cert_hash)) => {\n            let fingerprint = Fingerprint::try_from_multihash(cert_hash)?;\n            (port, fingerprint)\n        }\n        _ => return None,\n    };\n\n    match iter.next() {\n        Some(Protocol::P2p(_)) => {}\n        None => {}\n        Some(_) => return None,\n    }\n\n    Some((SocketAddr::new(ip, port), fingerprint))\n}"", ""code_context"": ""use std::net::{IpAddr, SocketAddr};\nuse libp2p_core::multiaddr::Protocol;\nuse libp2p_core::Multiaddr;\nuse libp2p_core::multihash;\n\ntype Multihash = multihash::Multihash<64>;\nconst MULTIHASH_SHA256_CODE: u64 = 0x12;\n\npub struct Fingerprint([u8; 32]);\n\nimpl Fingerprint {\n    pub fn try_from_multihash(hash: Multihash) -> Option<Self> {\n        if hash.code() != MULTIHASH_SHA256_CODE {\n            return None;\n        }\n        let bytes = hash.digest().try_into().ok()?;\n        Some(Self(bytes))\n    }\n}""}","{""docstring"": ""Parses the given Multiaddr into a SocketAddr and Fingerprint for dialing. Returns None if parsing fails.""}",docstring_generation
libp2p-webrtc-utils,"{""code"": ""pub fn render_description(\n    description: &str,\n    addr: SocketAddr,\n    fingerprint: Fingerprint,\n    ufrag: &str,\n) -> String {\n    let mut tt = TinyTemplate::new();\n    tt.add_template(\""description\"", description).unwrap();\n\n    let context = DescriptionContext {\n        ip_version: if addr.is_ipv4() { IpVersion::IP4 } else { IpVersion::IP6 },\n        target_ip: addr.ip(),\n        target_port: addr.port(),\n        fingerprint_algorithm: fingerprint.algorithm(),\n        fingerprint_value: fingerprint.to_sdp_format(),\n        ufrag: ufrag.to_owned(),\n        pwd: ufrag.to_owned(),\n    };\n    tt.render(\""description\"", &context).unwrap()\n}"", ""code_context"": ""use std::net::{IpAddr, SocketAddr};\nuse tinytemplate::TinyTemplate;\nuse serde::Serialize;\nuse crate::fingerprint::Fingerprint;\n\n#[derive(Serialize)]\nenum IpVersion {\n    IP4,\n    IP6,\n}\n\n#[derive(Serialize)]\nstruct DescriptionContext {\n    ip_version: IpVersion,\n    target_ip: IpAddr,\n    target_port: u16,\n    fingerprint_algorithm: String,\n    fingerprint_value: String,\n    ufrag: String,\n    pwd: String,\n}""}","{""docstring"": ""Renders a TinyTemplate description using the provided arguments.""}",docstring_generation
libp2p-noise,"{""buggy_code"": ""impl<T: AsyncWrite + Unpin> AsyncWrite for Output<T> {\n    fn poll_write(\n        self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n        buf: &[u8],\n    ) -> Poll<io::Result<usize>> {\n        let this = Pin::into_inner(self);\n        let mut io = Pin::new(&mut this.io);\n        let frame_buf = &mut this.send_buffer;\n\n        if this.send_offset == MAX_FRAME_LEN {\n            tracing::trace!(bytes=%MAX_FRAME_LEN, \""write: sending\"");\n            ready!(io.as_mut().poll_ready(cx))?;\n            io.as_mut().start_send(frame_buf)?;\n            this.send_offset = 0;\n        }\n\n        let off = this.send_offset;\n        let n = min(MAX_FRAME_LEN, off.saturating_add(buf.len()));\n        this.send_buffer.resize(n, 0u8);\n        let n = min(MAX_FRAME_LEN - off, buf.len());\n        this.send_buffer[off..off + n].copy_from_slice(&buf[..n]);\n        this.send_offset += n;\n        tracing::trace!(bytes=%this.send_offset, \""write: buffered\"");\n\n        Poll::Ready(Ok(n))\n    }\n\n    // ... other methods omitted ...\n}"", ""code_context"": ""use std::{cmp::min, fmt, io, pin::Pin, task::{Context, Poll}};\nuse asynchronous_codec::Framed;\nuse bytes::Bytes;\nuse futures::{prelude::*, ready};\n\npub const MAX_FRAME_LEN: usize = 65535 - 1024; // example value\n\npub struct Output<T> {\n    io: Framed<T, Codec>,\n    recv_buffer: Bytes,\n    recv_offset: usize,\n    send_buffer: Vec<u8>,\n    send_offset: usize,\n}\n\nstruct Codec; // placeholder for the actual codec type""}","{""fixed_code"": ""impl<T: AsyncWrite + Unpin> AsyncWrite for Output<T> {\n    fn poll_write(\n        self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n        buf: &[u8],\n    ) -> Poll<io::Result<usize>> {\n        let this = Pin::into_inner(self);\n        let mut io = Pin::new(&mut this.io);\n        let frame_buf = &mut this.send_buffer;\n\n        if this.send_offset == MAX_FRAME_LEN {\n            tracing::trace!(bytes=%MAX_FRAME_LEN, \""write: sending\"");\n            ready!(io.as_mut().poll_ready(cx))?;\n            io.as_mut().start_send(frame_buf)?;\n            this.send_offset = 0;\n        }\n\n        let off = this.send_offset;\n        // Number of bytes we can copy from the caller's buffer.\n        let n = min(MAX_FRAME_LEN - off, buf.len());\n        // Resize the internal buffer only to the new length needed.\n        let new_len = off + n;\n        this.send_buffer.resize(new_len, 0u8);\n        this.send_buffer[off..off + n].copy_from_slice(&buf[..n]);\n        this.send_offset += n;\n        tracing::trace!(bytes=%this.send_offset, \""write: buffered\"");\n\n        Poll::Ready(Ok(n))\n    }\n\n    // ... other methods omitted ...\n}"", ""bug_description"": ""The original `poll_write` resizes the internal `send_buffer` to `min(MAX_FRAME_LEN, off + buf.len())`. When `off + buf.len()` exceeds `MAX_FRAME_LEN`, the buffer is resized to `MAX_FRAME_LEN` even though only `MAX_FRAME_LEN - off` bytes are actually copied. This leaves uninitialized (zero) bytes at the end of the buffer. If a flush occurs before the buffer is full, those extra zero bytes are sent as part of the frame, corrupting the encrypted payload. The fix resizes the buffer precisely to `off + n`, where `n` is the number of bytes actually copied, preventing accidental transmission of padding data.""}",bug_detection
libp2p-noise,"{""buggy_code"": ""fn encode_length_prefixed(src: &[u8], dst: &mut BytesMut) {\n    dst.reserve(U16_LENGTH + src.len());\n    dst.extend_from_slice(&(src.len() as u16).to_be_bytes());\n    dst.extend_from_slice(src);\n}"", ""code_context"": ""use bytes::BytesMut;\nuse std::io;\nconst U16_LENGTH: usize = std::mem::size_of::<u16>();""}","{""fixed_code"": ""fn encode_length_prefixed(src: &[u8], dst: &mut BytesMut) -> io::Result<()> {\n    if src.len() > u16::MAX as usize {\n        return Err(io::Error::new(\n            io::ErrorKind::InvalidInput,\n            \""payload exceeds maximum length\"",\n        ));\n    }\n    dst.reserve(U16_LENGTH + src.len());\n    dst.extend_from_slice(&(src.len() as u16).to_be_bytes());\n    dst.extend_from_slice(src);\n    Ok(())\n}"", ""bug_description"": ""The function writes the length of the payload as a `u16` prefix but does not verify that the payload fits into 16 bits. If a caller passes a slice longer than 65535 bytes, the length is silently truncated, producing a malformed frame that the peer cannot decode, leading to a panic or data loss. The fix adds an explicit check and returns an `io::Error` when the payload is too large.""}",bug_detection
libp2p-noise,"{""buggy_code"": ""pub(crate) async fn recv_identity<T>(state: &mut State<T>) -> Result<(), Error>\nwhere\n    T: AsyncRead + Unpin,\n{\n    let pb = recv(state).await?;\n    state.id_remote_pubkey = Some(identity::PublicKey::try_decode_protobuf(&pb.identity_key)?);\n\n    if !pb.identity_sig.is_empty() {\n        state.dh_remote_pubkey_sig = Some(pb.identity_sig);\n    }\n\n    if let Some(extensions) = pb.extensions {\n        state.remote_extensions = Some(extensions.into());\n    }\n\n    Ok(())\n}\n\nimpl From<proto::NoiseExtensions> for Extensions {\n    fn from(value: proto::NoiseExtensions) -> Self {\n        Extensions {\n            webtransport_certhashes: value\n                .webtransport_certhashes\n                .into_iter()\n                .filter_map(|bytes| Multihash::read(&bytes[..]).ok())\n                .collect(),\n        }\n    }\n}"", ""code_context"": ""use std::{collections::HashSet, io};\nuse libp2p_identity as identity;\nuse multihash::Multihash;\nuse quick_protobuf::Error as ProtobufError;\nuse crate::Error;\n\npub struct Extensions {\n    pub webtransport_certhashes: HashSet<Multihash<64>>, \n}\n\nmod proto {\n    #[derive(Default)]\n    pub struct NoiseExtensions {\n        pub webtransport_certhashes: Vec<Vec<u8>>, \n    }\n}\n\nasync fn recv<T>(state: &mut State<T>) -> Result<proto::NoiseHandshakePayload, Error> { unimplemented!() }\n\nstruct State<T> {\n    // fields omitted\n    id_remote_pubkey: Option<identity::PublicKey>,\n    dh_remote_pubkey_sig: Option<Vec<u8>>,\n    remote_extensions: Option<Extensions>,\n}\n\nmod handshake {\n    pub struct NoiseHandshakePayload {\n        pub identity_key: Vec<u8>,\n        pub identity_sig: Vec<u8>,\n        pub extensions: Option<super::proto::NoiseExtensions>,\n    }\n}""}","{""fixed_code"": ""pub(crate) async fn recv_identity<T>(state: &mut State<T>) -> Result<(), Error>\nwhere\n    T: AsyncRead + Unpin,\n{\n    let pb = recv(state).await?;\n    state.id_remote_pubkey = Some(identity::PublicKey::try_decode_protobuf(&pb.identity_key)?);\n\n    if !pb.identity_sig.is_empty() {\n        state.dh_remote_pubkey_sig = Some(pb.identity_sig);\n    }\n\n    if let Some(extensions) = pb.extensions {\n        // Convert extensions and ensure all certhash entries are valid.\n        let ext = Extensions::try_from(extensions)?;\n        state.remote_extensions = Some(ext);\n    }\n\n    Ok(())\n}\n\nimpl TryFrom<proto::NoiseExtensions> for Extensions {\n    type Error = Error;\n    fn try_from(value: proto::NoiseExtensions) -> Result<Self, Self::Error> {\n        let mut set = std::collections::HashSet::new();\n        for bytes in value.webtransport_certhashes {\n            let mh = Multihash::read(&bytes[..])\n                .map_err(|_| Error::InvalidPayload(DecodeError(quick_protobuf::Error::MessageNotFullyRead)))?;\n            set.insert(mh);\n        }\n        Ok(Extensions { webtransport_certhashes: set })\n    }\n}"", ""bug_description"": ""The original `recv_identity` silently discards malformed WebTransport certhash entries by using `filter_map(... .ok())`. An attacker could send a payload containing invalid multihash bytes, which would be ignored, potentially causing the handshake to succeed with incomplete security guarantees. The fix replaces the silent filter with a `TryFrom` implementation that validates every certhash and returns an error (`Error::InvalidPayload`) if any entry is malformed, ensuring the handshake fails on malformed extensions.""}",bug_detection
serde-value,"{""code"": ""pub enum Value {\n    Bool(bool),\n\n    U8(u8),\n    U16(u16),\n    U32(u32),\n    U64(u64),\n\n    I8(i8),\n    I16(i16),\n    I32(i32),\n    I64(i64),\n\n    F32(f32),\n    F64(f64),\n\n    Char(char),\n    String(String),\n\n    Unit,\n    Option(Option<Box<Value>>),\n    Newtype(Box<Value>),\n    Seq(Vec<Value>),\n    Map(BTreeMap<Value, Value>),\n    Bytes(Vec<u8>),\n}"", ""code_context"": null}","{""docstring"": ""Represents a generic value that can hold any primitive, integer, floating‑point, character, string, unit, optional, newtype, sequence, map, or raw byte array. It is the core type used by the crate to model Serde value trees.""}",docstring_generation
serde-value,"{""code"": ""pub fn to_value<T: ser::Serialize>(value: T) -> Result<Value, SerializerError> {\n    value.serialize(Serializer)\n}"", ""code_context"": ""pub enum Value {\n    Bool(bool),\n    U8(u8),\n    U16(u16),\n    U32(u32),\n    U64(u64),\n    I8(i8),\n    I16(i16),\n    I32(i32),\n    I64(i64),\n    F32(f32),\n    F64(f64),\n    Char(char),\n    String(String),\n    Unit,\n    Option(Option<Box<Value>>),\n    Newtype(Box<Value>),\n    Seq(Vec<Value>),\n    Map(BTreeMap<Value, Value>),\n    Bytes(Vec<u8>),\n}\n\npub enum SerializerError {\n    Custom(String),\n}\n\nstruct Serializer;""}","{""docstring"": ""Serializes the given value `T` into a `Value` tree using the crate's `Serializer`. Returns the resulting `Value` or a `SerializerError` if serialization fails.""}",docstring_generation
serde-value,"{""code"": ""impl Value {\n    pub fn deserialize_into<'de, T: Deserialize<'de>>(self) -> Result<T, DeserializerError> {\n        T::deserialize(self)\n    }\n}"", ""code_context"": ""pub enum Value {\n    Bool(bool),\n    U8(u8),\n    U16(u16),\n    U32(u32),\n    U64(u64),\n    I8(i8),\n    I16(i16),\n    I32(i32),\n    I64(i64),\n    F32(f32),\n    F64(f64),\n    Char(char),\n    String(String),\n    Unit,\n    Option(Option<Box<Value>>),\n    Newtype(Box<Value>),\n    Seq(Vec<Value>),\n    Map(BTreeMap<Value, Value>),\n    Bytes(Vec<u8>),\n}\n\npub enum DeserializerError {\n    Custom(String),\n    InvalidType(Unexpected, String),\n    InvalidValue(Unexpected, String),\n    InvalidLength(usize, String),\n    UnknownVariant(String, &'static [&'static str]),\n    UnknownField(String, &'static [&'static str]),\n    MissingField(&'static str),\n    DuplicateField(&'static str),\n}\n\n#[derive(Debug)]\npub enum Unexpected {\n    Bool(bool),\n    Unsigned(u64),\n    Signed(i64),\n    Float(f64),\n    Char(char),\n    Str(String),\n    Bytes(Vec<u8>),\n    Unit,\n    Option,\n    NewtypeStruct,\n    Seq,\n    Map,\n    Enum,\n    UnitVariant,\n    NewtypeVariant,\n    TupleVariant,\n    StructVariant,\n    Other(String),\n}""}","{""docstring"": ""Converts this `Value` into a concrete type `T` that implements `Deserialize`. It forwards the conversion to `T::deserialize` and returns either the deserialized value or a `DeserializerError`.""}",docstring_generation
libp2p-tcp,"{""code"": ""impl Config {\n    fn create_socket(&self, socket_addr: SocketAddr, port_use: PortUse) -> io::Result<Socket> {\n        let socket = Socket::new(\n            Domain::for_address(socket_addr),\n            Type::STREAM,\n            Some(socket2::Protocol::TCP),\n        )?;\n        if socket_addr.is_ipv6() {\n            socket.set_only_v6(true)?;\n        }\n        if let Some(ttl) = self.ttl {\n            socket.set_ttl(ttl)?;\n        }\n        socket.set_nodelay(self.nodelay)?;\n        socket.set_reuse_address(true)?;\n        #[cfg(all(unix, not(any(target_os = \""solaris\"", target_os = \""illumos\"")))]\n        if port_use == PortUse::Reuse {\n            socket.set_reuse_port(true)?;\n        }\n        #[cfg(not(all(unix, not(any(target_os = \""solaris\"", target_os = \""illumos\""))))]\n        let _ = port_use;\n        socket.set_nonblocking(true)?;\n        Ok(socket)\n    }\n}"", ""code_context"": ""use std::io;\nuse std::net::SocketAddr;\nuse socket2::{Domain, Socket, Type};\n\n#[derive(Clone, Debug)]\npub struct Config {\n    ttl: Option<u32>,\n    nodelay: bool,\n    backlog: u32,\n}\n\nenum PortUse {\n    New,\n    Reuse,\n}""}","{""summary"": ""Creates a TCP socket with the given address and port‑use settings, applying TTL, nodelay, reuse and platform‑specific options.""}",code_summarization
libp2p-tcp,"{""code"": ""impl PortReuse {\n    fn local_dial_addr(&self, remote_ip: &IpAddr) -> Option<SocketAddr> {\n        for (ip, port) in self.listen_addrs.read().expect(\""local_dial_addr never panic while holding the lock\"").iter() {\n            if ip.is_ipv4() == remote_ip.is_ipv4() && ip.is_loopback() == remote_ip.is_loopback() {\n                if remote_ip.is_ipv4() {\n                    return Some(SocketAddr::new(IpAddr::V4(Ipv4Addr::UNSPECIFIED), *port));\n                } else {\n                    return Some(SocketAddr::new(IpAddr::V6(Ipv6Addr::UNSPECIFIED), *port));\n                }\n            }\n        }\n        None\n    }\n}"", ""code_context"": ""use std::collections::HashSet;\nuse std::net::{IpAddr, Ipv4Addr, Ipv6Addr, SocketAddr};\nuse std::sync::{Arc, RwLock};\n\ntype Port = u16;\n\nstruct PortReuse {\n    listen_addrs: Arc<RwLock<HashSet<(IpAddr, Port)>>>,\n}""}","{""summary"": ""Selects a listening socket address that matches the remote IP's version and loopback status for port‑reuse dialing.""}",code_summarization
libp2p-tcp,"{""code"": ""impl<T> Transport<T>\nwhere\n    T: Provider + Send,\n{\n    fn dial(&mut self, addr: Multiaddr, opts: DialOpts) -> Result<Self::Dial, TransportError<Self::Error>> {\n        let socket_addr = if let Ok(sa) = multiaddr_to_socketaddr(addr.clone()) {\n            if sa.port() == 0 || sa.ip().is_unspecified() {\n                return Err(TransportError::MultiaddrNotSupported(addr));\n            }\n            sa\n        } else {\n            return Err(TransportError::MultiaddrNotSupported(addr));\n        };\n        tracing::debug!(address = %socket_addr, \""dialing address\"");\n\n        let socket = self.config.create_socket(socket_addr, opts.port_use).map_err(TransportError::Other)?;\n\n        let bind_addr = match self.port_reuse.local_dial_addr(&socket_addr.ip()) {\n            Some(a) if opts.port_use == PortUse::Reuse => {\n                tracing::trace!(address = %addr, \""Binding dial socket to listen socket address\"");\n                Some(a)\n            }\n            _ => None,\n        };\n\n        let local_cfg = self.config.clone();\n\n        Ok(async move {\n            if let Some(bind) = bind_addr {\n                socket.bind(&bind.into())?;\n            }\n\n            let socket = match (socket.connect(&socket_addr.into()), bind_addr) {\n                (Ok(()), _) => socket,\n                (Err(e), _) if e.raw_os_error() == Some(libc::EINPROGRESS) => socket,\n                (Err(e), _) if e.kind() == io::ErrorKind::WouldBlock => socket,\n                (Err(e), Some(bind)) if e.kind() == io::ErrorKind::AddrNotAvailable => {\n                    tracing::debug!(connect_addr = %socket_addr, ?bind, \""Failed to connect using existing socket because we already have a connection, re-dialing with new port\"");\n                    std::mem::drop(socket);\n                    let socket = local_cfg.create_socket(socket_addr, PortUse::New)?;\n                    match socket.connect(&socket_addr.into()) {\n                        Ok(()) => socket,\n                        Err(e) if e.raw_os_error() == Some(libc::EINPROGRESS) => socket,\n                        Err(e) if e.kind() == io::ErrorKind::WouldBlock => socket,\n                        Err(e) => return Err(e),\n                    }\n                }\n                (Err(e), _) => return Err(e),\n            };\n\n            let stream = T::new_stream(socket.into()).await?;\n            Ok(stream)\n        }\n        .boxed())\n    }\n}"", ""code_context"": ""use std::collections::VecDeque;\nuse std::io;\nuse std::net::SocketAddr;\nuse futures::{future::Ready, prelude::*, stream::SelectAll};\nuse libp2p_core::{\n    multiaddr::Multiaddr,\n    transport::{DialOpts, ListenerId, PortUse, TransportError, TransportEvent},\n};\n\npub struct Config {\n    ttl: Option<u32>,\n    nodelay: bool,\n    backlog: u32,\n}\n\n#[derive(Clone)]\npub struct PortReuse {\n    // fields omitted for brevity\n}\n\npub struct Transport<T>\nwhere\n    T: Provider + Send,\n{\n    config: Config,\n    port_reuse: PortReuse,\n    listeners: SelectAll<ListenStream<T>>, \n    pending_events: VecDeque<TransportEvent<<Self as libp2p_core::Transport>::ListenerUpgrade, io::Error>>, \n}\n\n// Placeholder types to make the snippet compile\npub struct ListenStream<T> { /* ... */ }\npub trait Provider {}\n""}","{""summary"": ""Establishes a TCP connection to a multi‑address, handling port‑reuse binding, non‑blocking connect states and fallback on address‑unavailable errors.""}",code_summarization
libp2p-tcp,"{""code"": ""impl Provider for Tcp {\n    type Stream = TcpStream;\n    type Listener = tokio::net::TcpListener;\n    type IfWatcher = if_watch::tokio::IfWatcher;\n\n    fn poll_accept(l: &mut Self::Listener, cx: &mut Context<'_>) -> Poll<io::Result<Incoming<Self::Stream>>> {\n        let (stream, remote_addr) = match l.poll_accept(cx) {\n            Poll::Pending => return Poll::Pending,\n            Poll::Ready(Err(e)) => return Poll::Ready(Err(e)),\n            Poll::Ready(Ok((s, r))) => (s, r),\n        };\n        let local_addr = stream.local_addr()?;\n        let stream = TcpStream(stream);\n        Poll::Ready(Ok(Incoming {\n            stream,\n            local_addr,\n            remote_addr,\n        }))\n    }\n}"", ""code_context"": ""use std::io;\nuse std::task::{Context, Poll};\nuse tokio::net::TcpListener;\nuse if_watch::tokio::IfWatcher;\n\npub struct Tcp;\n\npub struct TcpStream(pub tokio::net::TcpStream);\n\npub struct Incoming<S> {\n    pub stream: S,\n    pub local_addr: std::net::SocketAddr,\n    pub remote_addr: std::net::SocketAddr,\n}\n\npub trait Provider: Clone + Send + 'static {\n    type Stream;\n    type Listener;\n    type IfWatcher;\n    fn poll_accept(l: &mut Self::Listener, cx: &mut Context<'_>) -> Poll<io::Result<Incoming<Self::Stream>>>;\n}""}","{""summary"": ""Polls a Tokio TCP listener for an incoming connection and returns the wrapped stream together with its local and remote addresses.""}",code_summarization
quanta,"{""query"": ""How do I get the current time using the quanta crate?"", ""code_context"": null}","{""code_snippet"": ""let current_time = quanta::Clock::new().now();""}",code_search
quanta,"{""query"": ""How can I use the quanta crate to measure the time difference between two points?"", ""code_context"": null}","{""code_snippet"": ""use quanta::Clock;\n\nlet clock = Clock::new();\nlet start = clock.now();\n// Perform some operations\nlet end = clock.now();\nlet duration = end - start;""}",code_search
quanta,"{""query"": ""How do I configure and start the upkeep thread for recent time updates in the quanta crate?"", ""code_context"": null}","{""code_snippet"": ""use quanta::Upkeep;\n\nlet upkeep_handle = Upkeep::new(std::time::Duration::from_millis(100)).start().unwrap();""}",code_search
quanta,"{""query"": ""How can I mock the time in the quanta crate for testing purposes?"", ""code_context"": null}","{""code_snippet"": ""use quanta::{Clock, Mock};\n\nlet (clock, mock) = Clock::mock();\nmock.increment(1000);""}",code_search
quanta,"{""query"": ""How do I get the most recent time using the quanta crate?"", ""code_context"": null}","{""code_snippet"": ""let recent_time = quanta::Clock::new().recent();""}",code_search
bytecheck,"{""code"": ""unsafe impl<C: Fallible + ?Sized> CheckBytes<C> for PhantomData<T> {\n    #[inline]\n    unsafe fn check_bytes(_: *const Self, _: &mut C) -> Result<(), C::Error> {\n        Ok(())\n    }\n}"", ""code_context"": ""use core::marker::PhantomData;\nuse crate::{rancor::Fallible, CheckBytes};\n\npub unsafe trait CheckBytes<C: Fallible + ?Sized> {\n    unsafe fn check_bytes(value: *const Self, context: &mut C) -> Result<(), C::Error>;\n}""}","{""commented_code"": ""unsafe impl<C: Fallible + ?Sized> CheckBytes<C> for PhantomData<T> {\n    #[inline]\n    unsafe fn check_bytes(_: *const Self, _: &mut C) -> Result<(), C::Error> {\n        // SAFETY: `PhantomData` is a zero-sized type and so all bit patterns are valid.\n        Ok(())\n    }\n}""}",comment_generation
bytecheck,"{""code"": ""unsafe impl<C> CheckBytes<C> for bool\nwhere\n    C: Fallible + ?Sized,\n    C::Error: Source,\n{\n    #[inline]\n    unsafe fn check_bytes(\n        value: *const Self,\n        _: &mut C,\n    ) -> Result<(), C::Error> {\n        let byte = unsafe { *value.cast::<u8>() };\n        match byte {\n            0 | 1 => Ok(()),\n            _ => fail!(BoolCheckError { byte }),\n        }\n    }\n}"", ""code_context"": ""use core::{error::Error, fmt};\nuse crate::{rancor::Fallible, CheckBytes};\n\n#[derive(Debug)]\nstruct BoolCheckError {\n    byte: u8,\n}\n\nimpl fmt::Display for BoolCheckError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \""bool set to invalid byte {}, expected either 0 or 1\"", self.byte)\n    }\n}\n\nimpl Error for BoolCheckError {}""}","{""commented_code"": ""unsafe impl<C> CheckBytes<C> for bool\nwhere\n    C: Fallible + ?Sized,\n    C::Error: Source,\n{\n    #[inline]\n    unsafe fn check_bytes(\n        value: *const Self,\n        _: &mut C,\n    ) -> Result<(), C::Error> {\n        // SAFETY: `value` is a pointer to a `bool`, which has a size and\n        // alignment of one. `u8` also has a size and alignment of one, and all\n        // bit patterns are valid for `u8`. So we can cast `value` to a `u8`\n        // pointer and read from it.\n        let byte = unsafe { *value.cast::<u8>() };\n        match byte {\n            0 | 1 => Ok(()),\n            _ => fail!(BoolCheckError { byte }),\n        }\n    }\n}""}",comment_generation
bytecheck,"{""code"": ""unsafe impl<C: Fallible + ?Sized> CheckBytes<C> for char\nwhere\n    C::Error: Source,\n{\n    #[inline]\n    unsafe fn check_bytes(ptr: *const Self, _: &mut C) -> Result<(), C::Error> {\n        let value = unsafe { ptr.cast::<u32>().read_unaligned() };\n        char::try_from(value).into_error()?;\n        Ok(())\n    }\n}"", ""code_context"": ""use core::{error::Error, fmt};\nuse crate::{rancor::Fallible, CheckBytes};\nuse rancor::Source;""}","{""commented_code"": ""unsafe impl<C: Fallible + ?Sized> CheckBytes<C> for char\nwhere\n    C::Error: Source,\n{\n    #[inline]\n    unsafe fn check_bytes(ptr: *const Self, _: &mut C) -> Result<(), C::Error> {\n        // SAFETY: `char` and `u32` are both four bytes, but we're not\n        // guaranteed that they have the same alignment. Using `read_unaligned`\n        // ensures that we can read a `u32` regardless and try to convert it to a `char`.\n        let value = unsafe { ptr.cast::<u32>().read_unaligned() };\n        char::try_from(value).into_error()?;\n        Ok(())\n    }\n}""}",comment_generation
inotify,"{""title"": ""Add recursive watches for a directory tree"", ""description"": ""I need to monitor a directory and all of its existing subdirectories for create, delete, and modify events. The helper should add a watch for each directory in the tree and return the list of watch descriptors so I can later remove them if needed."", ""code_context"": ""use std::path::Path;\nuse std::io;\nuse inotify::{Inotify, WatchMask, WatchDescriptor};""}","{""code"": ""fn add_recursive_watch(inotify: &Inotify, root: &Path) -> io::Result<Vec<WatchDescriptor>> {\n    let mut watches = Vec::new();\n    let mut stack = vec![root.to_path_buf()];\n    while let Some(path) = stack.pop() {\n        let wd = inotify.watches().add(&path, WatchMask::CREATE | WatchMask::DELETE | WatchMask::MODIFY)?;\n        watches.push(wd);\n        for entry in std::fs::read_dir(&path)? {\n            let entry = entry?;\n            if entry.metadata()?.is_dir() {\n                stack.push(entry.path());\n            }\n        }\n    }\n    Ok(watches)\n}""}",code_generation
inotify,"{""title"": ""Filter events by file name"", ""description"": ""When processing a stream of inotify events I only care about events that refer to a specific file name. I want a utility that takes an iterator of events and returns only those whose `name` matches the target name, yielding owned events."", ""code_context"": ""use std::ffi::OsStr;\nuse inotify::{Event, EventOwned};""}","{""code"": ""fn filter_events_by_name<'a, I>(events: I, target: &OsStr) -> impl Iterator<Item = EventOwned> + 'a\nwhere\n    I: Iterator<Item = Event<&'a OsStr>> + 'a,\n{\n    events.filter_map(move |e| {\n        if e.name.as_deref() == Some(target) {\n            Some(e.to_owned())\n        } else {\n            None\n        }\n    })\n}""}",code_generation
inotify,"{""title"": ""Compute total inotify buffer size for multiple paths"", ""description"": ""I need to allocate a buffer that can hold the largest possible inotify event for a set of paths. The helper should sum the buffer sizes required for each absolute path using the crate's utility function."", ""code_context"": ""use std::path::Path;\nuse crate::util::get_absolute_path_buffer_size;""}","{""code"": ""fn compute_total_buffer(paths: &[&Path]) -> usize {\n    paths.iter().map(|p| get_absolute_path_buffer_size(p)).sum()\n}""}",code_generation
inotify,"{""title"": ""Collect a limited number of asynchronous inotify events"", ""description"": ""In an async context I want to read a specific number of events from an `Inotify` instance using the stream API. The function should return a vector of owned events once the limit is reached or the stream ends."", ""code_context"": ""use std::io;\nuse inotify::{Inotify, EventOwned};\nuse futures_util::StreamExt;""}","{""code"": ""async fn collect_events(mut inotify: Inotify, buffer: &mut [u8], limit: usize) -> io::Result<Vec<EventOwned>> {\n    let mut stream = inotify.into_event_stream(buffer)?;\n    let mut events = Vec::new();\n    while let Some(item) = stream.next().await {\n        let ev = item?;\n        events.push(ev);\n        if events.len() >= limit {\n            break;\n        }\n    }\n    Ok(events)\n}""}",code_generation
datafusion-spark,"{""code_context"": ""use arrow::array::{Array, Int64Array};\nuse arrow::datatypes::DataType::{Int32, Int64};\nuse datafusion_common::cast::as_int32_array;\nuse datafusion_common::{exec_err, DataFusionError, Result, ScalarValue};\nuse datafusion_expr::ColumnarValue;\nuse std::sync::Arc;\n\nconst FACTORIALS: [i64; 21] = [\n    1,\n    1,\n    2,\n    6,\n    24,\n    120,\n    720,\n    5040,\n    40320,\n    362880,\n    3628800,\n    39916800,\n    479001600,\n    6227020800,\n    87178291200,\n    1307674368000,\n    20922789888000,\n    355687428096000,\n    6402373705728000,\n    121645100408832000,\n    2432902008176640000,\n];\n\nfn compute_factorial(num: Option<i32>) -> Option<i64> {\n    num.filter(|&v| (0..=20).contains(&v))\n        .map(|v| FACTORIALS[v as usize])\n}"", ""code_to_test"": ""pub fn spark_factorial(args: &[ColumnarValue]) -> Result<ColumnarValue, DataFusionError> {\n    if args.len() != 1 {\n        return Err(DataFusionError::Internal(\n            \""`factorial` expects exactly one argument\"".to_string(),\n        ));\n    }\n\n    match &args[0] {\n        ColumnarValue::Scalar(ScalarValue::Int32(value)) => {\n            let result = compute_factorial(*value);\n            Ok(ColumnarValue::Scalar(ScalarValue::Int64(result)))\n        }\n        ColumnarValue::Scalar(other) => {\n            exec_err!(\""`factorial` got an unexpected scalar type: {:?}\"", other)\n        }\n        ColumnarValue::Array(array) => match array.data_type() {\n            Int32 => {\n                let array = as_int32_array(array)?;\n\n                let result: Int64Array = array.iter().map(compute_factorial).collect();\n\n                Ok(ColumnarValue::Array(Arc::new(result)))\n            }\n            other => {\n                exec_err!(\""`factorial` got an unexpected argument type: {:?}\"", other)\n            }\n        },\n    }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn test_spark_factorial_array() {\n    let input = Int32Array::from(vec![\n        Some(-1),\n        Some(0),\n        Some(1),\n        Some(2),\n        Some(4),\n        Some(20),\n        Some(21),\n        None,\n    ]);\n\n    let args = ColumnarValue::Array(Arc::new(input));\n    let result = spark_factorial(&[args]).unwrap();\n    let result = match result {\n        ColumnarValue::Array(array) => array,\n        _ => panic!(\""Expected array\""),\n    };\n\n    let actual = as_int64_array(&result).unwrap();\n    let expected = Int64Array::from(vec![\n        None,\n        Some(1),\n        Some(1),\n        Some(2),\n        Some(24),\n        Some(2432902008176640000),\n        None,\n        None,\n    ]);\n\n    assert_eq!(actual, &expected);\n}"", ""#[test]\nfn test_spark_factorial_scalar() {\n    let input = ScalarValue::Int32(Some(5));\n\n    let args = ColumnarValue::Scalar(input);\n    let result = spark_factorial(&[args]).unwrap();\n    let result = match result {\n        ColumnarValue::Scalar(ScalarValue::Int64(val)) => val,\n        _ => panic!(\""Expected scalar\""),\n    };\n    let actual = result.unwrap();\n    let expected = 120_i64;\n\n    assert_eq!(actual, expected);\n}""]}",test_generation
datafusion-spark,"{""code_context"": ""use arrow::array::{ArrayRef, StringArray};\nuse arrow::datatypes::DataType;\nuse datafusion_common::{exec_err, Result, DataFusionError};\nuse datafusion_expr::ColumnarValue;\nuse std::sync::Arc;\nuse arrow::array::{as_int64_array, as_string_array, as_dictionary_array};\nuse arrow::datatypes::Int32Type;\n\nfn compute_hex(args: &[ColumnarValue], lowercase: bool) -> Result<ColumnarValue, DataFusionError> {\n    if args.len() != 1 {\n        return Err(DataFusionError::Internal(\""hex expects exactly one argument\"".to_string()));\n    }\n\n    let input = match &args[0] {\n        ColumnarValue::Scalar(value) => ColumnarValue::Array(value.to_array()?),\n        ColumnarValue::Array(_) => args[0].clone(),\n    };\n\n    match &input {\n        ColumnarValue::Array(array) => match array.data_type() {\n            DataType::Int64 => {\n                let array = as_int64_array(array)?;\n                let hexed_array: StringArray = array.iter().map(|v| v.map(hex_int64)).collect();\n                Ok(ColumnarValue::Array(Arc::new(hexed_array)))\n            }\n            DataType::Utf8 => {\n                let array = as_string_array(array);\n                let hexed: StringArray = array\n                    .iter()\n                    .map(|v| v.map(|b| hex_bytes(b, lowercase)).transpose())\n                    .collect::<Result<_, _>>()?;\n                Ok(ColumnarValue::Array(Arc::new(hexed)))\n            }\n            DataType::LargeUtf8 => {\n                let array = as_string_array(array);\n                let hexed: StringArray = array\n                    .iter()\n                    .map(|v| v.map(|b| hex_bytes(b, lowercase)).transpose())\n                    .collect::<Result<_, _>>()?;\n                Ok(ColumnarValue::Array(Arc::new(hexed)))\n            }\n            DataType::Binary => {\n                let array = as_string_array(array);\n                let hexed: StringArray = array\n                    .iter()\n                    .map(|v| v.map(|b| hex_bytes(b, lowercase)).transpose())\n                    .collect::<Result<_, _>>()?;\n                Ok(ColumnarValue::Array(Arc::new(hexed)))\n            }\n            DataType::Dictionary(_, value_type) => {\n                let dict = as_dictionary_array::<Int32Type>(&array);\n                let values = match **value_type {\n                    DataType::Int64 => as_int64_array(dict.values())?\n                        .iter()\n                        .map(|v| v.map(hex_int64))\n                        .collect::<Vec<_>>(),\n                    DataType::Utf8 => as_string_array(dict.values())\n                        .iter()\n                        .map(|v| v.map(|b| hex_bytes(b, lowercase)).transpose())\n                        .collect::<Result<_, _>>()?,\n                    _ => exec_err!(\""hex got an unexpected argument type: {:?}\"", array.data_type())?,\n                };\n                let new_values: Vec<Option<String>> = dict\n                    .keys()\n                    .iter()\n                    .map(|key| key.map(|k| values[k as usize].clone()).unwrap_or(None))\n                    .collect();\n                let string_array_values = StringArray::from(new_values);\n                Ok(ColumnarValue::Array(Arc::new(string_array_values)))\n            }\n            _ => exec_err!(\""hex got an unexpected argument type: {:?}\"", array.data_type()),\n        },\n        _ => exec_err!(\""native hex does not support scalar values at this time\""),\n    }\n}\n\nfn hex_int64(num: i64) -> String {\n    format!(\""{num:X}\"")\n}\n\nfn hex_encode<T: AsRef<[u8]>>(data: T, lower_case: bool) -> String {\n    let mut s = String::with_capacity(data.as_ref().len() * 2);\n    if lower_case {\n        for b in data.as_ref() {\n            write!(&mut s, \""{b:02x}\"").unwrap();\n        }\n    } else {\n        for b in data.as_ref() {\n            write!(&mut s, \""{b:02X}\"").unwrap();\n        }\n    }\n    s\n}\n\nfn hex_bytes<T: AsRef<[u8]>>(bytes: T, lowercase: bool) -> Result<String, std::fmt::Error> {\n    let hex_string = hex_encode(bytes, lowercase);\n    Ok(hex_string)\n}"", ""code_to_test"": ""pub fn spark_hex(args: &[ColumnarValue]) -> Result<ColumnarValue, DataFusionError> {\n    compute_hex(args, false)\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn test_dictionary_hex_utf8() {\n    let mut input_builder = StringDictionaryBuilder::<Int32Type>::new();\n    input_builder.append_value(\""hi\"");\n    input_builder.append_value(\""bye\"");\n    input_builder.append_null();\n    input_builder.append_value(\""rust\"");\n    let input = input_builder.finish();\n\n    let mut string_builder = StringBuilder::new();\n    string_builder.append_value(\""6869\"");\n    string_builder.append_value(\""627965\"");\n    string_builder.append_null();\n    string_builder.append_value(\""72757374\"");\n    let expected = string_builder.finish();\n\n    let columnar_value = ColumnarValue::Array(Arc::new(input));\n    let result = super::spark_hex(&[columnar_value]).unwrap();\n\n    let result = match result {\n        ColumnarValue::Array(array) => array,\n        _ => panic!(\""Expected array\""),\n    };\n\n    let result = as_string_array(&result);\n\n    assert_eq!(result, &expected);\n}"", ""#[test]\nfn test_dictionary_hex_int64() {\n    let mut input_builder = PrimitiveDictionaryBuilder::<Int32Type, Int64Type>::new();\n    input_builder.append_value(1);\n    input_builder.append_value(2);\n    input_builder.append_null();\n    input_builder.append_value(3);\n    let input = input_builder.finish();\n\n    let mut string_builder = StringBuilder::new();\n    string_builder.append_value(\""1\"");\n    string_builder.append_value(\""2\"");\n    string_builder.append_null();\n    string_builder.append_value(\""3\"");\n    let expected = string_builder.finish();\n\n    let columnar_value = ColumnarValue::Array(Arc::new(input));\n    let result = super::spark_hex(&[columnar_value]).unwrap();\n\n    let result = match result {\n        ColumnarValue::Array(array) => array,\n        _ => panic!(\""Expected array\""),\n    };\n\n    let result = as_string_array(&result);\n\n    assert_eq!(result, &expected);\n}"", ""#[test]\nfn test_dictionary_hex_binary() {\n    let mut input_builder = BinaryDictionaryBuilder::<Int32Type>::new();\n    input_builder.append_value(\""1\"");\n    input_builder.append_value(\""j\"");\n    input_builder.append_null();\n    input_builder.append_value(\""3\"");\n    let input = input_builder.finish();\n\n    let mut expected_builder = StringBuilder::new();\n    expected_builder.append_value(\""31\"");\n    expected_builder.append_value(\""6A\"");\n    expected_builder.append_null();\n    expected_builder.append_value(\""33\"");\n    let expected = expected_builder.finish();\n\n    let columnar_value = ColumnarValue::Array(Arc::new(input));\n    let result = super::spark_hex(&[columnar_value]).unwrap();\n\n    let result = match result {\n        ColumnarValue::Array(array) => array,\n        _ => panic!(\""Expected array\""),\n    };\n\n    let result = as_string_array(&result);\n\n    assert_eq!(result, &expected);\n}"", ""#[test]\nfn test_hex_int64() {\n    let num = 1234;\n    let hexed = super::hex_int64(num);\n    assert_eq!(hexed, \""4D2\"".to_string());\n\n    let num = -1;\n    let hexed = super::hex_int64(num);\n    assert_eq!(hexed, \""FFFFFFFFFFFFFFFF\"".to_string());\n}"", ""#[test]\nfn test_spark_hex_int64() {\n    let int_array = Int64Array::from(vec![Some(1), Some(2), None, Some(3)]);\n    let columnar_value = ColumnarValue::Array(Arc::new(int_array));\n\n    let result = super::spark_hex(&[columnar_value]).unwrap();\n    let result = match result {\n        ColumnarValue::Array(array) => array,\n        _ => panic!(\""Expected array\""),\n    };\n\n    let string_array = as_string_array(&result);\n    let expected_array = StringArray::from(vec![\n        Some(\""1\"".to_string()),\n        Some(\""2\"".to_string()),\n        None,\n        Some(\""3\"".to_string()),\n    ]);\n\n    assert_eq!(string_array, &expected_array);\n}""]}",test_generation
datafusion-spark,"{""code_context"": ""use arrow::array::{ArrayAccessor, ArrayIter, ArrayRef, Int32Array};\nuse arrow::datatypes::DataType;\nuse datafusion_common::{internal_err, Result, ScalarValue};\nuse datafusion_expr::ColumnarValue;\n\nfn calculate_ascii<'a, V>(array: V) -> Result<ArrayRef, ArrowError>\nwhere\n    V: ArrayAccessor<Item = &'a str>,\n{\n    let iter = ArrayIter::new(array);\n    let result = iter\n        .map(|string| {\n            string.map(|s| {\n                let mut chars = s.chars();\n                chars.next().map_or(0, |v| v as i32)\n            })\n        })\n        .collect::<Int32Array>();\n\n    Ok(Arc::new(result) as ArrayRef)\n}"", ""code_to_test"": ""pub fn ascii(args: &[ArrayRef]) -> Result<ArrayRef> {\n    match args[0].data_type() {\n        DataType::Utf8 => {\n            let string_array = args[0].as_string::<i32>();\n            Ok(calculate_ascii(string_array)?)\n        }\n        DataType::LargeUtf8 => {\n            let string_array = args[0].as_string::<i64>();\n            Ok(calculate_ascii(string_array)?)\n        }\n        DataType::Utf8View => {\n            let string_array = args[0].as_string_view();\n            Ok(calculate_ascii(string_array)?)\n        }\n        _ => internal_err!(\""Unsupported data type\""),\n    }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn test_ascii_invoke() -> Result<()> {\n    test_ascii_string_invoke!(Some(String::from(\""x\"")), Ok(Some(120)));\n    test_ascii_string_invoke!(Some(String::from(\""a\"")), Ok(Some(97)));\n    test_ascii_string_invoke!(Some(String::from(\""\"")), Ok(Some(0)));\n    test_ascii_string_invoke!(Some(String::from(\""\\n\"")), Ok(Some(10)));\n    test_ascii_string_invoke!(Some(String::from(\""\\t\"")), Ok(Some(9)));\n    test_ascii_string_invoke!(None, Ok(None));\n\n    Ok(())\n}""]}",test_generation
convert_case,"{""query"": ""How can I convert a string to snake case using the convert_case crate?"", ""code_context"": null}","{""code_snippet"": ""use convert_case::{Case, Casing};\n\nfn main() {\n    let input = \""Hello World Example\"";\n    let result = input.to_case(Case::Snake);\n    println!(\""{}\"", result);\n}""}",code_search
convert_case,"{""query"": ""How do I convert a kebab‑case identifier to Title case?"", ""code_context"": null}","{""code_snippet"": ""use convert_case::{Case, Casing};\n\nfn main() {\n    let input = \""my-variable-name\"";\n    let result = input.from_case(Case::Kebab).to_case(Case::Title);\n    println!(\""{}\"", result);\n}""}",code_search
convert_case,"{""query"": ""How can I define a custom delimiter (dot) and convert a string to lower case with underscores?"", ""code_context"": null}","{""code_snippet"": ""use convert_case::{Boundary, Case, Casing, Converter};\n\nfn main() {\n    let conv = Converter::new()\n        .set_boundaries(&[Boundary::from_delim(\"".\"")])\n        .set_pattern(convert_case::pattern::lowercase)\n        .set_delim(\""_\"");\n    let result = conv.convert(\""my.custom.string\"");\n    println!(\""{}\"", result);\n}""}",code_search
convert_case,"{""query"": ""How do I convert a string containing an acronym to Pascal case while preserving the acronym?"", ""code_context"": null}","{""code_snippet"": ""use convert_case::{Case, Casing};\n\nfn main() {\n    let input = \""XMLHttpRequest\"";\n    let result = input.to_case(Case::Pascal);\n    println!(\""{}\"", result);\n}""}",code_search
convert_case,"{""query"": ""How can I remove digit‑letter boundaries when converting to snake case?"", ""code_context"": null}","{""code_snippet"": ""use convert_case::{Boundary, Case, Casing};\n\nfn main() {\n    let result = \""scale2D\""\n        .from_case(Case::Camel)\n        .without_boundaries(&Boundary::digits())\n        .to_case(Case::Snake);\n    println!(\""{}\"", result);\n}""}",code_search
fragile,"{""code"": ""value: ManuallyDrop::new(value),"", ""code_context"": ""use std::mem::ManuallyDrop;\nuse std::thread::ThreadId;\n\npub struct Fragile<T> {\n    value: ManuallyDrop<T>,\n    thread_id: ThreadId,\n}""}","{""commented_code"": ""// ManuallyDrop is necessary because we need to move out of here without running the Drop code in functions like `into_inner`.\nvalue: ManuallyDrop::new(value),""}",comment_generation
fragile,"{""code"": ""unsafe { ManuallyDrop::drop(&mut self.value) }"", ""code_context"": ""use std::mem::ManuallyDrop;\n\nimpl<T> Drop for Fragile<T> {\n    fn drop(&mut self) {\n        if std::mem::needs_drop::<T>() {\n            if self.is_valid() {\n                // SAFETY: `ManuallyDrop::drop` cannot be called after this point.\n                unsafe { ManuallyDrop::drop(&mut self.value) };\n            } else {\n                panic!(\""destructor of fragile object ran on wrong thread\"");\n            }\n        }\n    }\n}\n\nimpl<T> Fragile<T> {\n    fn is_valid(&self) -> bool { true }\n}""}","{""commented_code"": ""// SAFETY: `ManuallyDrop::drop` cannot be called after this point.\nunsafe { ManuallyDrop::drop(&mut self.value) }""}",comment_generation
fragile,"{""code"": ""drop(unsafe { Box::from_raw(ptr) });"", ""code_context"": ""mod registry {\n    pub struct Entry {\n        pub ptr: *mut (),\n        pub drop: unsafe fn(*mut ()),\n    }\n}\n\nfn example<T>(value: T) {\n    let entry = registry::Entry {\n        ptr: Box::into_raw(Box::new(value)).cast(),\n        drop: |ptr| {\n            let ptr = ptr.cast::<T>();\n            // SAFETY: This callback will only be called once, with the above pointer.\n            drop(unsafe { Box::from_raw(ptr) });\n        },\n    };\n    let _ = entry;\n}""}","{""commented_code"": ""// SAFETY: This callback will only be called once, with the above pointer.\ndrop(unsafe { Box::from_raw(ptr) });""}",comment_generation
fragile,"{""code_before"": ""pub fn get(&self) -> &T {\n    self.assert_thread();\n    &self.value\n}\n\npub fn get_mut(&mut self) -> &mut T {\n    self.assert_thread();\n    &mut self.value\n}"", ""code_context"": ""use std::mem::ManuallyDrop;\nuse std::thread;\nuse crate::errors::InvalidThreadAccess;\n\npub struct Fragile<T> {\n    value: ManuallyDrop<T>,\n    thread_id: std::thread::ThreadId,\n}\n\nimpl<T> Fragile<T> {\n    pub fn is_valid(&self) -> bool {\n        thread::current().id() == self.thread_id\n    }\n\n    #[track_caller]\n    fn assert_thread(&self) {\n        if !self.is_valid() {\n            panic!(\""trying to access wrapped value in fragile container from incorrect thread.\"");\n        }\n    }\n\n    // --- original buggy getters ---\n    // pub fn get(&self) -> &T {\n    //     self.assert_thread();\n    //     &self.value\n    // }\n    //\n    // pub fn get_mut(&mut self) -> &mut T {\n    //     self.assert_thread();\n    //     &mut self.value\n    // }\n\n    // --- corrected getters (shown in the data point) ---\n    // pub fn get(&self) -> &T {\n    //     self.assert_thread();\n    //     &*self.value\n    // }\n    //\n    // pub fn get_mut(&mut self) -> &mut T {\n    //     self.assert_thread();\n    //     &mut *self.value\n    // }\n\n    pub fn try_get(&self) -> Result<&T, InvalidThreadAccess> {\n        if self.is_valid() {\n            Ok(&*self.value)\n        } else {\n            Err(InvalidThreadAccess)\n        }\n    }\n\n    pub fn try_get_mut(&mut self) -> Result<&mut T, InvalidThreadAccess> {\n        if self.is_valid() {\n            Ok(&mut *self.value)\n        } else {\n            Err(InvalidThreadAccess)\n        }\n    }\n}""}","{""code_after"": ""pub fn get(&self) -> &T {\n    self.assert_thread();\n    &*self.value\n}\n\npub fn get_mut(&mut self) -> &mut T {\n    self.assert_thread();\n    &mut *self.value\n}"", ""review_comment"": ""The original `get` and `get_mut` returned references to the `ManuallyDrop<T>` field, which does not match the declared return type `&T`/`&mut T`. Dereferencing the `ManuallyDrop` (`&*self.value` and `&mut *self.value`) yields the actual inner value, fixing the type mismatch and preventing potential misuse of the wrapper type.""}",code_review
fragile,"{""code_before"": ""pub fn into_inner(self) -> T {\n    self.assert_thread();\n\n    let mut this = ManuallyDrop::new(self);\n\n    // SAFETY: `this` is not accessed beyond this point, and because it's in a ManuallyDrop its\n    // destructor is not run.\n    unsafe { ManuallyDrop::take(&mut this.value) }\n}"", ""code_context"": ""use std::mem::ManuallyDrop;\nuse std::thread;\nuse crate::errors::InvalidThreadAccess;\n\npub struct Fragile<T> {\n    value: ManuallyDrop<T>,\n    thread_id: std::thread::ThreadId,\n}\n\nimpl<T> Fragile<T> {\n    pub fn is_valid(&self) -> bool {\n        thread::current().id() == self.thread_id\n    }\n\n    #[track_caller]\n    fn assert_thread(&self) {\n        if !self.is_valid() {\n            panic!(\""trying to access wrapped value in fragile container from incorrect thread.\"");\n        }\n    }\n\n    pub fn into_inner(self) -> T {\n        self.assert_thread();\n        // original version (shown in the data point) used an extra ManuallyDrop wrapper.\n        // unsafe { ManuallyDrop::take(&mut ManuallyDrop::new(self).value) }\n        // simplified version (shown in the data point):\n        unsafe { ManuallyDrop::into_inner(self.value) }\n    }\n\n    pub fn get(&self) -> &T {\n        self.assert_thread();\n        &*self.value\n    }\n\n    pub fn get_mut(&mut self) -> &mut T {\n        self.assert_thread();\n        &mut *self.value\n    }\n}""}","{""code_after"": ""pub fn into_inner(self) -> T {\n    self.assert_thread();\n    // SAFETY: `self` is consumed, so we can safely extract the inner value.\n    unsafe { ManuallyDrop::into_inner(self.value) }\n}"", ""review_comment"": ""The original implementation created an extra `ManuallyDrop` wrapper around `self` and then used `ManuallyDrop::take`. Since `self` is already being moved, we can directly call `ManuallyDrop::into_inner` on the `value` field, eliminating unnecessary allocation and making the code clearer.""}",code_review
fragile,"{""code_before"": ""pub fn is_valid(&self) -> bool {\n    thread::current().id() == self.thread_id\n}"", ""code_context"": ""use std::thread;\n\npub struct Fragile<T> {\n    value: std::mem::ManuallyDrop<T>,\n    thread_id: std::thread::ThreadId,\n}\n\nimpl<T> Fragile<T> {\n    #[inline]\n    pub fn is_valid(&self) -> bool {\n        thread::current().id() == self.thread_id\n    }\n\n    #[track_caller]\n    fn assert_thread(&self) {\n        if !self.is_valid() {\n            panic!(\""trying to access wrapped value in fragile container from incorrect thread.\"");\n        }\n    }\n}""}","{""code_after"": ""#[inline]\npub fn is_valid(&self) -> bool {\n    thread::current().id() == self.thread_id\n}"", ""review_comment"": ""Marking `is_valid` with `#[inline]` hints the compiler to inline this tiny, frequently called function, reducing call overhead and potentially enabling further optimizations in hot paths.""}",code_review
quanta,"{""code"": ""impl Instant {\\n    pub fn now() -> Instant {\\n        crate::get_now()\\n    }\\n}"", ""code_context"": ""pub struct Instant(pub(crate) u64);""}","{""docstring"": ""Gets the current time, scaled to reference time.\\n\\nThis method depends on a lazily initialized global clock, which can take up to 200ms to initialize and calibrate itself.\\n\\nThis method is the spiritual equivalent of [`Instant::now`][instant_now].  It is guaranteed to return a monotonically increasing value.\\n\\n[instant_now]: std::time::Instant::now""}",docstring_generation
quanta,"{""code"": ""impl Instant {\\n    pub fn recent() -> Instant {\\n        crate::get_recent()\\n    }\\n}"", ""code_context"": ""pub struct Instant(pub(crate) u64);""}","{""docstring"": ""Gets the most recent current time, scaled to reference time.\\n\\nThis method provides ultra-low-overhead access to a slightly-delayed version of the current time.  Instead of querying the underlying source clock directly, a shared, global value is read directly without the need to scale to reference time.\\n\\nThe value is updated by running an \\\""upkeep\\\"" thread or by calling [`set_recent`][set_recent].\\n\\nIf the upkeep thread has not been started, or no value has been set manually, a lazily initialized global clock will be used to get the current time.  This clock can take up to 200ms to initialize and calibrate itself.\\n\\n[set_recent]: crate::set_recent""}",docstring_generation
quanta,"{""code"": ""impl Instant {\\n    pub fn duration_since(&self, earlier: Instant) -> Duration {\\n        self.checked_duration_since(earlier).unwrap_or_default()\\n    }\\n}"", ""code_context"": ""pub struct Instant(pub(crate) u64);""}","{""docstring"": ""Returns the amount of time elapsed from another instant to this one.\\n\\n# Panics\\n\\nPrevious versions of this method panicked when earlier was later than `self`. Currently, this method saturates to zero. Future versions may reintroduce the panic in some circumstances. See [Monotonicity].\\n\\n[Monotonicity]: Instant#monotonicity\\n\\n# Examples\\n\\n```no_run\\nuse quanta::Clock;\\nuse std::time::Duration;\\nuse std::thread::sleep;\\n\\nlet mut clock = Clock::new();\\nlet now = clock.now();\\nsleep(Duration::new(1, 0));\\nlet new_now = clock.now();\\nprintln!(\""{:?}\"", new_now.duration_since(now));\\n```""}",docstring_generation
datafusion-catalog-listing,"{""buggy_code"": ""pub fn expr_applicable_for_cols(col_names: &[&str], expr: &Expr) -> bool {\n    let mut is_applicable = true;\n    expr.apply(|expr| match expr {\n        Expr::Column(Column { ref name, .. }) => {\n            is_applicable &= col_names.contains(&name.as_str());\n            if is_applicable {\n                Ok(TreeNodeRecursion::Jump)\n            } else {\n                Ok(TreeNodeRecursion::Stop)\n            }\n        }\n        // other variants are treated as Continue\n        Expr::Literal(_, _)\n        | Expr::Alias(_)\n        | Expr::OuterReferenceColumn(_, _)\n        | Expr::ScalarVariable(_, _)\n        | Expr::Not(_)\n        | Expr::IsNotNull(_)\n        | Expr::IsNull(_)\n        | Expr::IsTrue(_)\n        | Expr::IsFalse(_)\n        | Expr::IsUnknown(_)\n        | Expr::IsNotTrue(_)\n        | Expr::IsNotFalse(_)\n        | Expr::IsNotUnknown(_)\n        | Expr::Negative(_)\n        | Expr::Cast(_)\n        | Expr::TryCast(_)\n        | Expr::BinaryExpr(_)\n        | Expr::Between(_)\n        | Expr::Like(_)\n        | Expr::SimilarTo(_)\n        | Expr::InList(_)\n        | Expr::Exists(_)\n        | Expr::InSubquery(_)\n        | Expr::ScalarSubquery(_)\n        | Expr::GroupingSet(_)\n        | Expr::Case(_) => Ok(TreeNodeRecursion::Continue),\n        Expr::ScalarFunction(scalar_function) => {\n            match scalar_function.func.signature().volatility {\n                Volatility::Immutable => Ok(TreeNodeRecursion::Continue),\n                Volatility::Stable | Volatility::Volatile => {\n                    is_applicable = false;\n                    Ok(TreeNodeRecursion::Stop)\n                }\n            }\n        }\n        // TODO other expressions are not handled yet:\n        // - AGGREGATE and WINDOW should not end up in filter conditions, except maybe in some edge cases\n        // - Can `Wildcard` be considered as a `Literal`?\n        // - ScalarVariable could be `applicable`, but that would require access to the context\n        // TODO: remove the next line after `Expr::Wildcard` is removed\n        #[expect(deprecated)]\n        Expr::AggregateFunction { .. }\n        | Expr::WindowFunction { .. }\n        | Expr::Wildcard { .. }\n        | Expr::Unnest { .. }\n        | Expr::Placeholder(_) => {\n            is_applicable = false;\n            Ok(TreeNodeRecursion::Stop)\n        }\n    })\n    .unwrap();\n    is_applicable\n}"", ""code_context"": null}","{""fixed_code"": ""pub fn expr_applicable_for_cols(col_names: &[&str], expr: &Expr) -> bool {\n    let mut is_applicable = true;\n    expr.apply(|expr| match expr {\n        Expr::Column(Column { ref name, .. }) => {\n            is_applicable &= col_names.contains(&name.as_str());\n            if is_applicable {\n                Ok(TreeNodeRecursion::Jump)\n            } else {\n                Ok(TreeNodeRecursion::Stop)\n            }\n        }\n        // Expressions that do not depend on columns are always applicable\n        Expr::Literal(_, _)\n        | Expr::Alias(_)\n        | Expr::OuterReferenceColumn(_, _)\n        | Expr::ScalarVariable(_, _)\n        | Expr::Not(_)\n        | Expr::IsNotNull(_)\n        | Expr::IsNull(_)\n        | Expr::IsTrue(_)\n        | Expr::IsFalse(_)\n        | Expr::IsUnknown(_)\n        | Expr::IsNotTrue(_)\n        | Expr::IsNotFalse(_)\n        | Expr::IsNotUnknown(_)\n        | Expr::Negative(_)\n        | Expr::Cast(_)\n        | Expr::TryCast(_)\n        | Expr::BinaryExpr(_)\n        | Expr::Between(_)\n        | Expr::Like(_)\n        | Expr::SimilarTo(_)\n        | Expr::InList(_)\n        | Expr::Exists(_)\n        | Expr::InSubquery(_)\n        | Expr::ScalarSubquery(_)\n        | Expr::GroupingSet(_)\n        | Expr::Case(_) => Ok(TreeNodeRecursion::Continue),\n        Expr::ScalarFunction(scalar_function) => {\n            match scalar_function.func.signature().volatility {\n                Volatility::Immutable => Ok(TreeNodeRecursion::Continue),\n                Volatility::Stable | Volatility::Volatile => {\n                    is_applicable = false;\n                    Ok(TreeNodeRecursion::Stop)\n                }\n            }\n        }\n        // Explicitly reject wildcard and other unsupported expressions\n        Expr::Wildcard { .. } => {\n            is_applicable = false;\n            Ok(TreeNodeRecursion::Stop)\n        }\n        // TODO other expressions are not handled yet:\n        #[expect(deprecated)]\n        Expr::AggregateFunction { .. }\n        | Expr::WindowFunction { .. }\n        | Expr::Unnest { .. }\n        | Expr::Placeholder(_) => {\n            is_applicable = false;\n            Ok(TreeNodeRecursion::Stop)\n        }\n    })\n    .unwrap();\n    is_applicable\n}"", ""bug_description"": ""The original `expr_applicable_for_cols` treats a wildcard expression (`Expr::Wildcard`) as a generic case that falls through to the \""continue\"" branch. This incorrectly marks a filter containing a wildcard as applicable, allowing the planner to push down a filter that cannot be evaluated using only the listed partition columns. The fix adds an explicit match arm for `Expr::Wildcard` that sets `is_applicable` to false and stops traversal, ensuring only truly column‑only expressions are considered applicable.""}",bug_detection
datafusion-catalog-listing,"{""buggy_code"": ""pub fn split_files(\n    mut partitioned_files: Vec<PartitionedFile>,\n    n: usize,\n) -> Vec<Vec<PartitionedFile>> {\n    if partitioned_files.is_empty() {\n        return vec![];\n    }\n\n    // ObjectStore::list does not guarantee any consistent order and for some\n    // implementations such as LocalFileSystem, it may be inconsistent. Thus\n    // Sort files by path to ensure consistent plans when run more than once.\n    partitioned_files.sort_by(|a, b| a.path().cmp(b.path()));\n\n    // effectively this is div with rounding up instead of truncating\n    let chunk_size = partitioned_files.len().div_ceil(n);\n    let mut chunks = Vec::with_capacity(n);\n    let mut current_chunk = Vec::with_capacity(chunk_size);\n    for file in partitioned_files.drain(..) {\n        current_chunk.push(file);\n        if current_chunk.len() == chunk_size {\n            let full_chunk =\n                mem::replace(&mut current_chunk, Vec::with_capacity(chunk_size));\n            chunks.push(full_chunk);\n        }\n    }\n\n    if !current_chunk.is_empty() {\n        chunks.push(current_chunk)\n    }\n\n    chunks\n}"", ""code_context"": null}","{""fixed_code"": ""pub fn split_files(\n    mut partitioned_files: Vec<PartitionedFile>,\n    n: usize,\n) -> Vec<Vec<PartitionedFile>> {\n    // Guard against division by zero – an empty `n` means no splitting.\n    if n == 0 {\n        return vec![];\n    }\n\n    if partitioned_files.is_empty() {\n        return vec![];\n    }\n\n    // ObjectStore::list does not guarantee any consistent order and for some\n    // implementations such as LocalFileSystem, it may be inconsistent. Thus\n    // Sort files by path to ensure consistent plans when run more than once.\n    // Clone the vector to avoid mutating the caller's data.\n    let mut files = partitioned_files.clone();\n    files.sort_by(|a, b| a.path().cmp(b.path()));\n\n    // effectively this is div with rounding up instead of truncating\n    let chunk_size = files.len().div_ceil(n);\n    let mut chunks = Vec::with_capacity(n);\n    let mut current_chunk = Vec::with_capacity(chunk_size);\n    for file in files.into_iter() {\n        current_chunk.push(file);\n        if current_chunk.len() == chunk_size {\n            let full_chunk =\n                mem::replace(&mut current_chunk, Vec::with_capacity(chunk_size));\n            chunks.push(full_chunk);\n        }\n    }\n\n    if !current_chunk.is_empty() {\n        chunks.push(current_chunk);\n    }\n\n    chunks\n}"", ""bug_description"": ""When `n` is zero the original implementation calls `partitioned_files.len().div_ceil(0)`, which panics due to division by zero. Additionally, the function mutates the caller‑provided `partitioned_files` vector by sorting and draining it, which is surprising side‑effect behavior. The fix adds an early return for `n == 0` and works on a cloned, sorted copy of the input, preserving the original vector.""}",bug_detection
datafusion-catalog-listing,"{""buggy_code"": ""pub async fn list_partitions(\n    store: &dyn ObjectStore,\n    table_path: &ListingTableUrl,\n    max_depth: usize,\n    partition_prefix: Option<Path>,\n) -> Result<Vec<Partition>> {\n    let partition = Partition {\n        path: match partition_prefix {\n            Some(prefix) => Path::from_iter(\n                Path::from(table_path.prefix().as_ref())\n                    .parts()\n                    .chain(Path::from(prefix.as_ref()).parts()),\n            ),\n            None => table_path.prefix().clone(),\n        },\n        depth: 0,\n        files: None,\n    };\n\n    let mut out = Vec::with_capacity(64);\n\n    let mut pending = vec![];\n    let mut futures = FuturesUnordered::new();\n    futures.push(partition.list(store));\n\n    while let Some((partition, paths)) = futures.next().await.transpose()? {\n        if let Some(next) = pending.pop() {\n            futures.push(next)\n        }\n\n        let depth = partition.depth;\n        out.push(partition);\n        for path in paths {\n            let child = Partition {\n                path,\n                depth: depth + 1,\n                files: None,\n            };\n            match depth < max_depth {\n                true => match futures.len() < CONCURRENCY_LIMIT {\n                    true => futures.push(child.list(store)),\n                    false => pending.push(child.list(store)),\n                },\n                false => out.push(child),\n            }\n        }\n    }\n    Ok(out)\n}"", ""code_context"": null}","{""fixed_code"": ""pub async fn list_partitions(\n    store: &dyn ObjectStore,\n    table_path: &ListingTableUrl,\n    max_depth: usize,\n    partition_prefix: Option<Path>,\n) -> Result<Vec<Partition>> {\n    let partition = Partition {\n        path: match partition_prefix {\n            Some(prefix) => Path::from_iter(\n                Path::from(table_path.prefix().as_ref())\n                    .parts()\n                    .chain(Path::from(prefix.as_ref()).parts()),\n            ),\n            None => table_path.prefix().clone(),\n        },\n        depth: 0,\n        files: None,\n    };\n\n    let mut out = Vec::with_capacity(64);\n\n    let mut pending = vec![];\n    let mut futures = FuturesUnordered::new();\n    futures.push(partition.list(store));\n\n    while let Some((partition, paths)) = futures.next().await.transpose()? {\n        if let Some(next) = pending.pop() {\n            futures.push(next)\n        }\n\n        let depth = partition.depth;\n        out.push(partition);\n        for path in paths {\n            let child = Partition {\n                path,\n                depth: depth + 1,\n                files: None,\n            };\n            if depth < max_depth {\n                // Recurse only when we are still below the requested depth.\n                match futures.len() < CONCURRENCY_LIMIT {\n                    true => futures.push(child.list(store)),\n                    false => pending.push(child.list(store)),\n                }\n            } else {\n                // Do not descend further; simply record the partition without its children.\n                out.push(child);\n            }\n        }\n    }\n    Ok(out)\n}"", ""bug_description"": ""The original `list_partitions` adds child partitions to the output even when `depth >= max_depth`. This violates the contract that the function should return partitions only up to `max_depth`. The corrected version checks the depth before recursing: if the current depth is less than `max_depth` it continues the asynchronous listing, otherwise it records the partition but does not explore its children, ensuring the returned list respects the depth limit.""}",bug_detection
libp2p-tls,"{""code_before"": ""let mut msg = vec![];\nmsg.extend(P2P_SIGNING_PREFIX);\nmsg.extend(certificate_keypair.public_key_der());"", ""code_context"": ""use libp2p_identity as identity;\nconst P2P_SIGNING_PREFIX: [u8; 21] = *b\""libp2p-tls-handshake:\"";\n\nfn make_libp2p_extension(\n    identity_keypair: &identity::Keypair,\n    certificate_keypair: &rcgen::KeyPair,\n) -> Result<rcgen::CustomExtension, rcgen::Error> {\n    unimplemented!()\n}""}","{""code_after"": ""let pubkey_der = certificate_keypair.public_key_der();\nlet mut msg = Vec::with_capacity(P2P_SIGNING_PREFIX.len() + pubkey_der.len());\nmsg.extend_from_slice(P2P_SIGNING_PREFIX);\nmsg.extend_from_slice(pubkey_der);"", ""review_comment"": ""Pre-allocate vector capacity to avoid reallocations. Since we know the exact size needed (prefix + public key DER), this eliminates potential heap reallocations and zero-fill operations. The `extend_from_slice` calls are also more efficient than generic `extend` and clearly communicate byte-oriented operations.""}",code_review
libp2p-tls,"{""code_before"": ""let Some([cert]) = state.peer_certificates() else {\n    panic!(\""config enforces exactly one certificate\"");\n};"", ""code_context"": ""use rustls::CommonState;\nuse crate::certificate;\nuse webpki;\n\nfn extract_single_certificate(\n    state: &CommonState,\n) -> Result<certificate::P2pCertificate<'_>, certificate::ParseError> {\n    let [cert] = state.peer_certificates() else {\n        return Err(certificate::ParseError(webpki::Error::BadDer));\n    };\n    certificate::parse(cert)\n}""}","{""code_after"": ""let [cert] = state.peer_certificates() else {\n    return Err(certificate::ParseError(webpki::Error::BadDer));\n};"", ""review_comment"": ""Replace panic with proper error propagation. While the configuration intends to enforce a single certificate, panics are unacceptable in library code as they crash the entire application. Returning a specific error (BadDer) maintains safety guarantees while providing recoverable error handling for callers. The panic also violated Rust's 'fail early but gracefully' principle for library APIs.""}",code_review
libp2p-tls,"{""code_before"": ""if pki_algorithm.algorithm == OID_PKCS1_RSAENCRYPTION {\n    if signature_algorithm.algorithm == OID_PKCS1_SHA256WITHRSA {\n        return Ok(RSA_PKCS1_SHA256);\n    }\n    if signature_algorithm.algorithm == OID_PKCS1_SHA384WITHRSA {\n        return Ok(RSA_PKCS1_SHA384);\n    }\n    // ... (10+ more nested if conditions) ...\n}\n\nif pki_algorithm.algorithm == OID_KEY_TYPE_EC_PUBLIC_KEY {\n    // ... (more nested ifs) ...\n}"", ""code_context"": ""mod oid_registry {\n    pub const OID_PKCS1_RSAENCRYPTION: u32 = 0;\n    pub const OID_PKCS1_SHA256WITHRSA: u32 = 0;\n    pub const OID_PKCS1_SHA384WITHRSA: u32 = 0;\n    pub const OID_PKCS1_SHA512WITHRSA: u32 = 0;\n    pub const OID_PKCS1_RSASSAPSS: u32 = 0;\n    pub const OID_KEY_TYPE_EC_PUBLIC_KEY: u32 = 0;\n}\nuse oid_registry::*;\nuse rustls::SignatureScheme;\nuse webpki::Error;\n\nstruct AlgorithmIdentifier {\n    algorithm: u32,\n}\nstruct SubjectPki {\n    algorithm: AlgorithmIdentifier,\n}\nstruct TbsCertificate {\n    subject_pki: SubjectPki,\n}\nstruct Certificate {\n    signature_algorithm: AlgorithmIdentifier,\n    tbs_certificate: TbsCertificate,\n}\nstruct P2pCertificate<'a> {\n    certificate: Certificate,\n}\nimpl P2pCertificate<'_> {\n    fn signature_scheme(&self) -> Result<SignatureScheme, Error> {\n        let signature_algorithm = &self.certificate.signature_algorithm;\n        let pki_algorithm = &self.certificate.tbs_certificate.subject_pki.algorithm;\n        match &pki_algorithm.algorithm {\n            oid if oid == &OID_PKCS1_RSAENCRYPTION => match &signature_algorithm.algorithm {\n                oid if oid == &OID_PKCS1_SHA256WITHRSA => return Ok(SignatureScheme::RSA_PKCS1_SHA256),\n                oid if oid == &OID_PKCS1_SHA384WITHRSA => return Ok(SignatureScheme::RSA_PKCS1_SHA384),\n                _ => return Err(Error::UnsupportedSignatureAlgorithm),\n            },\n            oid if oid == &OID_KEY_TYPE_EC_PUBLIC_KEY => {\n                unimplemented!()\n            },\n            _ => return Err(Error::UnsupportedSignatureAlgorithm),\n        }\n    }\n}""}","{""code_after"": ""match &pki_algorithm.algorithm {\n    oid if oid == &OID_PKCS1_RSAENCRYPTION => match &signature_algorithm.algorithm {\n        oid if oid == &OID_PKCS1_SHA256WITHRSA => return Ok(RSA_PKCS1_SHA256),\n        oid if oid == &OID_PKCS1_SHA384WITHRSA => return Ok(RSA_PKCS1_SHA384),\n        // ... (other cases) ...\n        _ => return Err(webpki::Error::UnsupportedSignatureAlgorithm),\n    },\n    oid if oid == &OID_KEY_TYPE_EC_PUBLIC_KEY => {\n        // ... (match-based handling) ...\n    },\n    _ => return Err(webpki::Error::UnsupportedSignatureAlgorithm),\n}"", ""review_comment"": ""Replace nested if-chains with exhaustive match statements. This makes the logic's structure explicit and compiler-verifiable, reducing risk of missed cases. The match approach better expresses intent for signature scheme classification, improves readability by visually grouping related algorithms, and eliminates error-prone manual fallthrough handling. Rust's match ergonomics make this both safer and more maintainable.""}",code_review
simd-adler32,"{""code"": ""impl Adler32 {\n    pub fn write(&mut self, data: &[u8]) {\n        let (a, b) = (self.update)(self.a, self.b, data);\n        self.a = a;\n        self.b = b;\n    }\n}"", ""code_context"": ""use crate::imp::Adler32Imp;\n\npub struct Adler32 {\n    a: u16,\n    b: u16,\n    update: Adler32Imp,\n}\n\ntype Adler32Imp = fn(u16, u16, &[u8]) -> (u16, u16);""}","{""explanation"": ""The `write` method updates the internal Adler-32 state with new data. It calls the implementation function stored in `self.update` (chosen at runtime based on CPU features) passing the current `a` and `b` sums and the byte slice. The returned sums replace the stored state, allowing subsequent calls to continue hashing from the current checksum.""}",code_explanation
simd-adler32,"{""code"": ""pub fn update(a: u16, b: u16, data: &[u8]) -> (u16, u16) {\n    let mut a = a as u32;\n    let mut b = b as u32;\n    let chunks = data.chunks_exact(NMAX);\n    let remainder = chunks.remainder();\n    for chunk in chunks {\n        for byte in chunk {\n            a = a.wrapping_add(*byte as u32);\n            b = b.wrapping_add(a);\n        }\n        a %= MOD;\n        b %= MOD;\n    }\n    for byte in remainder {\n        a = a.wrapping_add(*byte as u32);\n        b = b.wrapping_add(a);\n    }\n    a %= MOD;\n    b %= MOD;\n    (a as u16, b as u16)\n}"", ""code_context"": ""const MOD: u32 = 65521;\nconst NMAX: usize = 5552;""}","{""explanation"": ""This is the scalar fallback implementation of the Adler-32 update function. It processes the input in fixed‑size chunks (`NMAX`) to limit intermediate values, adding each byte to the `a` sum and then adding `a` to the `b` sum. After each chunk it reduces both sums modulo the Adler prime (`MOD`). The final sums are returned as 16‑bit values.""}",code_explanation
simd-adler32,"{""code"": ""pub fn adler32<H: Adler32Hash>(hash: &H) -> u32 {\n    hash.hash()\n}"", ""code_context"": ""pub trait Adler32Hash {\n    fn hash(&self) -> u32;\n}""}","{""explanation"": ""A generic helper that computes the Adler‑32 checksum for any type implementing the `Adler32Hash` trait. It simply forwards the call to the type's `hash` method, allowing slices, strings, arrays, and custom types to be hashed uniformly.""}",code_explanation
sha1_smol,"{""code"": ""impl Sha1 {\n    pub fn new() -> Sha1 {\n        Sha1 {\n            state: DEFAULT_STATE,\n            len: 0,\n            blocks: Blocks {\n                len: 0,\n                block: [0; 64],\n            },\n        }\n    }\n}"", ""code_context"": ""use core::cmp;\n\npub const DIGEST_LENGTH: usize = 20;\n\ntype Sha1State = [u32; 5];\npub const DEFAULT_STATE: Sha1State = [0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0];\n\npub struct Sha1 {\n    state: Sha1State,\n    blocks: Blocks,\n    len: u64,\n}\n\npub struct Blocks {\n    len: u32,\n    block: [u8; 64],\n}\n\npub struct Digest {\n    data: Sha1State,\n}\n\nunsafe fn as_block(input: &[u8]) -> &[u8; 64] {\n    assert!(input.len() == 64);\n    &*(input.as_ptr() as *const [u8; 64])\n}\n\nimpl Blocks {\n    fn input<F>(&mut self, mut input: &[u8], mut f: F)\n    where\n        F: FnMut(&[u8; 64]),\n    {\n        if self.len > 0 {\n            let len = self.len as usize;\n            let amt = core::cmp::min(input.len(), self.block.len() - len);\n            self.block[len..len + amt].clone_from_slice(&input[..amt]);\n            if len + amt == self.block.len() {\n                f(&self.block);\n                self.len = 0;\n                input = &input[amt..];\n            } else {\n                self.len += amt as u32;\n                return;\n            }\n        }\n        assert_eq!(self.len, 0);\n        for chunk in input.chunks(64) {\n            if chunk.len() == 64 {\n                f(as_block(chunk));\n            } else {\n                self.block[..chunk.len()].clone_from_slice(chunk);\n                self.len = chunk.len() as u32;\n            }\n        }\n    }\n}\n\nimpl Sha1State {\n    fn process(&mut self, _block: &[u8; 64]) {\n        // implementation omitted for brevity\n    }\n}""}","{""summary"": ""Creates a new Sha1 object with the default initial state.""}",code_summarization
sha1_smol,"{""code"": ""impl Sha1 {\n    pub fn update(&mut self, data: &[u8]) {\n        let len = &mut self.len;\n        let state = &mut self.state;\n        self.blocks.input(data, |block| {\n            *len += block.len() as u64;\n            state.process(block);\n        })\n    }\n}"", ""code_context"": ""use core::cmp;\n\npub const DIGEST_LENGTH: usize = 20;\n\ntype Sha1State = [u32; 5];\npub const DEFAULT_STATE: Sha1State = [0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0];\n\npub struct Sha1 {\n    state: Sha1State,\n    blocks: Blocks,\n    len: u64,\n}\n\npub struct Blocks {\n    len: u32,\n    block: [u8; 64],\n}\n\npub struct Digest {\n    data: Sha1State,\n}\n\nunsafe fn as_block(input: &[u8]) -> &[u8; 64] {\n    assert!(input.len() == 64);\n    &*(input.as_ptr() as *const [u8; 64])\n}\n\nimpl Blocks {\n    fn input<F>(&mut self, mut input: &[u8], mut f: F)\n    where\n        F: FnMut(&[u8; 64]),\n    {\n        if self.len > 0 {\n            let len = self.len as usize;\n            let amt = core::cmp::min(input.len(), self.block.len() - len);\n            self.block[len..len + amt].clone_from_slice(&input[..amt]);\n            if len + amt == self.block.len() {\n                f(&self.block);\n                self.len = 0;\n                input = &input[amt..];\n            } else {\n                self.len += amt as u32;\n                return;\n            }\n        }\n        assert_eq!(self.len, 0);\n        for chunk in input.chunks(64) {\n            if chunk.len() == 64 {\n                f(as_block(chunk));\n            } else {\n                self.block[..chunk.len()].clone_from_slice(chunk);\n                self.len = chunk.len() as u32;\n            }\n        }\n    }\n}\n\nimpl Sha1State {\n    fn process(&mut self, _block: &[u8; 64]) {\n        // implementation omitted for brevity\n    }\n}""}","{""summary"": ""Updates the Sha1 hash with input data, processing it in 64‑byte blocks.""}",code_summarization
sha1_smol,"{""code"": ""impl Sha1 {\n    pub fn digest(&self) -> Digest {\n        let mut state = self.state;\n        let bits = (self.len + (self.blocks.len as u64)) * 8;\n        let extra = [\n            (bits >> 56) as u8,\n            (bits >> 48) as u8,\n            (bits >> 40) as u8,\n            (bits >> 32) as u8,\n            (bits >> 24) as u8,\n            (bits >> 16) as u8,\n            (bits >> 8) as u8,\n            (bits >> 0) as u8,\n        ];\n        let mut last = [0u8; 128];\n        let blocklen = self.blocks.len as usize;\n        last[..blocklen].clone_from_slice(&self.blocks.block[..blocklen]);\n        last[blocklen] = 0x80;\n        if blocklen < 56 {\n            last[56..64].clone_from_slice(&extra);\n            state.process(as_block(&last[0..64]));\n        } else {\n            last[120..128].clone_from_slice(&extra);\n            state.process(as_block(&last[0..64]));\n            state.process(as_block(&last[64..128]));\n        }\n        Digest { data: state }\n    }\n}"", ""code_context"": ""use core::cmp;\n\npub const DIGEST_LENGTH: usize = 20;\n\ntype Sha1State = [u32; 5];\npub const DEFAULT_STATE: Sha1State = [0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0];\n\npub struct Sha1 {\n    state: Sha1State,\n    blocks: Blocks,\n    len: u64,\n}\n\npub struct Blocks {\n    len: u32,\n    block: [u8; 64],\n}\n\npub struct Digest {\n    data: Sha1State,\n}\n\nunsafe fn as_block(input: &[u8]) -> &[u8; 64] {\n    assert!(input.len() == 64);\n    &*(input.as_ptr() as *const [u8; 64])\n}\n\nimpl Blocks {\n    fn input<F>(&mut self, mut input: &[u8], mut f: F)\n    where\n        F: FnMut(&[u8; 64]),\n    {\n        if self.len > 0 {\n            let len = self.len as usize;\n            let amt = core::cmp::min(input.len(), self.block.len() - len);\n            self.block[len..len + amt].clone_from_slice(&input[..amt]);\n            if len + amt == self.block.len() {\n                f(&self.block);\n                self.len = 0;\n                input = &input[amt..];\n            } else {\n                self.len += amt as u32;\n                return;\n            }\n        }\n        assert_eq!(self.len, 0);\n        for chunk in input.chunks(64) {\n            if chunk.len() == 64 {\n                f(as_block(chunk));\n            } else {\n                self.block[..chunk.len()].clone_from_slice(chunk);\n                self.len = chunk.len() as u32;\n            }\n        }\n    }\n}\n\nimpl Sha1State {\n    fn process(&mut self, _block: &[u8; 64]) {\n        // implementation omitted for brevity\n    }\n}""}","{""summary"": ""Finalizes the hash computation and returns the SHA‑1 digest.""}",code_summarization
radix_trie,"{""code"": ""impl<K, V> Trie<K, V>\nwhere\n    K: TrieKey,\n{\n    pub fn insert(&mut self, key: K, value: V) -> Option<V> {\n        let key_fragments = key.encode();\n        let result = self.node.insert(key, value, key_fragments);\n        if result.is_none() {\n            self.length += 1;\n        }\n        result\n    }\n}"", ""code_context"": ""use crate::TrieNode;\nuse crate::TrieKey;\n\npub struct Trie<K, V> {\n    length: usize,\n    node: TrieNode<K, V>,\n}""}","{""summary"": ""Inserts a key-value pair into the trie, returning any previous value.""}",code_summarization
radix_trie,"{""code"": ""pub fn match_keys(start_idx: usize, first: &Nibblet, second: &Nibblet) -> KeyMatch {\n    let first_len = first.len() - start_idx;\n    let min_length = ::std::cmp::min(first_len, second.len());\n\n    for i in 0..min_length {\n        if first.get(start_idx + i) != second.get(i) {\n            return KeyMatch::Partial(i);\n        }\n    }\n\n    match (first_len, second.len()) {\n        (x, y) if x < y => KeyMatch::FirstPrefix,\n        (x, y) if x == y => KeyMatch::Full,\n        _ => KeyMatch::SecondPrefix,\n    }\n}"", ""code_context"": ""use nibble_vec::Nibblet;\n\npub enum KeyMatch {\n    Partial(usize),\n    FirstPrefix,\n    SecondPrefix,\n    Full,\n}""}","{""summary"": ""Compares two encoded keys starting at an offset and returns their match relationship.""}",code_summarization
radix_trie,"{""code"": ""impl<'a, K, V> SubTrieMut<'a, K, V>\nwhere\n    K: TrieKey,\n{\n    pub fn insert(&mut self, key: K, value: V) -> SubTrieResult<V> {\n        let key_enc = key.encode();\n        let previous = match match_keys(0, &self.prefix, &key_enc) {\n            KeyMatch::Full => self.node.replace_value(key, value),\n            KeyMatch::FirstPrefix => self.node.insert(key, value, stripped(key_enc, &self.prefix)),\n            _ => {\n                return Err(());\n            }\n        };\n\n        if previous.is_none() {\n            *self.length += 1;\n        }\n\n        Ok(previous)\n    }\n}"", ""code_context"": ""use crate::TrieKey;\nuse crate::SubTrieResult;\nuse crate::keys::match_keys;\nuse crate::keys::KeyMatch;\nuse crate::TrieNode;\nuse nibble_vec::Nibblet;\n\npub struct SubTrieMut<'a, K: 'a, V: 'a> {\n    prefix: Nibblet,\n    length: &'a mut usize,\n    node: &'a mut TrieNode<K, V>,\n}\n\npub fn stripped(mut key: Nibblet, prefix: &Nibblet) -> Nibblet {\n    key.split(prefix.len())\n}""}","{""summary"": ""Inserts a value into a mutable subtrie, updating length and handling prefix cases.""}",code_summarization
debugid,"{""code"": ""fn parse_str(string: &str, options: ParseOptions) -> Option<DebugId> {"", ""code_context"": ""use std::str::FromStr; use debugid::DebugId; use uuid::Uuid;""}","{""commented_code"": ""// This function parses a string into a DebugId based on the given options. It handles both hyphenated and compact formats.\nfn parse_str(string: &str, options: ParseOptions) -> Option<DebugId> {""}",comment_generation
debugid,"{""code"": ""impl DebugId {"", ""code_context"": ""use std::error; use std::fmt; use uuid::{Bytes, Uuid}; use std::str; use std::fmt::Write;""}","{""commented_code"": ""// Implementation of the DebugId struct, which represents a debug information file identifier.\nimpl DebugId {""}",comment_generation
debugid,"{""code"": ""pub struct ParseOptions {"", ""code_context"": ""use std::str::FromStr; use debugid::DebugId;""}","{""commented_code"": ""// Structure to configure the parsing options for DebugId.\npub struct ParseOptions {""}",comment_generation
debugid,"{""code"": ""let mut new_buf: Vec<u8> = Vec::new();"", ""code_context"": ""use std::io::Copy; use std::slice; use std::ptr;""}","{""commented_code"": ""// Create a new buffer to copy the bytes.\nlet mut new_buf: Vec<u8> = Vec::new();""}",comment_generation
debugid,"{""code"": ""let slice = &[debug_id];"", ""code_context"": ""use std::mem; use std::io::Cursor; use std::io::copy;""}","{""commented_code"": ""// Get a slice of the debug_id.\nlet slice = &[debug_id];""}",comment_generation
byte-slice-cast,"{""code"": ""let __placeholder__ = slice.as_byte_slice();\n\nif cfg!(target_endian = \""big\"") {\n    assert_eq!(__placeholder__, &[1, 2, 3, 4, 5, 6]);\n} else {\n    assert_eq!(__placeholder__, &[2, 1, 4, 3, 6, 5]);\n}\n\nlet converted_back_slice = __placeholder__.as_slice_of::<u16>().unwrap();\n\nassert_eq!(converted_back_slice, &slice);"", ""code_context"": ""use byte_slice_cast::{AsByteSlice, AsSliceOf};""}","{""variable_name"": ""byte_slice""}",variable_naming
byte-slice-cast,"{""code"": ""let mut __placeholder__ = data.as_mut_byte_slice();"", ""code_context"": ""use byte_slice_cast::AsMutByteSlice;""}","{""variable_name"": ""converted_slice""}",variable_naming
byte-slice-cast,"{""code"": ""let __placeholder__ = data.as_byte_slice();"", ""code_context"": ""use byte_slice_cast::AsByteSlice;""}","{""variable_name"": ""bytes""}",variable_naming
byte-slice-cast,"{""code"": ""let __placeholder__ = bytes.as_slice_of::<u16>().unwrap();"", ""code_context"": ""use byte_slice_cast::{AsSliceOf, FromByteSlice};""}","{""variable_name"": ""slice""}",variable_naming
float-cmp,"{""code_context"": ""use super::Ulps;\nuse core::{f32, f64};\n#[cfg(feature = \""num-traits\"")]\n#[allow(unused_imports)]\nuse num_traits::float::FloatCore;\n\n/// A margin specifying a maximum distance two floating point values can be while\n/// still being considered equal enough.\npub trait FloatMargin: Copy + Default {\n    type F;\n    type I;\n    fn zero() -> Self;\n    fn epsilon(self, epsilon: Self::F) -> Self;\n    fn ulps(self, ulps: Self::I) -> Self;\n}\n\n/// A trait for approximate equality comparisons.\npub trait ApproxEq: Sized {\n    type Margin: FloatMargin;\n    fn approx_eq<M: Into<Self::Margin>>(self, other: Self, margin: M) -> bool;\n    fn approx_ne<M: Into<Self::Margin>>(self, other: Self, margin: M) -> bool {\n        !self.approx_eq(other, margin)\n    }\n}\n\n/// This type defines a margin within two `f32` values might be considered equal,\n/// and is intended as the associated type for the `ApproxEq` trait.\n#[repr(C)]\n#[derive(Debug, Clone, Copy)]\npub struct F32Margin {\n    pub epsilon: f32,\n    pub ulps: i32,\n}\nimpl Default for F32Margin {\n    #[inline]\n    fn default() -> F32Margin {\n        F32Margin {\n            epsilon: f32::EPSILON,\n            ulps: 4,\n        }\n    }\n}\nimpl FloatMargin for F32Margin {\n    type F = f32;\n    type I = i32;\n\n    #[inline]\n    fn zero() -> F32Margin {\n        F32Margin {\n            epsilon: 0.0,\n            ulps: 0,\n        }\n    }\n    fn epsilon(self, epsilon: f32) -> Self {\n        F32Margin { epsilon, ..self }\n    }\n    fn ulps(self, ulps: i32) -> Self {\n        F32Margin { ulps, ..self }\n    }\n}\nimpl From<(f32, i32)> for F32Margin {\n    fn from(m: (f32, i32)) -> F32Margin {\n        F32Margin {\n            epsilon: m.0,\n            ulps: m.1,\n        }\n    }\n}\n\n// no-std compatible abs function\n#[inline(always)]\nfn f32abs(x: f32) -> f32 {\n    f32::from_bits(x.to_bits() & !(1 << 31))\n}"", ""code_to_test"": ""impl ApproxEq for f32 {\n    type Margin = F32Margin;\n\n    fn approx_eq<M: Into<Self::Margin>>(self, other: f32, margin: M) -> bool {\n        let margin = margin.into();\n\n        // Check for exact equality first. This is often true, and so we get the\n        // performance benefit of only doing one compare in most cases.\n        self == other || {\n            // Perform epsilon comparison next\n            let eps = f32abs(self - other);\n            (eps <= margin.epsilon) || {\n                // Perform ulps comparison last\n                let diff: i32 = self.ulps(&other);\n                saturating_abs_i32!(diff) <= margin.ulps\n            }\n        }\n    }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn f32_approx_eq_test1() {\n    let f: f32 = 0.0_f32;\n    let g: f32 = -0.0000000000000005551115123125783_f32;\n    assert!(f != g); // Should not be directly equal\n    assert!(f.approx_eq(g, (f32::EPSILON, 0)) == true);\n}"", ""#[test]\nfn f32_approx_eq_test2() {\n    let f: f32 = 0.0_f32;\n    let g: f32 = -0.0_f32;\n    assert!(f.approx_eq(g, (f32::EPSILON, 0)) == true);\n}"", ""#[test]\nfn f32_approx_eq_test3() {\n    let f: f32 = 0.0_f32;\n    let g: f32 = 0.00000000000000001_f32;\n    assert!(f.approx_eq(g, (f32::EPSILON, 0)) == true);\n}"", ""#[test]\nfn f32_approx_eq_test4() {\n    let f: f32 = 0.00001_f32;\n    let g: f32 = 0.00000000000000001_f32;\n    assert!(f.approx_eq(g, (f32::EPSILON, 0)) == false);\n}"", ""#[test]\nfn f32_approx_eq_test5() {\n    let f: f32 = 0.1_f32;\n    let mut sum: f32 = 0.0_f32;\n    for _ in 0_isize..10_isize {\n        sum += f;\n    }\n    let product: f32 = f * 10.0_f32;\n    assert!(sum != product); // Should not be directly equal:\n    assert!(sum.approx_eq(product, (f32::EPSILON, 1)) == true);\n    assert!(sum.approx_eq(product, F32Margin::zero()) == false);\n}"", ""#[test]\nfn f32_approx_eq_test6() {\n    let x: f32 = 1000000_f32;\n    let y: f32 = 1000000.1_f32;\n    assert!(x != y); // Should not be directly equal\n    assert!(x.approx_eq(y, (0.0, 2)) == true); // 2 ulps does it\n    // epsilon method no good here:\n    assert!(x.approx_eq(y, (1000.0 * f32::EPSILON, 0)) == false);\n}""]}",test_generation
float-cmp,"{""code_context"": ""use super::Ulps;\nuse core::{f32, f64};\n#[cfg(feature = \""num-traits\"")]\n#[allow(unused_imports)]\nuse num_traits::float::FloatCore;\n\n/// A margin specifying a maximum distance two floating point values can be while\n/// still being considered equal enough.\npub trait FloatMargin: Copy + Default {\n    type F;\n    type I;\n    fn zero() -> Self;\n    fn epsilon(self, epsilon: Self::F) -> Self;\n    fn ulps(self, ulps: Self::I) -> Self;\n}\n\n/// A trait for approximate equality comparisons.\npub trait ApproxEq: Sized {\n    type Margin: FloatMargin;\n    fn approx_eq<M: Into<Self::Margin>>(self, other: Self, margin: M) -> bool;\n    fn approx_ne<M: Into<Self::Margin>>(self, other: Self, margin: M) -> bool {\n        !self.approx_eq(other, margin)\n    }\n}\n\n/// This type defines a margin within two `f64` values might be considered equal,\n/// and is intended as the associated type for the `ApproxEq` trait.\n#[derive(Debug, Clone, Copy)]\npub struct F64Margin {\n    pub epsilon: f64,\n    pub ulps: i64,\n}\nimpl Default for F64Margin {\n    #[inline]\n    fn default() -> F64Margin {\n        F64Margin {\n            epsilon: f64::EPSILON,\n            ulps: 4,\n        }\n    }\n}\nimpl FloatMargin for F64Margin {\n    type F = f64;\n    type I = i64;\n\n    #[inline]\n    fn zero() -> F64Margin {\n        F64Margin {\n            epsilon: 0.0,\n            ulps: 0,\n        }\n    }\n    fn epsilon(self, epsilon: f64) -> Self {\n        F64Margin { epsilon, ..self }\n    }\n    fn ulps(self, ulps: i64) -> Self {\n        F64Margin { ulps, ..self }\n    }\n}\nimpl From<(f64, i64)> for F64Margin {\n    fn from(m: (f64, i64)) -> F64Margin {\n        F64Margin {\n            epsilon: m.0,\n            ulps: m.1,\n        }\n    }\n}\n\n// no-std compatible abs function\n#[inline(always)]\nfn f64abs(x: f64) -> f64 {\n    f64::from_bits(x.to_bits() & !(1 << 63))\n}"", ""code_to_test"": ""impl ApproxEq for f64 {\n    type Margin = F64Margin;\n\n    fn approx_eq<M: Into<Self::Margin>>(self, other: f64, margin: M) -> bool {\n        let margin = margin.into();\n\n        // Check for exact equality first. This is often true, and so we get the\n        // performance benefit of only doing one compare in most cases.\n        self == other || {\n            // Perform epsilon comparison next\n            let eps = f64abs(self - other);\n            (eps <= margin.epsilon) || {\n                // Perform ulps comparison last\n                let diff: i64 = self.ulps(&other);\n                saturating_abs_i64!(diff) <= margin.ulps\n            }\n        }\n    }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn f64_approx_eq_test1() {\n    let f: f64 = 0.0_f64;\n    let g: f64 = -0.0000000000000005551115123125783_f64;\n    assert!(f != g); // Should not be precisely equal.\n    assert!(f.approx_eq(g, (3.0 * f64::EPSILON, 0)) == true); // 3e is enough.\n    // ULPs test won't ever call these equal.\n}"", ""#[test]\nfn f64_approx_eq_test2() {\n    let f: f64 = 0.0_f64;\n    let g: f64 = -0.0_f64;\n    assert!(f.approx_eq(g, (f64::EPSILON, 0)) == true);\n}"", ""#[test]\nfn f64_approx_eq_test3() {\n    let f: f64 = 0.0_f64;\n    let g: f64 = 1e-17_f64;\n    assert!(f.approx_eq(g, (f64::EPSILON, 0)) == true);\n}"", ""#[test]\nfn f64_approx_eq_test4() {\n    let f: f64 = 0.00001_f64;\n    let g: f64 = 0.00000000000000001_f64;\n    assert!(f.approx_eq(g, (f64::EPSILON, 0)) == false);\n}"", ""#[test]\nfn f64_approx_eq_test5() {\n    let f: f64 = 0.1_f64;\n    let mut sum: f64 = 0.0_f64;\n    for _ in 0_isize..10_isize {\n        sum += f;\n    }\n    let product: f64 = f * 10.0_f64;\n    assert!(sum != product); // Should not be precisely equally.\n    assert!(sum.approx_eq(product, (f64::EPSILON, 0)) == true);\n    assert!(sum.approx_eq(product, (0.0, 1)) == true);\n}""]}",test_generation
float-cmp,"{""code_context"": ""use super::Ulps;\n\npub trait ApproxEqUlps {\n    type Flt: Ulps;\n\n    fn approx_eq_ulps(&self, other: &Self, ulps: <Self::Flt as Ulps>::U) -> bool;\n    fn approx_ne_ulps(&self, other: &Self, ulps: <Self::Flt as Ulps>::U) -> bool {\n        !self.approx_eq_ulps(other, ulps)\n    }\n}\n\npub trait Ulps {\n    type U: Copy;\n    fn ulps(&self, other: &Self) -> Self::U;\n    fn next(&self) -> Self;\n    fn prev(&self) -> Self;\n}\n\nimpl Ulps for f32 {\n    type U = i32;\n    fn ulps(&self, other: &f32) -> i32 {\n        // simplified placeholder implementation\n        0\n    }\n    fn next(&self) -> Self { *self }\n    fn prev(&self) -> Self { *self }\n}"", ""code_to_test"": ""impl ApproxEqUlps for f32 {\n    type Flt = f32;\n\n    fn approx_eq_ulps(&self, other: &f32, ulps: i32) -> bool {\n        if *self == *other {\n            return true;\n        }\n        if self.is_sign_positive() != other.is_sign_positive() {\n            return false;\n        }\n        let diff: i32 = self.ulps(other);\n        diff >= -ulps && diff <= ulps\n    }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn f32_approx_eq_ulps_test1() {\n    let f: f32 = 0.1_f32;\n    let mut sum: f32 = 0.0_f32;\n    for _ in 0_isize..10_isize {\n        sum += f;\n    }\n    let product: f32 = f * 10.0_f32;\n    assert!(sum != product);\n    assert!(sum.approx_eq_ulps(&product, 1) == true);\n    assert!(sum.approx_eq_ulps(&product, 0) == false);\n}\n#[test]\nfn f32_approx_eq_ulps_test2() {\n    let x: f32 = 1000000_f32;\n    let y: f32 = 1000000.1_f32;\n    assert!(x != y);\n    assert!(x.approx_eq_ulps(&y, 2) == true);\n    assert!(x.approx_eq_ulps(&y, 1) == false);\n}""]}",test_generation
atoi,"{""code"": ""fn from_radix_10_signed(text: &[u8]) -> (Self, usize) {\n    let mut index;\n    let mut number = I::zero();\n\n    let (sign, offset) = text\n        .first()\n        .and_then(|&byte| Sign::try_from(byte))\n        .map(|sign| (sign, 1))\n        .unwrap_or((Sign::Plus, 0));\n\n    index = offset;\n\n    match sign {\n        Sign::Plus => {\n            while index != text.len() {\n                if let Some(digit) = ascii_to_digit::<I>(text[index]) {\n                    number *= nth(10);\n                    number += digit;\n                    index += 1;\n                } else {\n                    break;\n                }\n            }\n        }\n        Sign::Minus => {\n            while index != text.len() {\n                if let Some(digit) = ascii_to_digit::<I>(text[index]) {\n                    number *= nth(10);\n                    number -= digit;\n                    index += 1;\n                } else {\n                    break;\n                }\n            }\n        }\n    }\n\n    (number, index)\n}"", ""code_context"": ""use num_traits::{Zero, One, AddAssign, SubAssign, MulAssign};\n\npub enum Sign {\n    Plus,\n    Minus,\n}\n\nimpl Sign {\n    pub fn try_from(byte: u8) -> Option<Sign> {\n        match byte {\n            b'+' => Some(Sign::Plus),\n            b'-' => Some(Sign::Minus),\n            _ => None,\n        }\n    }\n}\n\npub trait FromRadix10Signed: Sized {\n    fn from_radix_10_signed(_: &[u8]) -> (Self, usize);\n}\n\nfn ascii_to_digit<I>(character: u8) -> Option<I>\nwhere\n    I: Zero + One,\n{\n    match character {\n        b'0' => Some(nth(0)),\n        b'1' => Some(nth(1)),\n        b'2' => Some(nth(2)),\n        b'3' => Some(nth(3)),\n        b'4' => Some(nth(4)),\n        b'5' => Some(nth(5)),\n        b'6' => Some(nth(6)),\n        b'7' => Some(nth(7)),\n        b'8' => Some(nth(8)),\n        b'9' => Some(nth(9)),\n        _ => None,\n    }\n}\n\nfn nth<I>(n: u8) -> I\nwhere\n    I: Zero + One,\n{\n    let mut i = I::zero();\n    for _ in 0..n {\n        i = i + I::one();\n    }\n    i\n}""}","{""commented_code"": ""fn from_radix_10_signed(text: &[u8]) -> (Self, usize) {\n    let mut index;\n    let mut number = I::zero();\n\n    let (sign, offset) = text\n        .first()\n        .and_then(|&byte| Sign::try_from(byte))\n        .map(|sign| (sign, 1))\n        .unwrap_or((Sign::Plus, 0));\n\n    index = offset;\n\n    // Having two dedicated loops for both the negative and the nonnegative case is rather\n    // verbose, yet performed up to 40% better then a more terse single loop with\n    // `number += digit * signum`.\n\n    match sign {\n        Sign::Plus => {\n            while index != text.len() {\n                if let Some(digit) = ascii_to_digit::<I>(text[index]) {\n                    number *= nth(10);\n                    number += digit;\n                    index += 1;\n                } else {\n                    break;\n                }\n            }\n        }\n        Sign::Minus => {\n            while index != text.len() {\n                if let Some(digit) = ascii_to_digit::<I>(text[index]) {\n                    number *= nth(10);\n                    number -= digit;\n                    index += 1;\n                } else {\n                    break;\n                }\n            }\n        }\n    }\n\n    (number, index)\n}""}",comment_generation
atoi,"{""code"": ""fn from_radix_10_checked(text: &[u8]) -> (Option<I>, usize) {\n    let max_safe_digits = max(1, I::max_num_digits_negative(nth(10))) - 1;\n    let (number, mut index) = I::from_radix_10(&text[..min(text.len(), max_safe_digits)]);\n    let mut number = Some(number);\n    while index != text.len() {\n        if let Some(digit) = ascii_to_digit(text[index]) {\n            number = number.and_then(|n| n.checked_mul(&nth(10)));\n            number = number.and_then(|n| n.checked_add(&digit));\n            index += 1;\n        } else {\n            break;\n        }\n    }\n    (number, index)\n}"", ""code_context"": ""use core::cmp::{max, min};\nuse num_traits::{Zero, One, CheckedAdd, CheckedMul, Bounded, DivAssign, AddAssign};\n\npub trait FromRadix10: Sized {\n    fn from_radix_10(_: &[u8]) -> (Self, usize);\n}\n\npub trait FromRadix10Checked: FromRadix10 {\n    fn from_radix_10_checked(_: &[u8]) -> (Option<Self>, usize);\n}\n\nfn ascii_to_digit<I>(character: u8) -> Option<I>\nwhere\n    I: Zero + One,\n{\n    match character {\n        b'0' => Some(nth(0)),\n        b'1' => Some(nth(1)),\n        b'2' => Some(nth(2)),\n        b'3' => Some(nth(3)),\n        b'4' => Some(nth(4)),\n        b'5' => Some(nth(5)),\n        b'6' => Some(nth(6)),\n        b'7' => Some(nth(7)),\n        b'8' => Some(nth(8)),\n        b'9' => Some(nth(9)),\n        _ => None,\n    }\n}\n\nfn nth<I>(n: u8) -> I\nwhere\n    I: Zero + One,\n{\n    let mut i = I::zero();\n    for _ in 0..n {\n        i = i + I::one();\n    }\n    i\n}""}","{""commented_code"": ""fn from_radix_10_checked(text: &[u8]) -> (Option<I>, usize) {\n    let max_safe_digits = max(1, I::max_num_digits_negative(nth(10))) - 1;\n    let (number, mut index) = I::from_radix_10(&text[..min(text.len(), max_safe_digits)]);\n    let mut number = Some(number);\n    // We parsed the digits, which do not need checking now lets see the next one:\n    while index != text.len() {\n        if let Some(digit) = ascii_to_digit(text[index]) {\n            number = number.and_then(|n| n.checked_mul(&nth(10)));\n            number = number.and_then(|n| n.checked_add(&digit));\n            index += 1;\n        } else {\n            break;\n        }\n    }\n    (number, index)\n}""}",comment_generation
atoi,"{""code"": ""fn from_radix_10_signed_checked(text: &[u8]) -> (Option<Self>, usize) {\n    let max_safe_digits = max(1, I::max_num_digits_negative(nth(10))) - 1;\n    let (number, mut index) = I::from_radix_10_signed(&text[..min(text.len(), max_safe_digits)]);\n    let mut number = Some(number);\n    while index != text.len() {\n        if let Some(digit) = ascii_to_digit(text[index]) {\n            number = number.and_then(|n| n.checked_mul(&nth(10)));\n            number = number.and_then(|n| n.checked_sub(&digit));\n            index += 1;\n        } else {\n            break;\n        }\n    }\n    (number, index)\n}"", ""code_context"": ""use core::cmp::{max, min};\nuse num_traits::{Zero, One, CheckedAdd, CheckedSub, CheckedMul, Bounded, DivAssign, AddAssign, SubAssign};\n\npub trait FromRadix10Signed: Sized {\n    fn from_radix_10_signed(_: &[u8]) -> (Self, usize);\n}\n\npub trait FromRadix10SignedChecked: FromRadix10Signed {\n    fn from_radix_10_signed_checked(_: &[u8]) -> (Option<Self>, usize);\n}\n\nfn ascii_to_digit<I>(character: u8) -> Option<I>\nwhere\n    I: Zero + One,\n{\n    match character {\n        b'0' => Some(nth(0)),\n        b'1' => Some(nth(1)),\n        b'2' => Some(nth(2)),\n        b'3' => Some(nth(3)),\n        b'4' => Some(nth(4)),\n        b'5' => Some(nth(5)),\n        b'6' => Some(nth(6)),\n        b'7' => Some(nth(7)),\n        b'8' => Some(nth(8)),\n        b'9' => Some(nth(9)),\n        _ => None,\n    }\n}\n\nfn nth<I>(n: u8) -> I\nwhere\n    I: Zero + One,\n{\n    let mut i = I::zero();\n    for _ in 0..n {\n        i = i + I::one();\n    }\n    i\n}""}","{""commented_code"": ""fn from_radix_10_signed_checked(text: &[u8]) -> (Option<Self>, usize) {\n    let max_safe_digits = max(1, I::max_num_digits_negative(nth(10))) - 1;\n    let (number, mut index) = I::from_radix_10_signed(&text[..min(text.len(), max_safe_digits)]);\n    let mut number = Some(number);\n    // We parsed the digits, which do not need checking now lets see the next one:\n    while index != text.len() {\n        if let Some(digit) = ascii_to_digit(text[index]) {\n            number = number.and_then(|n| n.checked_mul(&nth(10)));\n            number = number.and_then(|n| n.checked_sub(&digit));\n            index += 1;\n        } else {\n            break;\n        }\n    }\n    (number, index)\n}""}",comment_generation
atoi,"{""code"": ""fn nth<I>(n: u8) -> I\nwhere\n    I: Zero + One,\n{\n    let mut i = I::zero();\n    for _ in 0..n {\n        i = i + I::one();\n    }\n    i\n}"", ""code_context"": ""use num_traits::{Zero, One};""}","{""commented_code"": ""// At least for primitive types this function does not incur runtime costs, since it is only called with constants\nfn nth<I>(n: u8) -> I\nwhere\n    I: Zero + One,\n{\n    let mut i = I::zero();\n    for _ in 0..n {\n        i = i + I::one();\n    }\n    i\n}""}",comment_generation
libp2p-webrtc-websys,"{""code"": ""let __placeholder__ = RtcPeerConnection::new(remote_fingerprint.algorithm()).await?;\nlet (channel, _) = __placeholder__.new_handshake_stream();\nlet offer = __placeholder__.create_offer().await?;\nlet _ = offer;"", ""code_context"": ""use libp2p_webrtc_websys::connection::RtcPeerConnection;\nuse libp2p_webrtc_utils::Fingerprint;""}","{""variable_name"": ""rtc_peer_connection""}",variable_naming
libp2p-webrtc-websys,"{""code"": ""let __placeholder__ = rtc_peer_connection.new_regular_data_channel();\n__placeholder__.set_binary_type(RtcDataChannelType::Arraybuffer);\nlet _ = __placeholder__.ready_state();"", ""code_context"": ""use web_sys::{RtcDataChannel, RtcDataChannelType};""}","{""variable_name"": ""data_channel""}",variable_naming
libp2p-webrtc-websys,"{""code"": ""let __placeholder__ = Fingerprint::raw([0u8; 32]);\nlet sdp = __placeholder__.to_sdp_format();\nprintln!(\""Fingerprint SDP: {}\"", sdp);"", ""code_context"": ""use libp2p_webrtc_utils::Fingerprint;""}","{""variable_name"": ""peer_fingerprint""}",variable_naming
libp2p-webrtc-websys,"{""code"": ""let __placeholder__ = RtcSessionDescriptionInit::new(RtcSdpType::Offer);\n__placeholder__.set_sdp(&munged_sdp);\nlet _ = __placeholder__.sdp();"", ""code_context"": ""use web_sys::{RtcSessionDescriptionInit, RtcSdpType};""}","{""variable_name"": ""sdp_offer""}",variable_naming
quanta,"{""code"": ""fn __placeholder__(start: Instant) -> Duration { Instant::now() - start }"", ""code_context"": ""use crate::Instant;\nuse std::time::Duration;""}","{""function_name"": ""elapsed_since""}",function_naming
quanta,"{""code"": ""fn __placeholder__() -> bool { GLOBAL_RECENT.load() != 0 }"", ""code_context"": ""use crate::GLOBAL_RECENT;""}","{""function_name"": ""is_recent_valid""}",function_naming
quanta,"{""code"": ""fn __placeholder__(clock: &Clock, dur: Duration) -> Instant { let raw = clock.raw(); let target = raw + dur.as_nanos() as u64; clock.scaled(target) }"", ""code_context"": ""use crate::{Clock, Instant};\nuse std::time::Duration;""}","{""function_name"": ""advance_by_duration""}",function_naming
quanta,"{""code"": ""fn __placeholder__() -> u64 { let counter = Counter; counter.now() }"", ""code_context"": ""use crate::clocks::Counter;""}","{""function_name"": ""get_counter_raw""}",function_naming
quanta,"{""code"": ""fn __placeholder__(start: Instant) -> Duration { Instant::recent() - start }"", ""code_context"": ""use crate::Instant;\nuse std::time::Duration;""}","{""function_name"": ""recent_elapsed_since""}",function_naming
sha1_smol,"{""code"": ""let mut m = Sha1::new();"", ""code_context"": ""pub struct Sha1 {\n    state: Sha1State,\n    blocks: Blocks,\n    len: u64,\n}\n\npub struct Sha1State {\n    state: [u32; 5],\n}\n\npub struct Blocks {\n    len: u32,\n    block: [u8; 64],\n}\n\npub struct Digest {\n    data: Sha1State,\n}\n\nimpl Sha1 {\n    pub fn new() -> Sha1 {\n        Sha1 {\n            state: Sha1State { state: [0; 5] },\n            blocks: Blocks { len: 0, block: [0; 64] },\n            len: 0,\n        }\n    }\n\n    pub fn from<D: AsRef<[u8]>>(data: D) -> Sha1 {\n        let mut rv = Sha1::new();\n        rv.update(data.as_ref());\n        rv\n    }\n\n    pub fn update(&mut self, _data: &[u8]) {}\n\n    pub fn digest(&self) -> Digest {\n        Digest { data: Sha1State { state: [0; 5] } }\n    }\n}\n\nimpl Digest {\n    pub fn to_string(&self) -> String { String::new() }\n}""}","{""next_api_call"": ""m.update(data);""}",api_usage_prediction
sha1_smol,"{""code"": ""m.update(data);"", ""code_context"": ""pub struct Sha1 {\n    state: Sha1State,\n    blocks: Blocks,\n    len: u64,\n}\n\npub struct Sha1State {\n    state: [u32; 5],\n}\n\npub struct Blocks {\n    len: u32,\n    block: [u8; 64],\n}\n\npub struct Digest {\n    data: Sha1State,\n}\n\nimpl Sha1 {\n    pub fn new() -> Sha1 { Sha1 { state: Sha1State { state: [0;5] }, blocks: Blocks { len:0, block:[0;64]}, len:0 } }\n    pub fn update(&mut self, _data: &[u8]) {}\n    pub fn digest(&self) -> Digest { Digest { data: Sha1State { state: [0;5] } } }\n}\n\nimpl Digest {\n    pub fn to_string(&self) -> String { String::new() }\n}""}","{""next_api_call"": ""let hh = m.digest().to_string();""}",api_usage_prediction
sha1_smol,"{""code"": ""let s = Sha1::from(\""The quick brown fox jumps over the lazy dog\"");"", ""code_context"": ""pub struct Sha1 {\n    state: Sha1State,\n    blocks: Blocks,\n    len: u64,\n}\n\npub struct Sha1State {\n    state: [u32; 5],\n}\n\npub struct Blocks {\n    len: u32,\n    block: [u8; 64],\n}\n\npub struct Digest {\n    data: Sha1State,\n}\n\nimpl Sha1 {\n    pub fn new() -> Sha1 { Sha1 { state: Sha1State { state: [0;5] }, blocks: Blocks { len:0, block:[0;64]}, len:0 } }\n    pub fn from<D: AsRef<[u8]>>(data: D) -> Sha1 { let mut rv = Sha1::new(); rv.update(data.as_ref()); rv }\n    pub fn update(&mut self, _data: &[u8]) {}\n    pub fn digest(&self) -> Digest { Digest { data: Sha1State { state: [0;5] } } }\n}\n\nimpl Digest {\n    pub fn to_string(&self) -> String { String::new() }\n}""}","{""next_api_call"": ""assert_eq!(s.digest().to_string(), \""2fd4e1c67a2d28fced849ee1bb76e7391b93eb12\"");""}",api_usage_prediction
sha1_smol,"{""code"": ""let s = Sha1::from(\""The quick brown fox jumps over the lazy dog\"");"", ""code_context"": ""pub struct Sha1 {\n    state: Sha1State,\n    blocks: Blocks,\n    len: u64,\n}\n\npub struct Sha1State {\n    state: [u32; 5],\n}\n\npub struct Blocks {\n    len: u32,\n    block: [u8; 64],\n}\n\npub struct Digest {\n    data: Sha1State,\n}\n\nimpl Sha1 {\n    pub fn new() -> Sha1 { Sha1 { state: Sha1State { state: [0;5] }, blocks: Blocks { len:0, block:[0;64]}, len:0 } }\n    pub fn from<D: AsRef<[u8]>>(data: D) -> Sha1 { let mut rv = Sha1::new(); rv.update(data.as_ref()); rv }\n    pub fn update(&mut self, _data: &[u8]) {}\n    pub fn digest(&self) -> Digest { Digest { data: Sha1State { state: [0;5] } } }\n    #[cfg(feature = \""alloc\"")]\n    pub fn hexdigest(&self) -> std::string::String { std::string::String::new() }\n}\n\nimpl Digest {\n    pub fn to_string(&self) -> String { String::new() }\n}""}","{""next_api_call"": ""assert_eq!(s.hexdigest(), \""2fd4e1c67a2d28fced849ee1bb76e7391b93eb12\"");""}",api_usage_prediction
atoi,"{""prefix"": ""let num = "", ""suffix"": ""?;""}","{""completion"": ""i32::from_radix_10_checked(b\""123\"")""}",code_completion
atoi,"{""prefix"": ""let signed = "", ""suffix"": "";""}","{""completion"": ""i32::from_radix_10_signed_checked(b\""-42\"").0.unwrap()""}",code_completion
atoi,"{""prefix"": ""let value: i64 = "", ""suffix"": "";""}","{""completion"": ""atoi::atoi(b\""123456\"").unwrap()""}",code_completion
atoi,"{""prefix"": ""let hex = "", ""suffix"": "";""}","{""completion"": ""u32::from_radix_16_checked(b\""1A2B\"").0.unwrap()""}",code_completion
simd-adler32,"{""code_before"": ""pub fn update(a: u16, b: u16, data: &[u8]) -> (u16, u16) {\n    let mut a = a as u32;\n    let mut b = b as u32;\n\n    let chunks = data.chunks_exact(NMAX);\n    let remainder = chunks.remainder();\n\n    for chunk in chunks {\n        for byte in chunk {\n            a = a.wrapping_add(*byte as u32);\n            b = b.wrapping_add(a);\n        }\n        a %= MOD;\n        b %= MOD;\n    }\n\n    for byte in remainder {\n        a = a.wrapping_add(*byte as u32);\n        b = b.wrapping_add(a);\n    }\n\n    a %= MOD;\n    b %= MOD;\n\n    (a as u16, b as u16)\n}"", ""code_context"": ""const MOD: u32 = 65521;\nconst NMAX: usize = 5552;""}","{""rationale"": ""The original implementation performs a modulo operation after every NMAX‑sized chunk, which introduces unnecessary integer division overhead. By processing the entire input in a single pass and applying the modulo reduction only once at the end, we eliminate repeated costly modulo operations while preserving correct wrap‑around semantics via wrapping_add."", ""code_after"": ""pub fn update(a: u16, b: u16, data: &[u8]) -> (u16, u16) {\n    let mut a = a as u32;\n    let mut b = b as u32;\n\n    for byte in data {\n        a = a.wrapping_add(*byte as u32);\n        b = b.wrapping_add(a);\n    }\n\n    a %= MOD;\n    b %= MOD;\n\n    (a as u16, b as u16)\n}""}",code_optimization
simd-adler32,"{""code_before"": ""fn update_block(a: &mut u32, b: &mut u32, chunk: &[u8]) {\n    debug_assert!(\n        chunk.len() <= CHUNK_SIZE,\n        \""Unexpected chunk size (expected <= {}, got {})\"",\n        CHUNK_SIZE,\n        chunk.len()\n    );\n\n    for byte in reduce_add_blocks(a, b, chunk) {\n        *a += *byte as u32;\n        *b += *a;\n    }\n\n    *a %= MOD;\n    *b %= MOD;\n}"", ""code_context"": ""const MOD: u32 = 65521;\nconst BLOCK_SIZE: usize = 32;\nconst CHUNK_SIZE: usize = 5552 / BLOCK_SIZE * BLOCK_SIZE;""}","{""rationale"": ""The SIMD implementations fall back to this scalar block when the remaining data is smaller than a SIMD block. The original code calls `reduce_add_blocks`, which merely returns the same slice and adds an extra iterator layer. Rewriting the loop to iterate directly over the byte slice removes the indirection, reduces function call overhead, and enables the compiler to better optimize the tight inner loop."", ""code_after"": ""fn update_block(a: &mut u32, b: &mut u32, chunk: &[u8]) {\n    debug_assert!(\n        chunk.len() <= CHUNK_SIZE,\n        \""Unexpected chunk size (expected <= {}, got {})\"",\n        CHUNK_SIZE,\n        chunk.len()\n    );\n\n    let mut a_val = *a;\n    let mut b_val = *b;\n\n    for &byte in chunk {\n        a_val = a_val.wrapping_add(byte as u32);\n        b_val = b_val.wrapping_add(a_val);\n    }\n\n    *a = a_val % MOD;\n    *b = b_val % MOD;\n}""}",code_optimization
simd-adler32,"{""code_before"": ""fn sum_vector(v: Vec<i32>) -> i32 {\n    v.iter().sum()\n}"", ""code_context"": """"}","{""rationale"": ""Accepting a `Vec<i32>` forces a heap allocation for the caller even when the data already exists elsewhere. By taking a slice (`&[i32]`) the function can operate on any contiguous integer collection without allocating, reducing memory usage and improving cache locality."", ""code_after"": ""fn sum_slice(v: &[i32]) -> i32 {\n    v.iter().sum()\n}""}",code_optimization
debugid,"{""code"": ""let id = CodeId::new(\""dfb8e43af2423d73a453aeb6a777ef75\"".into());"", ""code_context"": ""pub struct CodeId {\n    inner: String,\n}\n\nimpl CodeId {\n    pub fn new(mut string: String) -> Self {\n        string.retain(|c| c.is_ascii_hexdigit());\n        string.make_ascii_lowercase();\n        CodeId { inner: string }\n    }\n\n    pub fn as_str(&self) -> &str {\n        self.inner.as_str()\n    }\n}""}","{""next_api_call"": ""id.as_str()""}",api_usage_prediction
debugid,"{""code"": ""let debug_id = DebugId::from_str(\""dfb8e43a-f242-3d73-a453-aeb6a777ef75\"").unwrap();"", ""code_context"": ""use uuid::Uuid;\n\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub struct ParseDebugIdError;\n\nstruct ParseOptions {\n    allow_hyphens: bool,\n    require_appendix: bool,\n    allow_tail: bool,\n}\n\npub struct DebugId {\n    bytes: uuid::Bytes,\n    appendix: u32,\n    _padding: [u8; 11],\n    typ: u8,\n}\n\nimpl DebugId {\n    pub fn from_str(s: &str) -> Result<Self, ParseDebugIdError> {\n        let options = ParseOptions {\n            allow_hyphens: true,\n            require_appendix: false,\n            allow_tail: true,\n        };\n        Self::parse_str(s, options).ok_or(ParseDebugIdError)\n    }\n\n    pub fn uuid(&self) -> Uuid {\n        Uuid::from_bytes(self.bytes)\n    }\n}""}","{""next_api_call"": ""debug_id.uuid()""}",api_usage_prediction
debugid,"{""code"": ""let debug_id = DebugId::from_parts(Uuid::parse_str(\""dfb8e43a-f242-3d73-a453-aeb6a777ef75\"").unwrap(), 0);"", ""code_context"": ""use uuid::Uuid;\n\npub struct DebugId {\n    bytes: uuid::Bytes,\n    appendix: u32,\n    _padding: [u8; 11],\n    typ: u8,\n}\n\nimpl DebugId {\n    pub fn from_parts(uuid: Uuid, appendix: u32) -> Self {\n        DebugId {\n            bytes: *uuid.as_bytes(),\n            appendix,\n            _padding: [0; 11],\n            typ: 0,\n        }\n    }\n\n    pub fn breakpad(&self) -> BreakpadFormat<'_> {\n        BreakpadFormat { inner: self }\n    }\n}\n\npub struct BreakpadFormat<'a> {\n    inner: &'a DebugId,\n}""}","{""next_api_call"": ""debug_id.breakpad()""}",api_usage_prediction
float-cmp,"{""code_before"": ""let eps = f32abs(self - other);"", ""code_context"": ""pub fn f32abs(x: f32) -> f32 {\n    f32::from_bits(x.to_bits() & !(1 << 31))\n}""}","{""code_after"": ""let eps = (self - other).abs();"", ""review_comment"": ""Replaced the custom `f32abs` helper with the standard `.abs()` method. This removes unnecessary bit‑twiddling, makes the intent clear, and relies on the well‑tested standard library implementation.""}",code_review
float-cmp,"{""code_before"": ""saturating_abs_i32!(diff) <= margin.ulps"", ""code_context"": ""macro_rules! saturating_abs_i32 {\n    ($val:expr) => {\n        if $val.is_negative() {\n            match $val.checked_neg() {\n                Some(v) => v,\n                None => i32::MAX,\n            }\n        } else {\n            $val\n        }\n    };\n}""}","{""code_after"": ""diff.abs() <= margin.ulps"", ""review_comment"": ""Used the built‑in `abs()` method on the `i32` difference instead of the `saturating_abs_i32!` macro. The standard method is clearer and avoids macro overhead while providing the same semantics.""}",code_review
float-cmp,"{""code_before"": ""impl ApproxEq for &[T]\nwhere\n    T: Copy + ApproxEq,\n{\n    type Margin = <T as ApproxEq>::Margin;\n\n    fn approx_eq<M: Into<Self::Margin>>(self, other: Self, margin: M) -> bool {\n        let margin = margin.into();\n        if self.len() != other.len() {\n            return false;\n        }\n        self.iter()\n            .zip(other.iter())\n            .all(|(a, b)| a.approx_eq(*b, margin))\n    }\n}"", ""code_context"": null}","{""code_after"": ""impl ApproxEq for &[T]\nwhere\n    T: Copy + ApproxEq,\n{\n    type Margin = <T as ApproxEq>::Margin;\n\n    fn approx_eq<M: Into<Self::Margin>>(self, other: Self, margin: M) -> bool {\n        let margin = margin.into();\n        self.len() == other.len() && self.iter().zip(other.iter()).all(|(a, b)| a.approx_eq(*b, margin))\n    }\n}"", ""review_comment"": ""Combined the length check and the element‑wise comparison into a single boolean expression. This removes an early return and makes the implementation more concise without changing behavior.""}",code_review
unicode-linebreak,"{""code"": ""let __placeholder__ = linebreaks(text).map(|(i, _)| i).collect::<Vec<_>>();"", ""code_context"": ""use unicode_linebreak::linebreaks;\n\nfn example(text: &str) {\n    let __placeholder__ = linebreaks(text).map(|(i, _)| i).collect::<Vec<_>>();\n}""}","{""variable_name"": ""break_points""}",variable_naming
unicode-linebreak,"{""code"": ""let __placeholder__ = break_property(ch as u32);"", ""code_context"": ""use unicode_linebreak::{break_property, BreakClass};\n\nfn get_break_class(ch: char) {\n    let __placeholder__ = break_property(ch as u32);\n}""}","{""variable_name"": ""break_class""}",variable_naming
unicode-linebreak,"{""code"": ""let __placeholder__ = PAIR_TABLE[state as usize][cls as usize];"", ""code_context"": ""use unicode_linebreak::PAIR_TABLE;\n\nfn lookup(state: u8, cls: u8) -> u8 {\n    let __placeholder__ = PAIR_TABLE[state as usize][cls as usize];\n    __placeholder__\n}""}","{""variable_name"": ""pair_value""}",variable_naming
serde-value,"{""code"": ""let value = Value::U8(8);"", ""code_context"": ""use serde::de;\n\nimpl<'de> de::Deserialize<'de> for Value {\n    fn deserialize<D>(d: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        d.deserialize_any(ValueVisitor)\n    }\n}""}","{""next_api_call"": ""let deserialized = Value::deserialize(value).unwrap();""}",api_usage_prediction
serde-value,"{""code"": ""let map = Value::Map(vec![(Value::String(\""a\"".into()), Value::U32(10))].into_iter().collect());"", ""code_context"": ""pub fn to_value<T: ser::Serialize>(value: T) -> Result<Value, SerializerError> {\n    value.serialize(Serializer)\n}""}","{""next_api_call"": ""let serialized = to_value(&map).unwrap();""}",api_usage_prediction
serde-value,"{""code"": ""let seq = Value::Seq(vec![Value::Bool(true), Value::Bool(false)]);"", ""code_context"": ""impl Value {\n    pub fn deserialize_into<'de, T: serde::de::Deserialize<'de>>(self) -> Result<T, DeserializerError> {\n        T::deserialize(self)\n    }\n}""}","{""next_api_call"": ""let vec_bool: Vec<bool> = seq.deserialize_into().unwrap();""}",api_usage_prediction
simd-adler32,"{""code"": ""let mut adler = simd_adler32::Adler32::new();"", ""code_context"": ""pub struct Adler32 {\n    a: u16,\n    b: u16,\n    update: Adler32Imp,\n}\n\nimpl Adler32 {\n    pub fn new() -> Self {\n        Default::default()\n    }\n\n    pub fn write(&mut self, data: &[u8]) {\n        let (a, b) = (self.update)(self.a, self.b, data);\n        self.a = a;\n        self.b = b;\n    }\n}""}","{""next_api_call"": ""adler.write(data);""}",api_usage_prediction
simd-adler32,"{""code"": ""let mut hash = Adler32::new();"", ""code_context"": ""pub trait Adler32Hash {\n    fn hash(&self) -> u32;\n}\n\npub struct Adler32 {\n    a: u16,\n    b: u16,\n    update: Adler32Imp,\n}\n\nimpl Adler32 {\n    pub fn new() -> Self {\n        Default::default()\n    }\n\n    pub fn write(&mut self, data: &[u8]) {\n        let (a, b) = (self.update)(self.a, self.b, data);\n        self.a = a;\n        self.b = b;\n    }\n}""}","{""next_api_call"": ""hash.write(self);""}",api_usage_prediction
simd-adler32,"{""code"": ""a = a.wrapping_add(*byte as _);"", ""code_context"": ""const MOD: u32 = 65521;\nconst NMAX: usize = 5552;\n\npub fn update(a: u16, b: u16, data: &[u8]) -> (u16, u16) {\n    let mut a = a as u32;\n    let mut b = b as u32;\n\n    let chunks = data.chunks_exact(NMAX);\n    let remainder = chunks.remainder();\n\n    for chunk in chunks {\n        for byte in chunk {\n            a = a.wrapping_add(*byte as _);\n            b = b.wrapping_add(a);\n        }\n        a %= MOD;\n        b %= MOD;\n    }\n\n    for byte in remainder {\n        a = a.wrapping_add(*byte as _);\n        b = b.wrapping_add(a);\n    }\n\n    a %= MOD;\n    b %= MOD;\n\n    (a as u16, b as u16)\n}""}","{""next_api_call"": ""b = b.wrapping_add(a);""}",api_usage_prediction
dotenvy,"{""title"": ""Merge Multiple .env Files with Priority"", ""description"": ""A developer needs to merge environment variables from two .env files, where variables in the second file override those in the first. They want a helper that loads both files in order and returns a combined EnvMap."", ""code_context"": ""use dotenvy::{EnvLoader, EnvMap, EnvSequence};\nuse std::error::Error;""}","{""code"": ""pub fn merge_env_files(path1: &str, path2: &str) -> Result<EnvMap, Box<dyn std::error::Error>> {\n    let mut loader1 = EnvLoader::with_path(path1).sequence(EnvSequence::InputThenEnv);\n    let mut env_map = loader1.load()?;\n    let mut loader2 = EnvLoader::with_path(path2).sequence(EnvSequence::InputOnly);\n    let env_map2 = loader2.load()?;\n    env_map.extend(env_map2);\n    Ok(env_map)\n}""}",code_generation
dotenvy,"{""title"": ""Validate Required Environment Variables"", ""description"": ""After loading environment variables, a developer wants to ensure that a set of required keys are present and non‑empty, returning a list of missing variables as errors."", ""code_context"": ""use dotenvy::{EnvLoader, EnvMap};""}","{""code"": ""pub fn load_and_validate(loader: EnvLoader) -> Result<EnvMap, Vec<String>> {\n    let env_map = loader.load().map_err(|e| vec![e.to_string()])?;\n    let required = [\""DATABASE_URL\"", \""SECRET_KEY\""];\n    let missing: Vec<String> = required.iter()\n        .filter(|key| env_map.get(*key).map_or(true, |v| v.is_empty()))\n        .map(|k| format!(\""{} is not set\"", k))\n        .collect();\n    if missing.is_empty() {\n        Ok(env_map)\n    } else {\n        Err(missing)\n    }\n}""}",code_generation
dotenvy,"{""title"": ""Load Environment Variables with Default Values"", ""description"": ""A developer wants to load variables from the environment but provide fallback defaults for any keys that are missing, producing a complete EnvMap ready for the application."", ""code_context"": ""use std::collections::HashMap;\nuse std::env;\nuse dotenvy::EnvMap;\nuse dotenvy::Error;""}","{""code"": ""pub fn load_env_vars_with_defaults(defaults: std::collections::HashMap<String, String>) -> Result<EnvMap, dotenvy::Error> {\n    let mut env_map = EnvMap::new();\n    for (key, default) in defaults {\n        let value = std::env::var(&key).unwrap_or(default);\n        env_map.insert(key, value);\n    }\n    Ok(env_map)\n}""}",code_generation
dotenvy,"{""title"": ""Ensure Environment Variables are Set Before Starting an Async Application"", ""description"": ""When building an async service, a developer must load and modify the process environment before the Tokio runtime starts, guaranteeing that all tasks see the correct variables."", ""code_context"": ""use dotenvy::{EnvLoader, EnvSequence};\nuse std::error::Error;\nuse tokio::runtime::Builder;""}","{""code"": ""fn main() -> Result<(), Box<dyn std::error::Error>> {\n    let loader = EnvLoader::with_path(\""./.env\"").sequence(EnvSequence::InputThenEnv);\n    unsafe { loader.load_and_modify()? };\n\n    let rt = tokio::runtime::Builder::new_multi_thread()\n        .enable_all()\n        .build()?;\n    rt.block_on(async {\n        // async code that can read env vars here\n        let host = std::env::var(\""HOST\"")?;\n        println!(\""HOST={}\"", host);\n        Ok::<_, std::env::VarError>(())\n    })?;\n    Ok(())\n}""}",code_generation
difflib,"{""title"": ""Add custom line formatter to Differ"", ""description"": ""A developer wants to customize how each diff line is formatted, allowing custom prefixes or suffixes instead of the default \""- \"", \""+ \"", or \""  \"". This requires adding a formatter function to the Differ struct and using it when generating diff lines."", ""code_context"": ""use std::cmp;\nuse utils::{count_leading, str_with_similar_chars};\n\n#[derive(Default)]\npub struct Differ {\n    pub line_junk: Option<fn(&&str) -> bool>,\n    pub char_junk: Option<fn(&char) -> bool>,\n    line_formatter: Option<fn(&str, &str) -> String>,\n}""}","{""code"": ""impl Differ {\n    pub fn set_line_formatter(&mut self, formatter: fn(&str, &str) -> String) {\n        self.line_formatter = Some(formatter);\n    }\n\n    fn format_line(&self, tag: &str, line: &str) -> String {\n        match self.line_formatter {\n            Some(f) => f(tag, line),\n            None => format!(\""{} {}\"", tag, line),\n        }\n    }\n}""}",code_generation
difflib,"{""title"": ""Calculate added, deleted, and modified line counts from Differ output"", ""description"": ""A developer needs a quick summary of how many lines were added, removed, or changed in a diff produced by Differ. This helper analyses the diff strings and returns the three counts."", ""code_context"": ""use std::cmp;\nuse utils::{count_leading, str_with_similar_chars};\n\n#[derive(Default)]\npub struct Differ {\n    pub line_junk: Option<fn(&&str) -> bool>,\n    pub char_junk: Option<fn(&char) -> bool>,\n    line_formatter: Option<fn(&str, &str) -> String>,\n}""}","{""code"": ""impl Differ {\n    pub fn calculate_changes(&self, diff: &[String]) -> (usize, usize, usize) {\n        let mut added = 0usize;\n        let mut deleted = 0usize;\n        let mut modified = 0usize;\n        for line in diff {\n            if line.starts_with(\""+ \"") {\n                added += 1;\n            } else if line.starts_with(\""- \"") {\n                deleted += 1;\n            } else if line.starts_with(\""? \"") {\n                modified += 1;\n            }\n        }\n        (added, deleted, modified)\n    }\n}""}",code_generation
difflib,"{""title"": ""Filter unwanted characters from a slice of strings"", ""description"": ""When preparing text for diffing, a developer may want to remove specific characters (e.g., spaces or tabs) from each line. This helper returns a new vector with the filtered strings."", ""code_context"": null}","{""code"": ""fn filter_chars(sequence: &[&str], chars_to_remove: &[char]) -> Vec<String> {\n    sequence.iter()\n        .map(|s| s.chars().filter(|c| !chars_to_remove.contains(c)).collect())\n        .collect()\n}""}",code_generation
libp2p-mdns,"{""code"": ""fn generate_peer_name() -> Vec<u8> {\n    let peer_name = random_string(32 + thread_rng().gen_range(0..32));\n    let mut peer_name_bytes = Vec::with_capacity(peer_name.len() + 32);\n    append_qname(&mut peer_name_bytes, peer_name.as_bytes());\n    peer_name_bytes\n}"", ""code_context"": ""use rand::{thread_rng, Rng};\nuse rand::distributions::Alphanumeric;\nuse std::vec::Vec;\n\nfn random_string(length: usize) -> String {\n    thread_rng()\n        .sample_iter(&Alphanumeric)\n        .take(length)\n        .map(char::from)\n        .collect()\n}\n\nfn append_qname(out: &mut Vec<u8>, name: &[u8]) {\n    for element in name.split(|&c| c == b'.') {\n        out.push(element.len() as u8);\n        out.extend_from_slice(element);\n    }\n    out.push(0);\n}""}","{""explanation"": ""Generates a random peer name for an mDNS query. It first creates a random alphanumeric string whose length is 32 plus a small random offset, then encodes that string as a DNS QNAME (a sequence of length‑prefixed labels) using `append_qname`. The resulting byte vector is returned and later used as the name field in DNS packets.""}",code_explanation
libp2p-mdns,"{""code"": ""fn append_qname(out: &mut Vec<u8>, name: &[u8]) {\n    for element in name.split(|&c| c == b'.') {\n        out.push(element.len() as u8);\n        out.extend_from_slice(element);\n    }\n    out.push(0);\n}"", ""code_context"": ""use std::vec::Vec;""}","{""explanation"": ""Encodes a DNS QNAME into a byte buffer. The input `name` is split on `.` characters; each label is prefixed with its length byte and appended to `out`. A terminating zero byte is added to mark the end of the name. This format follows RFC 1035 and is used when constructing mDNS queries and responses.""}",code_explanation
libp2p-mdns,"{""code"": ""impl MdnsPeer {\n    pub fn new(packet: &Message, record_value: &Name, ttl: u32) -> Option<MdnsPeer> {\n        let mut my_peer_id: Option<PeerId> = None;\n        let addrs = packet\n            .additionals()\n            .iter()\n            .filter_map(|add_record| {\n                if add_record.name() != record_value {\n                    return None;\n                }\n                if let RData::TXT(ref txt) = add_record.data() {\n                    Some(txt)\n                } else {\n                    None\n                }\n            })\n            .flat_map(|txt| txt.iter())\n            .filter_map(|txt| {\n                let addr = dns::decode_character_string(txt).ok()?;\n                if !addr.starts_with(b\""dnsaddr=\"") {\n                    return None;\n                }\n                let mut addr = std::str::from_utf8(&addr[8..]).ok()?.parse::<Multiaddr>().ok()?;\n                match addr.pop() {\n                    Some(Protocol::P2p(peer_id)) => {\n                        if let Some(pid) = &my_peer_id {\n                            if peer_id != *pid {\n                                return None;\n                            }\n                        } else {\n                            my_peer_id.replace(peer_id);\n                        }\n                    }\n                    _ => return None,\n                };\n                Some(addr)\n            })\n            .collect();\n\n        my_peer_id.map(|peer_id| MdnsPeer { addrs, peer_id, ttl })\n    }\n}"", ""code_context"": ""use hickory_proto::op::Message;\nuse hickory_proto::rr::{Name, RData};\nuse libp2p_core::multiaddr::{Multiaddr, Protocol};\nuse libp2p_identity::PeerId;\n\nmod dns {\n    use super::*;\n    pub fn decode_character_string(data: &hickory_proto::rr::rdata::TXT) -> Result<std::borrow::Cow<'_, [u8]>, ()> {\n        // Simplified placeholder implementation for the example.\n        Ok(std::borrow::Cow::Borrowed(&data.iter().next()?.to_vec()))\n    }\n}\n\nstruct MdnsPeer {\n    addrs: Vec<Multiaddr>,\n    peer_id: PeerId,\n    ttl: u32,\n}""}","{""explanation"": ""Parses an incoming mDNS response to extract a discovered peer. It scans the additional records for TXT records matching the given `record_value`. Each TXT record is decoded, filtered for the `dnsaddr=` prefix, and converted into a `Multiaddr`. The function ensures that all addresses refer to the same `PeerId`; if they do, it returns an `MdnsPeer` containing the list of addresses, the peer identifier, and the TTL.""}",code_explanation
inotify,"{""code"": ""impl Inotify {\n    pub fn __placeholder__(path: &Path, mask: WatchMask) -> io::Result<WatchDescriptor> {\n        let mut watches = self.watches();\n        watches.add(path, mask)\n    }\n}"", ""code_context"": ""use std::path::Path;\nuse std::io;\nuse inotify::{WatchMask, WatchDescriptor};""}","{""function_name"": ""add_watch""}",function_naming
inotify,"{""code"": ""impl Watches {\n    pub fn __placeholder__(wd: WatchDescriptor) -> io::Result<()> {\n        let fd = self.fd.clone();\n        let res = unsafe { ffi::inotify_rm_watch(*fd, wd.id) };\n        if res == 0 {\n            Ok(())\n        } else {\n            Err(io::Error::last_os_error())\n        }\n    }\n}"", ""code_context"": ""use std::io;\nuse inotify::WatchDescriptor;\nuse inotify_sys as ffi;""}","{""function_name"": ""remove_watch""}",function_naming
inotify,"{""code"": ""pub fn __placeholder__(fd: RawFd) -> io::Result<Inotify> {\n    let fd_guard = FdGuard::from_raw_fd(fd);\n    Ok(Inotify { fd: Arc::new(fd_guard) })\n}"", ""code_context"": ""use std::os::unix::io::RawFd;\nuse std::io;\nuse inotify::Inotify;\nuse inotify::fd_guard::FdGuard;\nuse std::sync::Arc;""}","{""function_name"": ""from_raw_fd""}",function_naming
inotify,"{""code"": ""impl Inotify {\n    pub fn __placeholder__(&mut self, buffer: &mut [u8]) -> io::Result<Events> {\n        let num_bytes = read_into_buffer(**self.fd, buffer);\n        Ok(Events::new(Arc::downgrade(&self.fd), buffer, num_bytes as usize))\n    }\n}"", ""code_context"": ""use std::io;\nuse inotify::Events;\nuse std::sync::Arc;\nuse crate::util::read_into_buffer;""}","{""function_name"": ""read_events""}",function_naming
bytecheck,"{""code"": ""pub unsafe trait CheckBytes<C: Fallible + ?Sized> {\n    unsafe fn check_bytes(\n        value: *const Self,\n        context: &mut C,\n    ) -> Result<(), C::Error>;\n}"", ""code_context"": null}","{""docstring"": ""A type that can check whether a pointer points to a valid value.\n\n`CheckBytes` can be derived with [`CheckBytes`](macro@CheckBytes) or implemented manually for custom behavior.\n\n# Safety\n\n`check_bytes` must only return `Ok` if `value` points to a valid instance of `Self`. Because `value` must always be properly aligned for `Self` and point to enough bytes to represent the type, this implies that `value` may be dereferenced safely.\n\n# Example\n\n```rust\nuse core::{error::Error, fmt};\n\nuse bytecheck::CheckBytes;\nuse rancor::{fail, Fallible, Source};\n\n#[repr(C, align(4))]\npub struct NonMaxU32(u32);\n\nunsafe impl<C: Fallible + ?Sized> CheckBytes<C> for NonMaxU32\nwhere\n    C::Error: Source,\n{\n    unsafe fn check_bytes(\n        value: *const Self,\n        context: &mut C,\n    ) -> Result<(), C::Error> {\n        #[derive(Debug)]\n        struct NonMaxCheckError;\n\n        impl fmt::Display for NonMaxCheckError {\n            fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n                write!(f, \""non-max u32 was set to u32::MAX\"")\n            }\n        }\n\n        impl Error for NonMaxCheckError {}\n\n        let value = unsafe { value.read() };\n        if value.0 == u32::MAX {\n            fail!(NonMaxCheckError);\n        }\n\n        Ok(())\n    }\n}\n```""}",docstring_generation
bytecheck,"{""code"": ""pub unsafe trait Verify<C: Fallible + ?Sized> {\n    fn verify(&self, context: &mut C) -> Result<(), C::Error>;\n}"", ""code_context"": null}","{""docstring"": ""A type that can check whether its invariants are upheld.\n\nWhen using [the derive](macro@CheckBytes), adding `#[bytecheck(verify)]` allows implementing `Verify` for the derived type. [`Verify::verify`] will be called after the type is checked and all fields are known to be valid.\n\n# Safety\n\n- `verify` must only return `Ok` if all of the invariants of this type are upheld by `self`.\n- `verify` may not assume that its type invariants are upheld by the given `self` (the invariants of each field are guaranteed to be upheld).\n\n# Example\n\n```rust\nuse core::{error::Error, fmt};\n\nuse bytecheck::{CheckBytes, Verify};\nuse rancor::{fail, Fallible, Source};\n\n#[derive(CheckBytes)]\n#[bytecheck(verify)]\n#[repr(C, align(4))]\npub struct NonMaxU32(u32);\n\nunsafe impl<C: Fallible + ?Sized> Verify<C> for NonMaxU32\nwhere\n    C::Error: Source,\n{\n    fn verify(&self, context: &mut C) -> Result<(), C::Error> {\n        #[derive(Debug)]\n        struct NonMaxCheckError;\n\n        impl fmt::Display for NonMaxCheckError {\n            fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n                write!(f, \""non-max u32 was set to u32::MAX\"")\n            }\n        }\n\n        impl Error for NonMaxCheckError {}\n\n        if self.0 == u32::MAX {\n            fail!(NonMaxCheckError);\n        }\n\n        Ok(())\n    }\n}\n```""}",docstring_generation
bytecheck,"{""code"": ""#[inline]\npub unsafe fn check_bytes<T, E>(value: *const T) -> Result<(), E>\nwhere\n    T: CheckBytes<Strategy<(), E>> + ?Sized,\n{\n    // SAFETY: The safety conditions of `check_bytes_with_context` are the same\n    // as the safety conditions of this function.\n    unsafe { check_bytes_with_context(value, &mut ()) }\n}"", ""code_context"": ""pub unsafe trait CheckBytes<C: Fallible + ?Sized> {\n    unsafe fn check_bytes(\n        value: *const Self,\n        context: &mut C,\n    ) -> Result<(), C::Error>;\n}""}","{""docstring"": ""Checks whether the given pointer points to a valid value.\n\n# Example\n\n```rust\nuse bytecheck::check_bytes;\nuse rancor::Failure;\n\nunsafe {\n    // 0 and 1 are valid values for bools\n    check_bytes::<bool, Failure>((&0u8 as *const u8).cast()).unwrap();\n    check_bytes::<bool, Failure>((&1u8 as *const u8).cast()).unwrap();\n\n    // 2 is not a valid value\n    check_bytes::<bool, Failure>((&2u8 as *const u8).cast()).unwrap_err();\n}\n```""}",docstring_generation
bytecheck,"{""code"": ""pub unsafe fn check_bytes_with_context<T, C, E>(\n    value: *const T,\n    context: &mut C,\n) -> Result<(), E>\nwhere\n    T: CheckBytes<Strategy<C, E>> + ?Sized,\n{\n    // SAFETY: The safety conditions of `check_bytes` are the same as the safety\n    // conditions of this function.\n    unsafe { CheckBytes::check_bytes(value, Strategy::wrap(context)) }\n}"", ""code_context"": ""pub unsafe trait CheckBytes<C: Fallible + ?Sized> {\n    unsafe fn check_bytes(\n        value: *const Self,\n        context: &mut C,\n    ) -> Result<(), C::Error>;\n}\n\npub unsafe trait Verify<C: Fallible + ?Sized> {\n    fn verify(&self, context: &mut C) -> Result<(), C::Error>;\n}""}","{""docstring"": ""Checks whether the given pointer points to a valid value within the given context.\n\n# Safety\n\nThe passed pointer must be aligned and point to enough initialized bytes to represent the type.\n\n# Example\n\n```rust\nuse core::{error::Error, fmt};\n\nuse bytecheck::{check_bytes_with_context, CheckBytes, Verify};\nuse rancor::{fail, Failure, Fallible, Source, Strategy};\n\ntrait Context {\n    fn is_allowed(&self, value: u8) -> bool;\n}\n\nimpl<T: Context + ?Sized, E> Context for Strategy<T, E> {\n    fn is_allowed(&self, value: u8) -> bool {\n        T::is_allowed(self, value)\n    }\n}\n\nstruct Allowed(u8);\n\nimpl Context for Allowed {\n    fn is_allowed(&self, value: u8) -> bool {\n        value == self.0\n    }\n}\n\n#[derive(CheckBytes)]\n#[bytecheck(verify)]\n#[repr(C)]\npub struct ContextualByte(u8);\n\nunsafe impl<C: Context + Fallible + ?Sized> Verify<C> for ContextualByte\nwhere\n    C::Error: Source,\n{\n    fn verify(&self, context: &mut C) -> Result<(), C::Error> {\n        #[derive(Debug)]\n        struct InvalidByte(u8);\n\n        impl fmt::Display for InvalidByte {\n            fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n                write!(f, \""invalid contextual byte: {}\"", self.0)\n            }\n        }\n\n        impl Error for InvalidByte {}\n\n        if !context.is_allowed(self.0) {\n            fail!(InvalidByte(self.0));\n        }\n\n        Ok(())\n    }\n}\n\nlet value = 45u8;\nunsafe {\n    // Checking passes when the context allows byte 45\n    check_bytes_with_context::<ContextualByte, _, Failure>(\n        (&value as *const u8).cast(),\n        &mut Allowed(45),\n    )\n    .unwrap();\n\n    // Checking fails when the context does not allow byte 45\n    check_bytes_with_context::<ContextualByte, _, Failure>(\n        (&value as *const u8).cast(),\n        &mut Allowed(0),\n    )\n    .unwrap_err();\n}\n```""}",docstring_generation
dotenvy,"{""code"": ""pub fn var(key: &str) -> Result<String, crate::Error> {\n    env::var(key).map_err(|e| match e {\n        VarError::NotPresent => Error::NotPresent(key.to_owned()),\n        VarError::NotUnicode(os_str) => Error::NotUnicode(os_str, key.to_owned()),\n    })\n}"", ""code_context"": ""pub enum Error {\n    LineParse(String, usize),\n    Io(io::Error, Option<PathBuf>),\n    NotPresent(String),\n    NotUnicode(OsString, String),\n    InvalidOp,\n    NoInput,\n}""}","{""docstring"": ""Fetches the environment variable `key` from the current process.\n\nThis is `std_env_var` but with an error type of `dotenvy::Error`.\n`dotenvy::Error` uses `NotPresent(String)` instead of `NotPresent`, reporting the name of the missing key.\n\n# Errors\n\nThis function will return an error if the environment variable isn't set.\n\nThis function may return an error if the environment variable's name contains the equal sign character (`=`) or the NUL character.\n\nThis function will return an error if the environment variable's value is not valid Unicode.""}",docstring_generation
dotenvy,"{""code"": ""impl<'a> EnvLoader<'a> {\n    pub fn load(self) -> Result<EnvMap, crate::Error> {\n        match self.sequence {\n            EnvSequence::EnvOnly => Ok(env::vars().collect()),\n            EnvSequence::EnvThenInput => {\n                let mut existing: EnvMap = env::vars().collect();\n                let input = self.load_input()?;\n                existing.extend(input);\n                Ok(existing)\n            }\n            EnvSequence::InputOnly => self.load_input(),\n            EnvSequence::InputThenEnv => {\n                let mut input = self.load_input()?;\n                input.extend(env::vars());\n                Ok(input)\n            }\n        }\n    }\n}"", ""code_context"": ""pub struct EnvLoader<'a> {\n    path: Option<PathBuf>,\n    reader: Option<Box<dyn Read + 'a>>,\n    sequence: EnvSequence,\n}\n\npub enum EnvSequence {\n    EnvOnly,\n    EnvThenInput,\n    InputOnly,\n    InputThenEnv,\n}\n\npub struct EnvMap(HashMap<String, String>);""}","{""docstring"": ""Loads environment variables into a hash map.\n\nThis is the primary method for loading environment variables.""}",docstring_generation
dotenvy,"{""code"": ""impl<'a> EnvLoader<'a> {\n    pub unsafe fn load_and_modify(self) -> Result<EnvMap, crate::Error> {\n        match self.sequence {\n            EnvSequence::EnvOnly => Err(Error::InvalidOp),\n            EnvSequence::EnvThenInput => {\n                let mut existing: EnvMap = env::vars().collect();\n                let input = unsafe { self.load_input_and_modify_override() }?;\n                existing.extend(input);\n                Ok(existing)\n            }\n            EnvSequence::InputOnly => unsafe { self.load_input_and_modify_override() },\n            EnvSequence::InputThenEnv => {\n                let existing: EnvMap = env::vars().collect();\n                let mut input = unsafe { self.load_input_and_modify() }?;\n                for k in input.keys() {\n                    if !existing.contains_key(k) {\n                        unsafe { env::set_var(k, &input[k]) };\n                    }\n                }\n                input.extend(existing);\n                Ok(input)\n            }\n        }\n    }\n}"", ""code_context"": ""pub enum Error {\n    LineParse(String, usize),\n    Io(io::Error, Option<PathBuf>),\n    NotPresent(String),\n    NotUnicode(OsString, String),\n    InvalidOp,\n    NoInput,\n}\n\npub struct EnvLoader<'a> {\n    path: Option<PathBuf>,\n    reader: Option<Box<dyn Read + 'a>>,\n    sequence: EnvSequence,\n}\n\npub enum EnvSequence {\n    EnvOnly,\n    EnvThenInput,\n    InputOnly,\n    InputThenEnv,\n}\n\npub struct EnvMap(HashMap<String, String>);""}","{""docstring"": ""Loads environment variables into a hash map, modifying the existing environment.\n\nThis calls `std::env::set_var` internally and is not thread-safe.\n\n# Errors\n\nThis function will return an error if the sequence is `EnvSequence::EnvOnly`.""}",docstring_generation
simple_asn1,"{""code"": ""fn __placeholder__(blocks: &[ASN1Block]) -> Option<&ASN1Block> {\n    blocks.iter().find(|block| matches!(block, ASN1Block::Sequence(_, _)))\n}"", ""code_context"": ""enum ASN1Block { Sequence(usize, Vec<ASN1Block>) }""}","{""function_name"": ""find_sequence_block""}",function_naming
simple_asn1,"{""code"": ""fn __placeholder__(block: &ASN1Block) -> bool {\n    matches!(block, ASN1Block::Explicit(_, _, _, _))\n}"", ""code_context"": ""enum ASN1Class { Universal, Application, ContextSpecific, Private }\nuse num_bigint::BigUint;\nenum ASN1Block { Explicit(ASN1Class, usize, BigUint, Box<ASN1Block>) }""}","{""function_name"": ""is_explicitly_tagged""}",function_naming
simple_asn1,"{""code"": ""fn __placeholder__(block: &ASN1Block) -> Option<&BigUint> {\n    if let ASN1Block::ObjectIdentifier(_, oid) = block {\n        oid.0.get(0)\n    } else {\n        None\n    }\n}"", ""code_context"": ""use num_bigint::BigUint;\nstruct OID(Vec<BigUint>);\nenum ASN1Block { ObjectIdentifier(usize, OID) }""}","{""function_name"": ""get_first_oid_component""}",function_naming
simple_asn1,"{""code"": ""fn __placeholder__(blocks: &[ASN1Block]) -> Result<Vec<ASN1Block>, ASN1DecodeErr> {\n    Ok(blocks.iter()\n        .filter(|block| matches!(block, ASN1Block::Sequence(_, _)))\n        .cloned()\n        .collect())\n}"", ""code_context"": ""enum ASN1DecodeErr {}\nenum ASN1Block { Sequence(usize, Vec<ASN1Block>) }""}","{""function_name"": ""filter_sequence_blocks""}",function_naming
simple_asn1,"{""code"": ""fn __placeholder__(block: &ASN1Block) -> Result<Vec<u8>, ASN1EncodeErr> {\n    to_der(block)\n}"", ""code_context"": ""enum ASN1EncodeErr {}\nfn to_der(_i: &ASN1Block) -> Result<Vec<u8>, ASN1EncodeErr> { Ok(vec![]) }\nenum ASN1Block {}""}","{""function_name"": ""encode_block_der""}",function_naming
parquet-variant-json,"{""title"": ""Parse JSON array of objects into Variant list and serialize back to JSON"", ""description"": ""A developer receives a JSON array where each element is an object representing a record. They need a helper that parses the array into a Variant (list) and then returns a compact JSON string of the same structure, preserving all nested types."", ""code_context"": ""use arrow_schema::ArrowError;\nuse parquet_variant::{Variant, VariantBuilder};\nuse parquet_variant_json::{json_to_variant, variant_to_json_string};""}","{""code"": ""pub fn parse_and_roundtrip(json: &str) -> Result<String, ArrowError> {\n    let mut builder = VariantBuilder::new();\n    json_to_variant(json, &mut builder)?;\n    let (metadata, value) = builder.finish();\n    let variant = Variant::try_new(&metadata, &value)?;\n    variant_to_json_string(&variant)\n}""}",code_generation
parquet-variant-json,"{""title"": ""Extract optional string field from Variant object with default"", ""description"": ""A developer has a Variant representing a JSON object that may or may not contain a \""name\"" field. They need a utility that safely extracts the field as a Rust String, returning a default value when the field is missing or not a string."", ""code_context"": ""use arrow_schema::ArrowError;\nuse parquet_variant::{Variant, VariantObject};""}","{""code"": ""pub fn get_name_field(variant: &Variant) -> Result<String, ArrowError> {\n    match variant {\n        Variant::Object(obj) => {\n            let mut found: Option<&Variant> = None;\n            for (key, value) in obj.iter() {\n                if key == \""name\"" {\n                    found = Some(value);\n                    break;\n                }\n            }\n            match found {\n                Some(v) => match v {\n                    Variant::String(s) => Ok(s.clone()),\n                    Variant::ShortString(ss) => Ok(ss.as_str().to_string()),\n                    _ => Err(ArrowError::InvalidArgumentError(\""Field 'name' is not a string\"".to_string())),\n                },\n                None => Ok(\""unknown\"".to_string()),\n            }\n        },\n        _ => Err(ArrowError::InvalidArgumentError(\""Expected Variant::Object\"".to_string())),\n    }\n}""}",code_generation
parquet-variant-json,"{""title"": ""Serialize binary payload as base64 within a JSON object"", ""description"": ""A developer needs to embed raw binary data into JSON for transport. The helper builds a Variant object with a single \""payload\"" field containing the binary data, which is automatically base64‑encoded by the crate's JSON conversion."", ""code_context"": ""use arrow_schema::ArrowError;\nuse parquet_variant::{Variant, VariantBuilder};\nuse parquet_variant_json::variant_to_json_string;""}","{""code"": ""pub fn binary_to_json(payload: &[u8]) -> Result<String, ArrowError> {\n    let mut builder = VariantBuilder::new();\n    let mut obj = builder.new_object();\n    obj.insert(\""payload\"", Variant::Binary(payload));\n    obj.finish()?;\n    let (metadata, value) = builder.finish();\n    let variant = Variant::try_new(&metadata, &value)?;\n    variant_to_json_string(&variant)\n}""}",code_generation
parquet-variant-json,"{""title"": ""Batch convert multiple JSON strings into a Variant list"", ""description"": ""A developer processes a slice of JSON strings, each representing an independent record. They need a function that parses each string into its own Variant and collects the results into a single Variant list for downstream processing."", ""code_context"": ""use arrow_schema::ArrowError;\nuse parquet_variant::{Variant, VariantBuilder, VariantBuilderExt};\nuse parquet_variant_json::json_to_variant;""}","{""code"": ""pub fn batch_json_to_variant_list(jsons: &[&str]) -> Result<Variant<'static, 'static>, ArrowError> {\n    let mut builder = VariantBuilder::new();\n    let mut list = builder.new_list();\n    for json in jsons {\n        let mut inner_builder = VariantBuilder::new();\n        json_to_variant(json, &mut inner_builder)?;\n        let (meta, val) = inner_builder.finish();\n        let inner_variant = Variant::try_new(&meta, &val)?;\n        list.append_value(inner_variant);\n    }\n    list.finish();\n    let (metadata, value) = builder.finish();\n    Variant::try_new(&metadata, &value)\n}""}",code_generation
lz4-sys,"{""code"": ""impl<R: Read> Decoder<R> {\n    pub fn new(r: R) -> Result<Decoder<R>> {\n        Ok(Decoder {\n            r,\n            c: DecoderContext::new()?,\n            buf: vec![0; BUFFER_SIZE].into_boxed_slice(),\n            pos: BUFFER_SIZE,\n            len: BUFFER_SIZE,\n            // Minimal LZ4 stream size\n            next: 11,\n        })\n    }\n}"", ""code_context"": ""use std::io::Result;\nuse std::io::Read;\nuse super::liblz4::*;\nuse super::size_t;\n\nconst BUFFER_SIZE: usize = 32 * 1024;\n\n#[derive(Debug)]\nstruct DecoderContext {\n    c: LZ4FDecompressionContext,\n}\n\npub struct Decoder<R> {\n    c: DecoderContext,\n    r: R,\n    buf: Box<[u8]>,\n    pos: usize,\n    len: usize,\n    next: usize,\n}\n\npub struct LZ4FDecompressionContext(pub *mut c_void);\nunsafe impl Send for LZ4FDecompressionContext {}""}","{""docstring"": ""Creates a new decoder which reads its input from the given input stream. The input stream can be re-acquired by calling `finish()`.""}",docstring_generation
lz4-sys,"{""code"": ""pub fn compress(src: &[u8], mode: Option<CompressionMode>, prepend_size: bool) -> Result<Vec<u8>> {\n    // 0 iff src too large\n    let compress_bound: i32 = unsafe { LZ4_compressBound(src.len() as i32) };\n\n    if src.len() > (i32::max_value() as usize) || compress_bound <= 0 {\n        return Err(Error::new(\n            ErrorKind::InvalidInput,\n            \""Compression input too long.\"",\n        ));\n    }\n\n    let mut compressed: Vec<u8> = vec![\n        0;\n        (if prepend_size {\n            compress_bound + 4\n        } else {\n            compress_bound\n        }) as usize\n    ];\n\n    let dec_size = compress_to_buffer(src, mode, prepend_size, &mut compressed)?;\n    compressed.truncate(dec_size as usize);\n    Ok(compressed)\n}"", ""code_context"": ""use std::io::{Error, ErrorKind, Result};\n\n#[derive(Clone, Copy, Debug)]\npub enum CompressionMode {\n    HIGHCOMPRESSION(i32),\n    FAST(i32),\n    DEFAULT,\n}""}","{""docstring"": ""Compresses the full src buffer using the specified CompressionMode, where None and Some(Default) are treated equally. If prepend_size is set, the source length will be prepended to the output buffer.""}",docstring_generation
lz4-sys,"{""code"": ""pub fn decompress(src: &[u8], uncompressed_size: Option<i32>) -> Result<Vec<u8>> {\n    let size = get_decompressed_size(src, uncompressed_size)?;\n\n    let mut buffer = vec![0u8; size];\n\n    let sz = decompress_to_buffer(src, uncompressed_size, &mut buffer)?;\n    buffer.truncate(sz);\n    Ok(buffer)\n}"", ""code_context"": ""use std::io::{Error, ErrorKind, Result};\n\nfn get_decompressed_size(src: &[u8], uncompressed_size: Option<i32>) -> Result<usize> {\n    let size;\n    if let Some(s) = uncompressed_size {\n        size = s;\n    } else {\n        if src.len() < 4 {\n            return Err(Error::new(\n                ErrorKind::InvalidInput,\n                \""Source buffer must at least contain size prefix.\"",\n            ));\n        }\n        size = (src[0] as i32) | (src[1] as i32) << 8 | (src[2] as i32) << 16 | (src[3] as i32) << 24;\n    }\n    if size < 0 {\n        return Err(Error::new(\n            ErrorKind::InvalidInput,\n            if uncompressed_size.is_some() {\n                \""Size parameter must not be negative.\""\n            } else {\n                \""Parsed size prefix in buffer must not be negative.\""\n            },\n        ));\n    }\n    if unsafe { LZ4_compressBound(size) } <= 0 {\n        return Err(Error::new(\n            ErrorKind::InvalidInput,\n            \""Given size parameter is too big\"",\n        ));\n    }\n    Ok(size as usize)\n}""}","{""docstring"": ""Decompresses the src buffer. If uncompressed_size is None, the source length will be read from the start of the input buffer.""}",docstring_generation
atoi,"{""title"": ""Parse signed integer with overflow checking"", ""description"": ""A developer needs to parse a signed integer from a byte slice while safely handling overflow. They want a helper that returns None when the input would overflow or is malformed, using the crate's FromRadix10SignedChecked trait."", ""code_context"": ""use atoi::FromRadix10SignedChecked;""}","{""code"": ""pub fn parse_i32_signed(text: &[u8]) -> Option<i32> {\n    let (opt, _) = i32::from_radix_10_signed_checked(text);\n    opt\n}""}",code_generation
atoi,"{""title"": ""Parse hexadecimal number with optional 0x prefix and overflow checking"", ""description"": ""A developer receives hexadecimal values that may optionally start with a \""0x\"" or \""0X\"" prefix. They need a function that strips the prefix if present, parses the remaining digits as a u32, checks for overflow, and reports how many bytes were consumed."", ""code_context"": ""use atoi::FromRadix16Checked;""}","{""code"": ""pub fn parse_hex_u32(text: &[u8]) -> (Option<u32>, usize) {\n    let (slice, prefix_len) = if text.starts_with(b\""0x\"") || text.starts_with(b\""0X\"") {\n        (&text[2..], 2)\n    } else {\n        (text, 0)\n    };\n    let (opt, used) = u32::from_radix_16_checked(slice);\n    (opt, used + prefix_len)\n}""}",code_generation
atoi,"{""title"": ""Parse signed integer and return remaining slice"", ""description"": ""When processing a stream of bytes, a developer wants to parse a signed integer with overflow checking and then continue processing the rest of the data. The function should return the parsed value (or None) together with the unconsumed remainder of the slice."", ""code_context"": ""use atoi::FromRadix10SignedChecked;""}","{""code"": ""pub fn parse_signed_and_rest<I>(text: &[u8]) -> (Option<I>, &[u8])\nwhere\n    I: FromRadix10SignedChecked,\n{\n    let (opt, used) = I::from_radix_10_signed_checked(text);\n    (opt, &text[used..])\n}""}",code_generation
atoi,"{""title"": ""Parse large i128 number with overflow detection"", ""description"": ""A developer needs to parse a potentially very large decimal number into an i128, ensuring that any overflow is detected and reported as None. The function should use the crate's checked parsing trait for i128."", ""code_context"": ""use atoi::FromRadix10Checked;""}","{""code"": ""pub fn parse_i128(text: &[u8]) -> Option<i128> {\n    let (opt, _) = i128::from_radix_10_checked(text);\n    opt\n}""}",code_generation
atoi,"{""title"": ""Parse comma‑separated list of u32 values with overflow safety"", ""description"": ""A developer receives a byte slice containing decimal numbers separated by commas (e.g., b\""12,34,56\""). They need a helper that parses each number using overflow‑checked parsing, stops on the first error, and returns a Vec of the successfully parsed u32 values."", ""code_context"": ""use atoi::FromRadix10Checked;""}","{""code"": ""pub fn parse_u32_list(text: &[u8]) -> Option<Vec<u32>> {\n    let mut remaining = text;\n    let mut result = Vec::new();\n    loop {\n        let (opt, used) = u32::from_radix_10_checked(remaining);\n        if used == 0 {\n            break;\n        }\n        match opt {\n            Some(num) => result.push(num),\n            None => return None,\n        }\n        remaining = &remaining[used..];\n        if remaining.starts_with(b\"",\"") {\n            remaining = &remaining[1..];\n        } else {\n            break;\n        }\n    }\n    Some(result)\n}""}",code_generation
dpi,"{""title"": ""Convert a logical position to a physical position respecting the scale factor"", ""description"": ""A UI developer needs to render an element at a logical coordinate. The function should validate the scale factor and convert the logical position into a physical position so the element appears at the correct size on any DPI screen."", ""code_context"": ""use dpi::{LogicalPosition, PhysicalPosition, Pixel, validate_scale_factor};""}","{""code"": ""pub fn logical_to_physical_position<P: Pixel>(logical: LogicalPosition<P>, scale_factor: f64) -> PhysicalPosition<P> {\n    validate_scale_factor(scale_factor);\n    logical.to_physical(scale_factor)\n}""}",code_generation
dpi,"{""title"": ""Clamp a logical size to minimum and maximum physical dimensions"", ""description"": ""When scaling UI elements, the resulting physical size must stay within predefined bounds. This helper converts a logical size to physical pixels, clamps it, and returns the clamped physical size."", ""code_context"": ""use dpi::{LogicalSize, PhysicalSize, Size, Pixel, validate_scale_factor};""}","{""code"": ""pub fn clamp_logical_size<P: Pixel>(\n    logical: LogicalSize<P>,\n    scale_factor: f64,\n    min: PhysicalSize<u32>,\n    max: PhysicalSize<u32>,\n) -> PhysicalSize<u32> {\n    validate_scale_factor(scale_factor);\n    let physical = logical.to_physical::<u32>(scale_factor);\n    Size::clamp(physical, min, max, scale_factor).into()\n}""}",code_generation
dpi,"{""title"": ""Round a logical unit to the nearest integer pixel value"", ""description"": ""Rasterization often requires an integer pixel count. This function takes a logical unit, rounds its value to the nearest integer, and returns a logical unit containing an unsigned integer pixel."", ""code_context"": ""use dpi::{LogicalUnit, Pixel};""}","{""code"": ""pub fn round_logical_unit<P: Pixel>(unit: LogicalUnit<P>) -> LogicalUnit<u32> {\n    let value = unit.0.into();\n    let rounded = value.round() as u32;\n    LogicalUnit::new(rounded)\n}""}",code_generation
dpi,"{""title"": ""Convert a physical size to a logical size with proper rounding"", ""description"": ""For layout calculations a developer needs the logical size that corresponds to a given physical size and scale factor. The conversion should preserve fractional values as f64 for further processing."", ""code_context"": ""use dpi::{PhysicalSize, LogicalSize, Pixel, validate_scale_factor};""}","{""code"": ""pub fn physical_to_logical_size<P: Pixel>(\n    physical: PhysicalSize<P>,\n    scale_factor: f64,\n) -> LogicalSize<f64> {\n    validate_scale_factor(scale_factor);\n    physical.to_logical(scale_factor)\n}""}",code_generation
sha1_smol,"{""code"": ""impl Sha1 {\n    pub fn new() -> Sha1 {\n        Sha1 {\n            state: DEFAULT_STATE,\n            len: 0,\n            blocks: Blocks {\n                len: 0,\n                block: [0; 64],\n            },\n        }\n    }\n}"", ""code_context"": ""pub struct Sha1 {\n    state: Sha1State,\n    blocks: Blocks,\n    len: u64,\n}\n\nstruct Blocks {\n    len: u32,\n    block: [u8; 64],\n}\n\n#[derive(Copy, Clone, PartialOrd, Ord, PartialEq, Eq, Hash, Default)]\nstruct Sha1State {\n    state: [u32; 5],\n}""}","{""docstring"": ""Creates an fresh sha1 hash object.\n\nThis is equivalent to creating a hash with `Default::default`.""}",docstring_generation
sha1_smol,"{""code"": ""impl Sha1 {\n    pub fn from<D: AsRef<[u8]>>(data: D) -> Sha1 {\n        let mut rv = Sha1::new();\n        rv.update(data.as_ref());\n        rv\n    }\n}"", ""code_context"": ""pub struct Sha1 {\n    state: Sha1State,\n    blocks: Blocks,\n    len: u64,\n}\n\nstruct Blocks {\n    len: u32,\n    block: [u8; 64],\n}\n\n#[derive(Copy, Clone, PartialOrd, Ord, PartialEq, Eq, Hash, Default)]\nstruct Sha1State {\n    state: [u32; 5],\n}""}","{""docstring"": ""Shortcut to create a sha1 from some bytes.\n\nThis also lets you create a hash from a utf-8 string.  This is equivalent\n to making a new Sha1 object and calling `update` on it once.""}",docstring_generation
sha1_smol,"{""code"": ""impl Digest {\n    pub fn bytes(&self) -> [u8; DIGEST_LENGTH] {\n        [\n            (self.data.state[0] >> 24) as u8,\n            (self.data.state[0] >> 16) as u8,\n            (self.data.state[0] >> 8) as u8,\n            (self.data.state[0] >> 0) as u8,\n            (self.data.state[1] >> 24) as u8,\n            (self.data.state[1] >> 16) as u8,\n            (self.data.state[1] >> 8) as u8,\n            (self.data.state[1] >> 0) as u8,\n            (self.data.state[2] >> 24) as u8,\n            (self.data.state[2] >> 16) as u8,\n            (self.data.state[2] >> 8) as u8,\n            (self.data.state[2] >> 0) as u8,\n            (self.data.state[3] >> 24) as u8,\n            (self.data.state[3] >> 16) as u8,\n            (self.data.state[3] >> 8) as u8,\n            (self.data.state[3] >> 0) as u8,\n            (self.data.state[4] >> 24) as u8,\n            (self.data.state[4] >> 16) as u8,\n            (self.data.state[4] >> 8) as u8,\n            (self.data.state[4] >> 0) as u8,\n        ]\n    }\n}"", ""code_context"": ""#[derive(PartialOrd, Ord, PartialEq, Eq, Hash, Clone, Copy, Default)]\npub struct Digest {\n    data: Sha1State,\n}\n\n#[derive(Copy, Clone, PartialOrd, Ord, PartialEq, Eq, Hash, Default)]\nstruct Sha1State {\n    state: [u32; 5],\n}""}","{""docstring"": ""Returns the 160 bit (20 byte) digest as a byte array.""}",docstring_generation
sha1_smol,"{""code"": ""impl Sha1 {\n    #[cfg(feature = \""alloc\"")]\n    pub fn hexdigest(&self) -> std::string::String {\n        use std::string::ToString;\n        self.digest().to_string()\n    }\n}"", ""code_context"": ""pub struct Sha1 {\n    state: Sha1State,\n    blocks: Blocks,\n    len: u64,\n}\n\nstruct Blocks {\n    len: u32,\n    block: [u8; 64],\n}\n\n#[derive(Copy, Clone, PartialOrd, Ord, PartialEq, Eq, Hash, Default)]\nstruct Sha1State {\n    state: [u32; 5],\n}\n\npub const DIGEST_LENGTH: usize = 20;\n\n#[derive(PartialOrd, Ord, PartialEq, Eq, Hash, Clone, Copy, Default)]\npub struct Digest {\n    data: Sha1State,\n}""}","{""docstring"": ""Retrieve the digest result as hex string directly.\n\n(The function is only available if the `alloc` feature is enabled)""}",docstring_generation
sha1_smol,"{""code"": ""impl Sha1 {\n    pub fn update(&mut self, data: &[u8]) {\n        let len = &mut self.len;\n        let state = &mut self.state;\n        self.blocks.input(data, |block| {\n            *len += block.len() as u64;\n            state.process(block);\n        })\n    }\n}"", ""code_context"": ""pub struct Sha1 {\n    state: Sha1State,\n    blocks: Blocks,\n    len: u64,\n}\n\nstruct Blocks {\n    len: u32,\n    block: [u8; 64],\n}\n\n#[derive(Copy, Clone, PartialOrd, Ord, PartialEq, Eq, Hash, Default)]\nstruct Sha1State {\n    state: [u32; 5],\n}""}","{""docstring"": ""Update hash with input data.""}",docstring_generation
dotenvy,"{""code"": ""pub fn var(key: &str) -> Result<String, crate::Error> {\n    env::var(key).map_err(|e| match e {\n        VarError::NotPresent => Error::NotPresent(key.to_owned()),\n        VarError::NotUnicode(os_str) => Error::NotUnicode(os_str, key.to_owned()),\n    })\n}"", ""code_context"": ""use std::env::{self, VarError};\n\npub enum Error {\n    NotPresent(String),\n    NotUnicode(std::ffi::OsString, String),\n}""}","{""summary"": ""Retrieves an environment variable, returning an error if it is missing or not valid Unicode.""}",code_summarization
dotenvy,"{""code"": ""impl<'a> EnvLoader<'a> {\n    pub unsafe fn load_and_modify(self) -> Result<EnvMap, crate::Error> {\n        match self.sequence {\n            EnvSequence::EnvOnly => Err(Error::InvalidOp),\n            EnvSequence::EnvThenInput => {\n                let mut existing: EnvMap = env::vars().collect();\n                let input = unsafe { self.load_input_and_modify_override() }?;\n                existing.extend(input);\n                Ok(existing)\n            }\n            EnvSequence::InputOnly => unsafe { self.load_input_and_modify_override() },\n            EnvSequence::InputThenEnv => {\n                let existing: EnvMap = env::vars().collect();\n                let mut input = unsafe { self.load_input_and_modify() }?;\n                for k in input.keys() {\n                    if !existing.contains_key(k) {\n                        unsafe { env::set_var(k, &input[k]) };\n                    }\n                }\n                input.extend(existing);\n                Ok(input)\n            }\n        }\n    }\n}"", ""code_context"": ""use std::env;\nuse std::collections::HashMap;\n\npub struct EnvMap(pub HashMap<String, String>);\n\npub enum Error {\n    InvalidOp,\n}\n\npub enum EnvSequence {\n    EnvOnly,\n    EnvThenInput,\n    InputOnly,\n    InputThenEnv,\n}\n\npub struct EnvLoader<'a> {\n    sequence: EnvSequence,\n    // other fields omitted\n}\n\nimpl<'a> EnvLoader<'a> {\n    unsafe fn load_input_and_modify_override(&self) -> Result<EnvMap, crate::Error> {\n        unimplemented!()\n    }\n    unsafe fn load_input_and_modify(&self) -> Result<EnvMap, crate::Error> {\n        unimplemented!()\n    }\n}""}","{""summary"": ""Loads environment variables and modifies the process environment according to the loader's sequence.""}",code_summarization
dotenvy,"{""code"": ""pub fn parse_line(\n    line: &str,\n    substitution_data: &mut HashMap<String, Option<String>>,\n) -> Result<Option<(String, String)>, ParseBufError> {\n    let mut parser = LineParser::new(line, substitution_data);\n    parser.parse_line()\n}"", ""code_context"": ""use std::collections::HashMap;\n\npub enum ParseBufError {\n    LineParse(String, usize),\n    Io(std::io::Error),\n}\n\npub struct LineParser<'a> {\n    original_line: &'a str,\n    substitution_data: &'a mut HashMap<String, Option<String>>,\n    line: &'a str,\n    pos: usize,\n}\n\nimpl<'a> LineParser<'a> {\n    fn new(line: &'a str, substitution_data: &'a mut HashMap<String, Option<String>>) -> Self {\n        LineParser {\n            original_line: line,\n            substitution_data,\n            line: line.trim_end(),\n            pos: 0,\n        }\n    }\n    fn parse_line(&mut self) -> Result<Option<(String, String)>, ParseBufError> {\n        unimplemented!()\n    }\n}""}","{""summary"": ""Parses a single line of an env file, handling variable substitution and returning a key‑value pair.""}",code_summarization
dotenvy,"{""code"": ""#[proc_macro]\npub fn dotenv(input: TokenStream) -> TokenStream {\n    let input = input.into();\n    unsafe { dotenv_inner(input) }.into()\n}"", ""code_context"": ""use dotenvy::EnvLoader;\nuse proc_macro::TokenStream;\nuse proc_macro2::TokenStream as TokenStream2;\nuse quote::quote;\nuse std::env::{self, VarError};\nuse syn::{parse::Parser, punctuated::Punctuated, spanned::Spanned, LitStr, Token};\n\nunsafe fn dotenv_inner(input: TokenStream2) -> TokenStream2 {\n    let loader = EnvLoader::new();\n    if let Err(e) = unsafe { loader.load_and_modify() } {\n        let msg = e.to_string();\n        return quote! {\n            compile_error!(#msg);\n        };\n    }\n\n    match expand_env(input) {\n        Ok(stream) => stream,\n        Err(e) => e.to_compile_error(),\n    }\n}\n\nfn expand_env(input_raw: TokenStream2) -> syn::Result<TokenStream2> {\n    let args = <Punctuated<syn::LitStr, Token![,]>>::parse_terminated\n        .parse(input_raw.into())\n        .expect(\""expected macro to be called with a comma-separated list of string literals\"");\n\n    let mut iter = args.iter();\n\n    let var_name = iter\n        .next()\n        .ok_or_else(|| syn::Error::new(args.span(), \""dotenv! takes 1 or 2 arguments\""))?\n        .value();\n    let err_msg = iter.next();\n\n    if iter.next().is_some() {\n        return Err(syn::Error::new(\n            args.span(),\n            \""dotenv! takes 1 or 2 arguments\"",\n        ));\n    }\n\n    match env::var(&var_name) {\n        Ok(val) => Ok(quote!(#val)),\n        Err(e) => Err(syn::Error::new(\n            var_name.span(),\n            err_msg.map_or_else(\n                || match e {\n                    VarError::NotPresent => {\n                        format!(\""environment variable `{var_name}` not defined\"")\n                    }\n\n                    VarError::NotUnicode(s) => {\n                        format!(\""environment variable `{var_name}` was not valid Unicode: {s:?}\"",)\n                    }\n                },\n                LitStr::value,\n            ),\n        )),\n    }\n}""}","{""summary"": ""Compile‑time macro that expands to the value of an environment variable, emitting a compile error if missing.""}",code_summarization
libp2p-webtransport-websys,"{""code"": ""#[derive(Debug)]\npub struct Connection {\n    inner: SendWrapper<ConnectionInner>,\n}"", ""code_context"": ""use crate::bindings::{WebTransport, WebTransportBidirectionalStream};\nuse crate::fused_js_promise::FusedJsPromise;\nuse web_sys::ReadableStreamDefaultReader;\n\npub struct ConnectionInner {\n    session: WebTransport,\n    create_stream_promise: FusedJsPromise,\n    incoming_stream_promise: FusedJsPromise,\n    incoming_streams_reader: ReadableStreamDefaultReader,\n    closed: bool,\n}""}","{""docstring"": ""An opened WebTransport connection.\n\nThis struct represents an opened WebTransport connection.\n\n# Examples\n\nlet connection = Connection::new(&endpoint);\n\n#![allow(unused_mut)]\n\n#![allow(clippy::all)]""}",docstring_generation
libp2p-webtransport-websys,"{""code"": ""pub(crate) fn parse_reader_response(resp: &JsValue) -> Result<Option<JsValue>, JsValue> {\n    let value = Reflect::get(resp, &JsValue::from_str(\""value\""))?;\n    let done = Reflect::get(resp, &JsValue::from_str(\""done\""))?\n        .as_bool()\n        .unwrap_or_default();\n\n    if value.is_undefined() || done {\n        Ok(None)\n    } else {\n        Ok(Some(value))\n    }\n}"", ""code_context"": ""use js_sys::{Reflect, JsValue};""}","{""docstring"": ""Parse response from `ReadableStreamDefaultReader::read`.\n\nThis function extracts the `value` and `done` fields from the JavaScript object returned by a stream read operation. It returns `Ok(None)` if the stream is finished or the value is undefined, otherwise returns `Ok(Some(value))`.""}",docstring_generation
libp2p-webtransport-websys,"{""code"": ""#[derive(Debug)]\npub(crate) struct FusedJsPromise {\n    promise: Option<JsFuture>,\n}"", ""code_context"": ""use std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\nuse js_sys::Promise;\nuse wasm_bindgen_futures::JsFuture;""}","{""docstring"": ""Convenient wrapper to poll a promise to completion.""}",docstring_generation
libp2p-webtransport-websys,"{""code"": ""impl StreamInner {\n    fn poll_reader_read(&mut self, cx: &mut Context) -> Poll<io::Result<Option<Uint8Array>>> {\n        let val = ready!(self\n            .reader_read_promise\n            .maybe_init(|| self.reader.read())\n            .poll_unpin(cx))\n        .map_err(to_io_error);\n        let val = parse_reader_response(&val)\n            .map_err(to_io_error)?\n            .map(Uint8Array::from);\n        Poll::Ready(Ok(val))\n    }\n}"", ""code_context"": ""use std::task::{Context, Poll};\nuse futures::FutureExt;\nuse js_sys::Uint8Array;\nuse crate::utils::{parse_reader_response, to_io_error};\nuse crate::fused_js_promise::FusedJsPromise;\nuse web_sys::{ReadableStreamDefaultReader, WritableStreamDefaultWriter};\n\nenum StreamState {\n    Open,\n    Closing,\n    Closed,\n}\n\nstruct StreamInner {\n    reader: ReadableStreamDefaultReader,\n    reader_read_promise: FusedJsPromise,\n    read_leftovers: Option<Uint8Array>,\n    writer: WritableStreamDefaultWriter,\n    writer_state: StreamState,\n    writer_ready_promise: FusedJsPromise,\n    writer_closed_promise: FusedJsPromise,\n}""}","{""summary"": ""Polls the reader promise to read data from a WebTransport stream, handling errors and parsing the response.""}",code_summarization
libp2p-webtransport-websys,"{""code"": ""impl ConnectionInner {\n    fn poll_create_bidirectional_stream(&mut self, cx: &mut Context) -> Poll<Result<Stream, Error>> {\n        let val = ready!(self\n            .create_stream_promise\n            .maybe_init(|| self.session.create_bidirectional_stream())\n            .poll_unpin(cx))\n        .map_err(Error::from_js_value);\n        let bidi_stream = to_js_type::<WebTransportBidirectionalStream>(val)?;\n        let stream = Stream::new(bidi_stream)?;\n        Poll::Ready(Ok(stream))\n    }\n}"", ""code_context"": ""use std::task::{Context, Poll};\nuse futures::FutureExt;\nuse crate::bindings::{WebTransport, WebTransportBidirectionalStream};\nuse crate::fused_js_promise::FusedJsPromise;\nuse crate::utils::to_js_type;\nuse crate::Error;\nuse crate::Stream;\n\nstruct ConnectionInner {\n    session: WebTransport,\n    create_stream_promise: FusedJsPromise,\n    // other fields omitted for brevity\n}""}","{""summary"": ""Polls the promise to create a bidirectional stream, converting the result into a `Stream` object.""}",code_summarization
libp2p-webtransport-websys,"{""code"": ""impl Endpoint {\n    fn url(&self) -> String {\n        let host = &self.host;\n        let port = self.port;\n        if self.is_ipv6 {\n            format!(\""https://[{host}]:{port}/.well-known/libp2p-webtransport?type=noise\"")\n        } else {\n            format!(\""https://{host}:{port}/.well-known/libp2p-webtransport?type=noise\"")\n        }\n    }\n}"", ""code_context"": ""struct Endpoint {\n    host: String,\n    port: u16,\n    is_ipv6: bool,\n    // other fields omitted for brevity\n}""}","{""summary"": ""Constructs the WebTransport URL for the endpoint, handling IPv6 formatting.""}",code_summarization
libp2p-websocket,"{""code"": ""#[derive(Debug)]\npub enum Error<E> {\n    Transport(E),\n    Tls(tls::Error),\n    Handshake(Box<dyn error::Error + Send + Sync>),\n    TooManyRedirects,\n    InvalidMultiaddr(Multiaddr),\n    InvalidRedirectLocation,\n    Base(Box<dyn error::Error + Send + Sync>),\n}"", ""code_context"": null}","{""docstring"": ""Error in WebSockets.""}",docstring_generation
libp2p-websocket,"{""code"": ""#[derive(Debug)]\npub struct Config<T> {\n    transport: Arc<Mutex<T>>,\n    max_data_size: usize,\n    tls_config: tls::Config,\n    max_redirects: u8,\n    listener_protos: HashMap<ListenerId, WsListenProto<'static>>,\n}"", ""code_context"": ""#[derive(Debug, PartialEq, Eq, Hash, Clone)]\npub(crate) enum WsListenProto<'a> {\n    Ws(std::borrow::Cow<'a, str>),\n    Wss(std::borrow::Cow<'a, str>),\n    TlsWs(std::borrow::Cow<'a, str>),\n}""}","{""docstring"": ""A Websocket transport whose output type is a [`Stream`] and [`Sink`] of frame payloads which does not implement [`AsyncRead`] or [`AsyncWrite`]. See [`crate::Config`] if you require the latter.""}",docstring_generation
libp2p-websocket,"{""code"": ""impl<T> Config<T>\nwhere\n    T: Send,\n{\n    pub fn new(transport: T) -> Self {\n        Config {\n            transport: Arc::new(Mutex::new(transport)),\n            max_data_size: MAX_DATA_SIZE,\n            tls_config: tls::Config::client(),\n            max_redirects: 0,\n            listener_protos: HashMap::new(),\n        }\n    }\n}"", ""code_context"": ""/// Max. number of payload bytes of a single frame.\nconst MAX_DATA_SIZE: usize = 256 * 1024 * 1024;\n\n#[derive(Debug)]\npub struct Config<T> {\n    transport: Arc<Mutex<T>>,\n    max_data_size: usize,\n    tls_config: tls::Config,\n    max_redirects: u8,\n    listener_protos: HashMap<ListenerId, WsListenProto<'static>>,\n}""}","{""docstring"": ""Create a new websocket transport based on another transport.""}",docstring_generation
libp2p-webtransport-websys,"{""code_before"": ""let mut data = Vec::new();\nfor i in 0..100_000 {\n    data.push(i);\n}"", ""code_context"": ""use std::vec::Vec;""}","{""rationale"": ""Preallocates the vector capacity to the exact number of elements, eliminating repeated reallocations and memory copies during the loop, which reduces allocation overhead and improves runtime performance."", ""code_after"": ""let mut data = Vec::with_capacity(100_000);\nfor i in 0..100_000 {\n    data.push(i);\n}""}",code_optimization
libp2p-webtransport-websys,"{""code_before"": ""let mut result = String::new();\nresult.push_str(prefix);\nresult.push_str(suffix);\nresult"", ""code_context"": ""use std::string::String;""}","{""rationale"": ""Allocates the exact amount of memory needed for the final string up front, avoiding multiple reallocations as the string grows, which reduces heap allocations and copying."", ""code_after"": ""let mut result = String::with_capacity(prefix.len() + suffix.len());\nresult.push_str(prefix);\nresult.push_str(suffix);\nresult""}",code_optimization
libp2p-webtransport-websys,"{""code_before"": ""let mut sum = 0u64;\nfor &x in data.iter() {\n    sum += x;\n}\nsum"", ""code_context"": ""use std::iter::Iterator;""}","{""rationale"": ""Leverages the highly optimized `Iterator::sum` implementation, removing the explicit loop and mutable accumulator, which can be faster due to internal optimizations and reduces code complexity."", ""code_after"": ""let sum: u64 = data.iter().sum();""}",code_optimization
libp2p-webtransport-websys,"{""title"": ""Convert Multiaddr to WebTransport URL"", ""description"": ""A developer needs to convert a `Multiaddr` into the WebTransport URL used by the libp2p‑webtransport‑websys crate. The helper should parse the multiaddr, build an `Endpoint` and return the URL string, propagating any crate errors."", ""code_context"": ""use libp2p_webtransport_websys::endpoint::Endpoint;\nuse libp2p_webtransport_websys::Error;\n\npub fn multiaddr_to_webtransport_url(addr: &multiaddr::Multiaddr) -> Result<String, Error> {\n    let endpoint = Endpoint::from_multiaddr(addr)?;\n    Ok(endpoint.url())\n}""}","{""code"": ""pub fn multiaddr_to_webtransport_url(addr: &multiaddr::Multiaddr) -> Result<String, libp2p_webtransport_websys::Error> {\n    let endpoint = libp2p_webtransport_websys::endpoint::Endpoint::from_multiaddr(addr)?;\n    Ok(endpoint.url())\n}""}",code_generation
libp2p-webtransport-websys,"{""title"": ""Wrap WebTransportBidirectionalStream into libp2p Stream"", ""description"": ""When a low‑level `WebTransportBidirectionalStream` is obtained from the browser API, the developer wants to turn it into the higher‑level `libp2p_webtransport_websys::Stream` type used by the rest of the library."", ""code_context"": ""use libp2p_webtransport_websys::bindings::WebTransportBidirectionalStream;\nuse libp2p_webtransport_websys::Stream;\nuse libp2p_webtransport_websys::Error;\n\npub fn webtransport_to_libp2p_stream(bidi: WebTransportBidirectionalStream) -> Result<Stream, Error> {\n    let stream = Stream::new(bidi)?;\n    Ok(stream)\n}""}","{""code"": ""pub fn webtransport_to_libp2p_stream(bidi: libp2p_webtransport_websys::bindings::WebTransportBidirectionalStream) -> Result<libp2p_webtransport_websys::Stream, libp2p_webtransport_websys::Error> {\n    let stream = libp2p_webtransport_websys::Stream::new(bidi)?;\n    Ok(stream)\n}""}",code_generation
libp2p-webtransport-websys,"{""title"": ""Add a server certificate hash to WebTransportOptions"", ""description"": ""The crate provides `WebTransportOptions` but only a setter for the whole hash list. A helper that creates a `WebTransportHash` from a SHA‑256 digest and appends it to the options makes configuring custom certificates easier."", ""code_context"": ""use js_sys::{Array, Uint8Array};\nuse libp2p_webtransport_websys::bindings::{WebTransportOptions, WebTransportHash};\nuse libp2p_webtransport_websys::Error;\n\npub fn add_server_cert_hash(opts: &mut WebTransportOptions, hash_bytes: &[u8]) -> Result<(), Error> {\n    let digest = Uint8Array::from(hash_bytes);\n    let mut hash = WebTransportHash::new();\n    hash.algorithm(\""sha-256\"").value(&digest);\n\n    let hashes = Array::new();\n    hashes.push(&hash);\n    opts.server_certificate_hashes(&hashes);\n    Ok(())\n}""}","{""code"": ""pub fn add_server_cert_hash(opts: &mut libp2p_webtransport_websys::bindings::WebTransportOptions, hash_bytes: &[u8]) -> Result<(), libp2p_webtransport_websys::Error> {\n    use js_sys::{Array, Uint8Array};\n    use libp2p_webtransport_websys::bindings::WebTransportHash;\n\n    let digest = Uint8Array::from(hash_bytes);\n    let mut hash = WebTransportHash::new();\n    hash.algorithm(\""sha-256\"").value(&digest);\n\n    let hashes = Array::new();\n    hashes.push(&hash);\n    opts.server_certificate_hashes(&hashes);\n    Ok(())\n}""}",code_generation
libp2p-webtransport-websys,"{""title"": ""Read an entire libp2p Stream into a byte vector"", ""description"": ""Utility to consume a `Stream` until EOF, collecting all received bytes. Useful for protocols that send a single message."", ""code_context"": ""use libp2p_webtransport_websys::Stream;\nuse libp2p_webtransport_websys::Error;\nuse futures::AsyncReadExt;\n\npub async fn read_stream_to_vec(stream: &mut Stream) -> Result<Vec<u8>, Error> {\n    let mut buf = Vec::new();\n    let mut tmp = [0u8; 1024];\n    loop {\n        let n = stream.read(&mut tmp).await?;\n        if n == 0 {\n            break;\n        }\n        buf.extend_from_slice(&tmp[..n]);\n    }\n    Ok(buf)\n}""}","{""code"": ""pub async fn read_stream_to_vec(stream: &mut libp2p_webtransport_websys::Stream) -> Result<Vec<u8>, libp2p_webtransport_websys::Error> {\n    use futures::AsyncReadExt;\n    let mut buf = Vec::new();\n    let mut tmp = [0u8; 1024];\n    loop {\n        let n = stream.read(&mut tmp).await?;\n        if n == 0 {\n            break;\n        }\n        buf.extend_from_slice(&tmp[..n]);\n    }\n    Ok(buf)\n}""}",code_generation
libp2p-webtransport-websys,"{""title"": ""Gracefully close a libp2p Stream"", ""description"": ""Ensures that a `Stream` is flushed before being closed, handling any I/O errors."", ""code_context"": ""use libp2p_webtransport_websys::Stream;\nuse libp2p_webtransport_websys::Error;\nuse futures::AsyncWriteExt;\n\npub async fn close_stream(stream: &mut Stream) -> Result<(), Error> {\n    stream.flush().await?;\n    stream.close().await\n}""}","{""code"": ""pub async fn close_stream(stream: &mut libp2p_webtransport_websys::Stream) -> Result<(), libp2p_webtransport_websys::Error> {\n    use futures::AsyncWriteExt;\n    stream.flush().await?;\n    stream.close().await\n}""}",code_generation
libp2p-webrtc-utils,"{""code"": ""impl Fingerprint {\n    pub fn to_sdp_format(self) -> String {\n        self.0.map(|byte| format!(\""{byte:02X}\"")).join(\"":\"")\n    }\n}"", ""code_context"": ""use itertools::Itertools;\n\npub struct Fingerprint(pub [u8; 32]);""}","{""explanation"": ""The `to_sdp_format` method converts the 32‑byte fingerprint into the colon‑separated uppercase hexadecimal representation required by the SDP fingerprint attribute. It maps each byte to a two‑digit hex string and joins them with `:`.""}",code_explanation
libp2p-webrtc-utils,"{""code"": ""pub fn noise_prologue(client_fingerprint: Fingerprint, server_fingerprint: Fingerprint) -> Vec<u8> {\n    let client = client_fingerprint.to_multihash().to_bytes();\n    let server = server_fingerprint.to_multihash().to_bytes();\n    const PREFIX: &[u8] = b\""libp2p-webrtc-noise:\"";\n    let mut out = Vec::with_capacity(PREFIX.len() + client.len() + server.len());\n    out.extend_from_slice(PREFIX);\n    out.extend_from_slice(&client);\n    out.extend_from_slice(&server);\n    out\n}"", ""code_context"": ""use libp2p_core::multihash;\n\npub struct Fingerprint(pub [u8; 32]);\n\nimpl Fingerprint {\n    pub fn to_multihash(self) -> multihash::Multihash<64> {\n        multihash::Multihash::wrap(0x12, &self.0).expect(\""valid length\"")\n    }\n}""}","{""explanation"": ""`noise_prologue` builds the prologue byte sequence used by the Noise handshake. It concatenates a constant prefix with the multihash encodings of the client and server fingerprints, ensuring both parties derive the same handshake context.""}",code_explanation
libp2p-webrtc-utils,"{""code"": ""pub fn render_description(description: &str, addr: SocketAddr, fingerprint: Fingerprint, ufrag: &str) -> String {\n    let mut tt = TinyTemplate::new();\n    tt.add_template(\""description\"", description).unwrap();\n    let context = DescriptionContext {\n        ip_version: if addr.is_ipv4() { IpVersion::IP4 } else { IpVersion::IP6 },\n        target_ip: addr.ip(),\n        target_port: addr.port(),\n        fingerprint_algorithm: fingerprint.algorithm(),\n        fingerprint_value: fingerprint.to_sdp_format(),\n        ufrag: ufrag.to_owned(),\n        pwd: ufrag.to_owned(),\n    };\n    tt.render(\""description\"", &context).unwrap()\n}"", ""code_context"": ""use std::net::{SocketAddr, IpAddr};\nuse tinytemplate::TinyTemplate;\n\npub struct Fingerprint(pub [u8; 32]);\n\nimpl Fingerprint {\n    pub fn algorithm(&self) -> String { \""sha-256\"".to_owned() }\n    pub fn to_sdp_format(self) -> String { self.0.map(|b| format!(\""{b:02X}\"")).join(\"":\"") }\n}\n\nenum IpVersion { IP4, IP6 }\n\nstruct DescriptionContext {\n    ip_version: IpVersion,\n    target_ip: IpAddr,\n    target_port: u16,\n    fingerprint_algorithm: String,\n    fingerprint_value: String,\n    ufrag: String,\n    pwd: String,\n}""}","{""explanation"": ""`render_description` fills an SDP template with concrete values. It selects the IP version, inserts the target IP/port, and embeds the fingerprint and ICE ufrag/pwd, producing the final SDP answer string for the WebRTC handshake.""}",code_explanation
libp2p-webrtc-utils,"{""code"": ""pub fn parse_webrtc_dial_addr(addr: &Multiaddr) -> Option<(SocketAddr, Fingerprint)> {\n    let mut iter = addr.iter();\n    let ip = match iter.next()? {\n        Protocol::Ip4(ip) => IpAddr::from(ip),\n        Protocol::Ip6(ip) => IpAddr::from(ip),\n        _ => return None,\n    };\n    let port = iter.next()?;\n    let webrtc = iter.next()?;\n    let certhash = iter.next()?;\n    let (port, fingerprint) = match (port, webrtc, certhash) {\n        (Protocol::Udp(port), Protocol::WebRTCDirect, Protocol::Certhash(cert_hash)) => {\n            let fingerprint = Fingerprint::try_from_multihash(cert_hash)?;\n            (port, fingerprint)\n        }\n        _ => return None,\n    };\n    match iter.next() {\n        Some(Protocol::P2p(_)) => {}\n        None => {}\n        Some(_) => return None,\n    }\n    Some((SocketAddr::new(ip, port), fingerprint))\n}"", ""code_context"": ""use std::net::{IpAddr, SocketAddr};\nuse libp2p_core::multiaddr::{Multiaddr, Protocol};\n\npub struct Fingerprint(pub [u8; 32]);\n\nimpl Fingerprint {\n    pub fn try_from_multihash(hash: multihash::Multihash<64>) -> Option<Self> {\n        if hash.code() != 0x12 { return None; }\n        let bytes: [u8; 32] = hash.digest().try_into().ok()?;\n        Some(Fingerprint(bytes))\n    }\n}""}","{""explanation"": ""`parse_webrtc_dial_addr` extracts a socket address and a certificate fingerprint from a libp2p multiaddress that encodes a WebRTC direct connection. It validates the protocol sequence (IP, UDP, webrtc‑direct, certhash) and optionally consumes a trailing peer‑id.""}",code_explanation
libp2p-floodsub,"{""title"": ""Check if a peer is subscribed to a given topic"", ""description"": ""As a developer using libp2p-floodsub, I need a helper that determines whether a remote peer is currently subscribed to a specific topic, so I can decide whether to send messages to that peer."", ""code_context"": ""use crate::Behaviour;\nuse libp2p_identity::PeerId;\nuse crate::Topic;""}","{""code"": ""fn is_peer_subscribed(behaviour: &Behaviour, peer_id: &PeerId, topic: &Topic) -> bool {\n    behaviour.connected_peers\n        .get(peer_id)\n        .map_or(false, |topics| topics.iter().any(|t| t.id() == topic.id()))\n}""}",code_generation
libp2p-floodsub,"{""title"": ""Deduplicate incoming Floodsub messages using the internal CuckooFilter"", ""description"": ""When processing a batch of incoming Floodsub messages, I want to filter out duplicates using the behaviour's CuckooFilter, ensuring each message is handled only once."", ""code_context"": ""use crate::Behaviour;\nuse crate::FloodsubMessage;\nuse cuckoofilter::CuckooError;""}","{""code"": ""fn deduplicate_messages(behaviour: &mut Behaviour, messages: Vec<FloodsubMessage>) -> Vec<FloodsubMessage> {\n    let mut unique = Vec::new();\n    for msg in messages {\n        match behaviour.received.test_and_add(&msg) {\n            Ok(true) => unique.push(msg),\n            Ok(false) => {},\n            Err(cuckoofilter::CuckooError::NotEnoughSpace) => {\n                // Filter is full; keep the message to avoid loss.\n                unique.push(msg);\n            }\n            _ => {}\n        }\n    }\n    unique\n}""}",code_generation
libp2p-floodsub,"{""title"": ""Publish a message to multiple topics efficiently"", ""description"": ""I need a utility that publishes the same payload to several topics in a single call, avoiding repetitive loops and reducing boilerplate."", ""code_context"": ""use crate::Behaviour;\nuse crate::Topic;\nuse bytes::Bytes;""}","{""code"": ""fn publish_to_multiple(behaviour: &mut Behaviour, topics: impl IntoIterator<Item = Topic>, data: impl Into<Bytes>) {\n    behaviour.publish_many(topics, data);\n}""}",code_generation
libp2p-floodsub,"{""title"": ""Get a list of topics the local node is subscribed to"", ""description"": ""For diagnostics I want to retrieve all topics that the local Floodsub behaviour is currently subscribed to, so I can display or log them."", ""code_context"": ""use crate::Behaviour;\nuse crate::Topic;""}","{""code"": ""fn get_subscribed_topics(behaviour: &Behaviour) -> &[Topic] {\n    &behaviour.subscribed_topics\n}""}",code_generation
atoi,"{""code"": ""let s = str::from_utf8(black_box(b\""1996\"")).unwrap();"", ""code_context"": ""use std::str;""}","{""next_api_call"": ""s.parse::<u32>().unwrap();""}",api_usage_prediction
atoi,"{""code"": ""let text = n.to_string();"", ""code_context"": ""type N = i32;\npub trait FromRadix10 {\n    fn from_radix_10(_: &[u8]) -> (Self, usize);\n}""}","{""next_api_call"": ""let (actual, len) = N::from_radix_10(text.as_bytes());""}",api_usage_prediction
atoi,"{""code"": ""let text = n.to_string();"", ""code_context"": ""type N = i32;\npub trait FromRadix10Signed {\n    fn from_radix_10_signed(_: &[u8]) -> (Self, usize);\n}""}","{""next_api_call"": ""let (actual, len) = N::from_radix_10_signed(text.as_bytes());""}",api_usage_prediction
libp2p-webtransport-websys,"{""code_before"": ""let mut noise = libp2p_noise::Config::new(keypair)?;\nif !certhashes.is_empty() {\n    noise = noise.with_webtransport_certhashes(certhashes);\n}"", ""code_context"": ""use libp2p_noise::Config;\nuse libp2p_identity::Keypair;\nuse multihash::Multihash;\nuse std::collections::HashSet;\n\nfn build_noise_config(keypair: &Keypair, certhashes: HashSet<Multihash<64>>) -> Result<Config, libp2p_noise::Error> {\n    // placeholder body; the snippets above are intended to be placed here\n    Ok(Config::new(keypair)?)\n}""}","{""code_after"": ""let noise = if certhashes.is_empty() {\n    libp2p_noise::Config::new(keypair)?\n} else {\n    libp2p_noise::Config::new(keypair)?.with_webtransport_certhashes(certhashes)\n};"", ""review_comment"": ""The conditional expression removes the mutable variable and the extra assignment, making the code more concise and expressive while preserving the same logic.""}",code_review
libp2p-webtransport-websys,"{""code_before"": ""let val = ready!(self.writer_ready_promise.maybe_init(|| self.writer.ready()).poll_unpin(cx)).map_err(to_io_error)?;"", ""code_context"": ""use futures::future::FutureExt;\nuse futures::ready;\nuse wasm_bindgen_futures::JsFuture;\nuse web_sys::WritableStreamDefaultWriter;\n\nfn to_io_error(_e: wasm_bindgen::JsValue) -> std::io::Error { std::io::Error::new(std::io::ErrorKind::Other, \""js error\"") }\n\nstruct FusedJsPromise { /* omitted */ }\nimpl FusedJsPromise {\n    fn maybe_init<F>(&mut self, _init: F) -> &mut Self where F: FnOnce() -> wasm_bindgen::JsValue { self }\n    fn is_active(&self) -> bool { false }\n}\n\nstruct StreamInner {\n    writer: WritableStreamDefaultWriter,\n    writer_ready_promise: FusedJsPromise,\n}\n\nimpl StreamInner {\n    fn example_poll(&mut self, cx: &mut std::task::Context<'_>) {\n        let _ = ready!(self.writer_ready_promise.maybe_init(|| self.writer.ready()).poll_unpin(cx)).map_err(to_io_error)?;\n    }\n}""}","{""code_after"": ""let _ = ready!(self.writer_ready_promise.maybe_init(|| self.writer.ready()).poll_unpin(cx)).map_err(to_io_error)?;"", ""review_comment"": ""The result of the `ready!` call is not used, so assigning it to `_` makes the intent explicit and avoids an unused‑variable warning.""}",code_review
libp2p-webtransport-websys,"{""code_before"": ""let data = parse_reader_response(&val)\n    .map_err(to_io_error)?\n    .map(Uint8Array::from);"", ""code_context"": ""use js_sys::Uint8Array;\nuse wasm_bindgen::JsValue;\n\nfn to_io_error(e: JsValue) -> std::io::Error { std::io::Error::new(std::io::ErrorKind::Other, \""js error\"") }\n\nfn parse_reader_response(_resp: &JsValue) -> Result<Option<JsValue>, JsValue> { Ok(None) }\n\nfn example(val: JsValue) -> Result<Option<Uint8Array>, std::io::Error> {\n    let data = parse_reader_response(&val)\n        .map_err(to_io_error)?\n        .map(|v| Uint8Array::from(v));\n    Ok(data)\n}""}","{""code_after"": ""let data = parse_reader_response(&val)\n    .map_err(to_io_error)?\n    .map(|v| Uint8Array::from(v));"", ""review_comment"": ""Using the closure form of `map` makes the conversion step explicit and avoids the confusion caused by passing a type directly to `map`.""}",code_review
integer-encoding,"{""prefix"": ""let varint_value = "", ""suffix"": ""u64::decode_var(&encoded_bytes)?;""}","{""completion"": ""varint::encode_var(varint_value, &mut encoded_bytes)""}",code_completion
libp2p-webrtc-websys,"{""code_before"": ""let ondatachannel_closure = Closure::new(move |ev: RtcDataChannelEvent| {\n    tracing::trace!(\""New data channel\"");\n\n    if let Err(e) = tx_ondatachannel.try_send(ev.channel()) {\n        if e.is_full() {\n            tracing::warn!(\""Remote is opening too many data channels, we can't keep up!\"");\n            return;\n        }\n\n        if e.is_disconnected() {\n            tracing::warn!(\""Receiver is gone, are we shutting down?\"");\n        }\n    }\n});"", ""code_context"": ""use futures::channel::mpsc;\nuse web_sys::RtcDataChannelEvent;\nuse wasm_bindgen::closure::Closure;""}","{""code_after"": ""let ondatachannel_closure = Closure::new(move |ev: RtcDataChannelEvent| {\n    tracing::trace!(\""New data channel\"");\n\n    match tx_ondatachannel.try_send(ev.channel()) {\n        Ok(_) => {}\n        Err(mpsc::TrySendError::Full(_)) => {\n            tracing::warn!(\""Remote is opening too many data channels, we can't keep up!\"");\n        }\n        Err(mpsc::TrySendError::Closed(_)) => {\n            tracing::warn!(\""Receiver is gone, are we shutting down?\"");\n        }\n    }\n});"", ""review_comment"": ""Using a `match` on `try_send` makes the error handling explicit and avoids checking the same error twice. It also distinguishes the `Full` and `Closed` cases clearly, improving readability and robustness.""}",code_review
libp2p-webrtc-websys,"{""code_before"": ""match self.ready_state() {\n    RtcDataChannelState::Connecting => {\n        self.open_waker.register(cx.waker());\n        return Poll::Pending;\n    }\n    RtcDataChannelState::Closing | RtcDataChannelState::Closed => {\n        return Poll::Ready(Err(io::ErrorKind::BrokenPipe.into()))\n    }\n    RtcDataChannelState::Open | RtcDataChannelState::__Invalid => {}\n    _ => {}\n}"", ""code_context"": ""use web_sys::RtcDataChannelState;\nuse std::io;\nuse std::task::{Context, Poll};""}","{""code_after"": ""match self.ready_state() {\n    RtcDataChannelState::Connecting => {\n        self.open_waker.register(cx.waker());\n        return Poll::Pending;\n    }\n    RtcDataChannelState::Closing | RtcDataChannelState::Closed => {\n        return Poll::Ready(Err(io::ErrorKind::BrokenPipe.into()));\n    }\n    RtcDataChannelState::Open => {}\n}"", ""review_comment"": ""The `__Invalid` and wildcard arms are unnecessary because all possible variants are already covered. Removing them simplifies the match and makes the intent clearer.""}",code_review
libp2p-webrtc-websys,"{""code_before"": ""fn maybe_local_firefox() -> bool {\n    let window = &web_sys::window().expect(\""window should be available\"");\n    let ua = match window.navigator().user_agent() {\n        Ok(agent) => agent.to_lowercase(),\n        Err(_) => return false,\n    };\n\n    let hostname = match window\n        .document()\n        .expect(\""should be valid document\"")\n        .location()\n    {\n        Some(location) => match location.hostname() {\n            Ok(hostname) => hostname,\n            Err(_) => return false,\n        },\n        None => return false,\n    };\n\n    // check if web_sys::Navigator::user_agent() matches any of the following:\n    // - firefox\n    // - seamonkey\n    // - iceape\n    // AND hostname is either localhost or  \""127.0.0.1\""\n    (ua.contains(\""firefox\"") || ua.contains(\""seamonkey\"") || ua.contains(\""iceape\""))\n        && (hostname == \""localhost\"" || hostname == \""127.0.0.1\"" || hostname == \""[::1]\"")\n}"", ""code_context"": ""use web_sys;""}","{""code_after"": ""fn maybe_local_firefox() -> bool {\n    let window = match web_sys::window() {\n        Some(w) => w,\n        None => return false,\n    };\n\n    let ua = window\n        .navigator()\n        .user_agent()\n        .map(|s| s.to_lowercase())\n        .unwrap_or_default();\n\n    let hostname = window\n        .document()\n        .and_then(|doc| doc.location())\n        .and_then(|loc| loc.hostname().ok())\n        .unwrap_or_default();\n\n    (ua.contains(\""firefox\"") || ua.contains(\""seamonkey\"") || ua.contains(\""iceape\""))\n        && (hostname == \""localhost\"" || hostname == \""127.0.0.1\"" || hostname == \""[::1]\"")\n}"", ""review_comment"": ""The rewritten version uses combinators (`map`, `and_then`, `unwrap_or_default`) to avoid deep nesting and early returns, resulting in clearer and more idiomatic Rust code.""}",code_review
libp2p-webtransport-websys,"{""code_before"": ""pub async fn authenticate(&mut self, keypair: &Keypair, remote_peer: Option<PeerId>, certhashes: HashSet<Multihash<64>>) -> Result<PeerId, Error> {\n    JsFuture::from(self.session.ready())\n        .await\n        .map_err(Error::from_js_value)?;\n\n    let stream = poll_fn(|cx| self.poll_create_bidirectional_stream(cx)).await?;\n    let mut noise = libp2p_noise::Config::new(keypair)?;\n\n    if !certhashes.is_empty() {\n        noise = noise.with_webtransport_certhashes(certhashes);\n    }\n\n    // We do not use `upgrade::apply_outbound` function because it uses\n    // `multistream_select` protocol, which is not used by WebTransport spec.\n    let info = noise.protocol_info().next().unwrap_or_default();\n    let (peer_id, _io) = noise.upgrade_outbound(stream, info).await?;\n\n    // TODO: This should be part libp2p-noise\n    if let Some(expected_peer_id) = remote_peer {\n        if peer_id != expected_peer_id {\n            return Err(Error::UnknownRemotePeerId);\n        }\n    }\n\n    Ok(peer_id)\n}"", ""code_context"": ""use std::collections::HashSet;\nuse std::future::poll_fn;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\n\nuse futures::FutureExt;\nuse libp2p_core::upgrade::OutboundConnectionUpgrade;\nuse libp2p_identity::{Keypair, PeerId};\nuse multihash::Multihash;\nuse send_wrapper::SendWrapper;\nuse wasm_bindgen_futures::JsFuture;\nuse web_sys::ReadableStreamDefaultReader;\n\nuse crate::bindings::{WebTransport, WebTransportBidirectionalStream};\nuse crate::error::Error;\nuse crate::stream::Stream;\nuse crate::utils::to_js_type;\n\npub struct Connection {\n    inner: SendWrapper<ConnectionInner>,\n}\n\nstruct ConnectionInner {\n    session: WebTransport,\n    // other fields omitted for brevity\n}\n\nimpl ConnectionInner {\n    async fn poll_create_bidirectional_stream(&mut self, cx: &mut Context<'_>) -> Result<Stream, Error> {\n        // original implementation omitted\n        unimplemented!()\n    }\n}""}","{""rationale"": ""Replaces the `poll_fn` wrapper with a direct `JsFuture` on `create_bidirectional_stream`, removing an unnecessary abstraction and making the async flow clearer and more idiomatic."", ""code_after"": ""pub async fn authenticate(&mut self, keypair: &Keypair, remote_peer: Option<PeerId>, certhashes: HashSet<Multihash<64>>) -> Result<PeerId, Error> {\n    JsFuture::from(self.session.ready())\n        .await\n        .map_err(Error::from_js_value)?;\n\n    // Directly await the JavaScript promise instead of using `poll_fn`.\n    let stream_js = JsFuture::from(self.session.create_bidirectional_stream())\n        .await\n        .map_err(Error::from_js_value)?;\n    let bidi_stream = to_js_type::<WebTransportBidirectionalStream>(stream_js)?;\n    let stream = Stream::new(bidi_stream)?;\n\n    let mut noise = libp2p_noise::Config::new(keypair)?;\n    if !certhashes.is_empty() {\n        noise = noise.with_webtransport_certhashes(certhashes);\n    }\n\n    let info = noise.protocol_info().next().unwrap_or_default();\n    let (peer_id, _io) = noise.upgrade_outbound(stream, info).await?;\n\n    if let Some(expected_peer_id) = remote_peer {\n        if peer_id != expected_peer_id {\n            return Err(Error::UnknownRemotePeerId);\n        }\n    }\n\n    Ok(peer_id)\n}""}",code_refactoring
libp2p-webtransport-websys,"{""code_before"": ""let val = ready!(self.reader_read_promise.maybe_init(|| self.reader.read()).poll_unpin(cx)).map_err(to_io_error)?;\n        let val = parse_reader_response(&val)\n            .map_err(to_io_error)?\n            .map(Uint8Array::from);"", ""code_context"": ""use std::task::{ready, Context, Poll};\nuse futures::future::FutureExt;\nuse js_sys::Uint8Array;\nuse web_sys::ReadableStreamDefaultReader;\n\nuse crate::utils::{parse_reader_response, to_io_error};\nuse crate::fused_js_promise::FusedJsPromise;\n\npub struct StreamInner {\n    reader: ReadableStreamDefaultReader,\n    reader_read_promise: FusedJsPromise,\n    read_leftovers: Option<Uint8Array>,\n}\n\nimpl StreamInner {\n    fn poll_reader_read(&mut self, cx: &mut Context) -> Poll<std::io::Result<Option<Uint8Array>>> {\n        // implementation omitted\n        unimplemented!()\n    }\n}""}","{""rationale"": ""Splits the parsing and conversion into two distinct statements, improving readability by making each transformation step explicit."", ""code_after"": ""let val = ready!(self.reader_read_promise.maybe_init(|| self.reader.read()).poll_unpin(cx)).map_err(to_io_error)?;\n        let val = parse_reader_response(&val).map_err(to_io_error)?;\n        let val = val.map(Uint8Array::from);""}",code_refactoring
libp2p-webtransport-websys,"{""code_before"": ""let data = match self.read_leftovers.take() {\n            Some(data) => data,\n            None => {\n                match ready!(self.poll_reader_read(cx))? {\n                    Some(data) => data,\n                    // EOF\n                    None => return Poll::Ready(Ok(0)),\n                }\n            }\n        };\n        if data.byte_length() == 0 {\n            return Poll::Ready(Ok(0));\n        }"", ""code_context"": ""use std::task::{ready, Context, Poll};\nuse futures::future::FutureExt;\nuse js_sys::Uint8Array;\nuse web_sys::ReadableStreamDefaultReader;\n\nuse crate::utils::{parse_reader_response, to_io_error};\nuse crate::fused_js_promise::FusedJsPromise;\n\npub struct StreamInner {\n    reader: ReadableStreamDefaultReader,\n    reader_read_promise: FusedJsPromise,\n    read_leftovers: Option<Uint8Array>,\n}\n\nimpl StreamInner {\n    fn poll_reader_read(&mut self, cx: &mut Context) -> Poll<std::io::Result<Option<Uint8Array>>> {\n        // implementation omitted\n        unimplemented!()\n    }\n\n    fn poll_read(&mut self, cx: &mut Context<'_>, buf: &mut [u8]) -> Poll<std::io::Result<usize>> {\n        // original snippet omitted\n        unimplemented!()\n    }\n}""}","{""rationale"": ""Uses `unwrap_or_else` to collapse the nested `match` into a single expression, reducing boilerplate and making the control flow clearer."", ""code_after"": ""let data = self.read_leftovers.take().unwrap_or_else(|| {\n            ready!(self.poll_reader_read(cx))?.and_then(|d| Some(d))\n        });\n        if data.byte_length() == 0 {\n            return Poll::Ready(Ok(0));\n        }""}",code_refactoring
lz4-sys,"{""code"": ""pub fn __placeholder__(code: usize) -> bool { unsafe { LZ4F_isError(code) != 0 } }"", ""code_context"": ""use lz4_sys::{size_t, c_uint};\nextern \""C\"" { pub fn LZ4F_isError(code: size_t) -> c_uint; }""}","{""function_name"": ""is_error""}",function_naming
lz4-sys,"{""code"": ""pub fn __placeholder__(code: usize) -> String { unsafe { let ptr = LZ4F_getErrorName(code); if ptr.is_null() { String::new() } else { std::ffi::CStr::from_ptr(ptr).to_string_lossy().into_owned() } } }"", ""code_context"": ""use lz4_sys::{size_t, c_char};\nuse std::ffi::CStr;\nextern \""C\"" { pub fn LZ4F_getErrorName(code: size_t) -> *const c_char; }""}","{""function_name"": ""error_name""}",function_naming
lz4-sys,"{""code"": ""pub fn __placeholder__(ctx: LZ4FDecompressionContext) { unsafe { LZ4F_resetDecompressionContext(ctx); } }"", ""code_context"": ""use lz4_sys::LZ4FDecompressionContext;\nextern \""C\"" { pub fn LZ4F_resetDecompressionContext(ctx: LZ4FDecompressionContext); }""}","{""function_name"": ""reset_decompression_context""}",function_naming
lz4-sys,"{""code"": ""pub fn __placeholder__() -> i32 { unsafe { LZ4_versionNumber() } }"", ""code_context"": ""use lz4_sys::LZ4_versionNumber;""}","{""function_name"": ""version_number""}",function_naming
lz4-sys,"{""code"": ""pub fn __placeholder__(size: usize) -> Result<usize, &'static str> { let bound = unsafe { LZ4_compressBound(size as i32) }; if bound <= 0 { Err(\""size too large\"") } else { Ok(bound as usize) } }"", ""code_context"": ""use lz4_sys::LZ4_compressBound;""}","{""function_name"": ""compress_bound""}",function_naming
libp2p-webtransport-websys,"{""code_context"": ""use std::collections::HashSet;\nuse js_sys::{Array, Uint8Array};\nuse libp2p_identity::PeerId;\nuse multiaddr::{Multiaddr, Protocol};\nuse multihash::Multihash;\nuse crate::bindings::{WebTransportHash, WebTransportOptions};\n\npub struct Endpoint {\n    pub host: String,\n    pub port: u16,\n    pub is_ipv6: bool,\n    pub certhashes: HashSet<Multihash<64>>,\n    pub remote_peer: Option<PeerId>,\n}"", ""code_to_test"": ""impl Endpoint {\n    pub fn from_multiaddr(addr: &Multiaddr) -> Result<Self, Error> {\n        let mut host = None;\n        let mut port = None;\n        let mut found_quic = false;\n        let mut found_webtransport = false;\n        let mut certhashes = HashSet::new();\n        let mut remote_peer = None;\n        let mut is_ipv6 = false;\n\n        for proto in addr.iter() {\n            match proto {\n                Protocol::Ip4(a) => {\n                    if host.is_some() {\n                        return Err(Error::InvalidMultiaddr(\""More than one host definitions\""));\n                    }\n                    host = Some(a.to_string());\n                }\n                Protocol::Ip6(a) => {\n                    if host.is_some() {\n                        return Err(Error::InvalidMultiaddr(\""More than one host definitions\""));\n                    }\n                    is_ipv6 = true;\n                    host = Some(a.to_string());\n                }\n                Protocol::Dns(d) | Protocol::Dns4(d) | Protocol::Dns6(d) => {\n                    if port.is_some() {\n                        return Err(Error::InvalidMultiaddr(\""More than one host definitions\""));\n                    }\n                    host = Some(d.to_string());\n                }\n                Protocol::Dnsaddr(_) => {\n                    return Err(Error::InvalidMultiaddr(\""/dnsaddr not supported from within a browser\""));\n                }\n                Protocol::Udp(p) => {\n                    if port.is_some() {\n                        return Err(Error::InvalidMultiaddr(\""More than one port definitions\""));\n                    }\n                    port = Some(p);\n                }\n                Protocol::Quic | Protocol::QuicV1 => {\n                    if host.is_none() || port.is_none() {\n                        return Err(Error::InvalidMultiaddr(\""No host and port definition before /quic/webtransport\""));\n                    }\n                    found_quic = true;\n                }\n                Protocol::WebTransport => {\n                    if !found_quic {\n                        return Err(Error::InvalidMultiaddr(\""/quic is not found before /webtransport\""));\n                    }\n                    found_webtransport = true;\n                }\n                Protocol::Certhash(hash) => {\n                    if !found_webtransport {\n                        return Err(Error::InvalidMultiaddr(\""/certhashes must be after /quic/found_webtransport\""));\n                    }\n                    certhashes.insert(hash);\n                }\n                Protocol::P2p(peer) => {\n                    if remote_peer.is_some() {\n                        return Err(Error::InvalidMultiaddr(\""More than one peer definitions\""));\n                    }\n                    remote_peer = Some(peer);\n                }\n                _ => {}\n            }\n        }\n\n        if !found_quic || !found_webtransport {\n            return Err(Error::InvalidMultiaddr(\""Not a /quic/webtransport multiaddr\""));\n        }\n\n        let host = host.ok_or_else(|| Error::InvalidMultiaddr(\""Host is not defined\""))?;\n        let port = port.ok_or_else(|| Error::InvalidMultiaddr(\""Port is not defined\""))?;\n\n        Ok(Endpoint {\n            host,\n            port,\n            is_ipv6,\n            certhashes,\n            remote_peer,\n        })\n    }\n\n    pub fn url(&self) -> String {\n        if self.is_ipv6 {\n            format!(\""https://[{}]:{}/.well-known/libp2p-webtransport?type=noise\"", self.host, self.port)\n        } else {\n            format!(\""https://{}:{}/.well-known/libp2p-webtransport?type=noise\"", self.host, self.port)\n        }\n    }\n\n    pub fn webtransport_opts(&self) -> WebTransportOptions {\n        let mut opts = WebTransportOptions::new();\n        let hashes = Array::new();\n        for hash in &self.certhashes {\n            let digest = Uint8Array::from(hash.digest());\n            let mut jshash = WebTransportHash::new();\n            jshash.algorithm(\""sha-256\"").value(&digest);\n            hashes.push(&jshash);\n        }\n        opts.server_certificate_hashes(&hashes);\n        opts\n    }\n}"", ""test_context"": ""use std::str::FromStr;\nuse crate::endpoint::Endpoint;\nuse crate::error::Error;\nuse multihash::Multihash;\nuse multibase;\nuse libp2p_identity::PeerId;\n\nfn multihash_from_str(s: &str) -> Multihash<64> {\n    let (_base, bytes) = multibase::decode(s).unwrap();\n    Multihash::from_bytes(&bytes).unwrap()\n}""}","{""test_cases"": [""#[test]\nfn valid_webtransport_multiaddr() {\n    let addr = Multiaddr::from_str(\""/ip4/127.0.0.1/udp/44874/quic-v1/webtransport/certhash/uEiCaDd1Ca1A8IVJ3hsIxIyi11cwxaDKqzVrBkGJbKZU5ng/certhash/uEiDv-VGW8oXxui_G_Kqp-87YjvET-Hr2qYAMYPePJDcsjQ/p2p/12D3KooWR7EfNv5SLtgjMRjUwR8AvNu3hP4fLrtSa9fmHHXKYWNG\"").unwrap();\n    let endpoint = Endpoint::from_multiaddr(&addr).unwrap();\n\n    assert_eq!(endpoint.host, \""127.0.0.1\"");\n    assert_eq!(endpoint.port, 44874);\n    assert_eq!(endpoint.certhashes.len(), 2);\n\n    assert!(endpoint.certhashes.contains(&multihash_from_str(\n        \""uEiCaDd1Ca1A8IVJ3hsIxIyi11cwxaDKqzVrBkGJbKZU5ng\""\n    )));\n\n    assert!(endpoint.certhashes.contains(&multihash_from_str(\n        \""uEiDv-VGW8oXxui_G_Kqp-87YjvET-Hr2qYAMYPePJDcsjQ\""\n    )));\n\n    assert_eq!(\n        endpoint.remote_peer.unwrap(),\n        PeerId::from_str(\""12D3KooWR7EfNv5SLtgjMRjUwR8AvNu3hP4fLrtSa9fmHHXKYWNG\"").unwrap()\n    );\n\n    assert_eq!(\n        endpoint.url(),\n        \""https://127.0.0.1:44874/.well-known/libp2p-webtransport?type=noise\""\n    );\n}"", ""#[test]\nfn valid_webtransport_multiaddr_without_certhashes() {\n    let addr = Multiaddr::from_str(\""/ip4/127.0.0.1/udp/44874/quic-v1/webtransport/p2p/12D3KooWR7EfNv5SLtgjMRjUwR8AvNu3hP4fLrtSa9fmHHXKYWNG\"").unwrap();\n    let endpoint = Endpoint::from_multiaddr(&addr).unwrap();\n\n    assert_eq!(endpoint.host, \""127.0.0.1\"");\n    assert_eq!(endpoint.port, 44874);\n    assert_eq!(endpoint.certhashes.len(), 0);\n    assert_eq!(\n        endpoint.remote_peer.unwrap(),\n        PeerId::from_str(\""12D3KooWR7EfNv5SLtgjMRjUwR8AvNu3hP4fLrtSa9fmHHXKYWNG\"").unwrap()\n    );\n}"", ""#[test]\nfn ipv6_webtransport() {\n    let addr = Multiaddr::from_str(\""/ip6/::1/udp/44874/quic-v1/webtransport/certhash/uEiCaDd1Ca1A8IVJ3hsIxIyi11cwxaDKqzVrBkGJbKZU5ng/certhash/uEiDv-VGW8oXxui_G_Kqp-87YjvET-Hr2qYAMYPePJDcsjQ/p2p/12D3KooWR7EfNv5SLtgjMRjUwR8AvNu3hP4fLrtSa9fmHHXKYWNG\"").unwrap();\n    let endpoint = Endpoint::from_multiaddr(&addr).unwrap();\n\n    assert_eq!(endpoint.host, \""::1\"");\n    assert_eq!(endpoint.port, 44874);\n    assert_eq!(\n        endpoint.url(),\n        \""https://[::1]:44874/.well-known/libp2p-webtransport?type=noise\""\n    );\n}"", ""#[test]\nfn dns_webtransport() {\n    let addr = Multiaddr::from_str(\""/dns/libp2p.io/udp/44874/quic-v1/webtransport/certhash/uEiCaDd1Ca1A8IVJ3hsIxIyi11cwxaDKqzVrBkGJbKZU5ng/certhash/uEiDv-VGW8oXxui_G_Kqp-87YjvET-Hr2qYAMYPePJDcsjQ/p2p/12D3KooWR7EfNv5SLtgjMRjUwR8AvNu3hP4fLrtSa9fmHHXKYWNG\"").unwrap();\n    let endpoint = Endpoint::from_multiaddr(&addr).unwrap();\n\n    assert_eq!(endpoint.host, \""libp2p.io\"");\n    assert_eq!(endpoint.port, 44874);\n    assert_eq!(\n        endpoint.url(),\n        \""https://libp2p.io:44874/.well-known/libp2p-webtransport?type=noise\""\n    );\n}""]}",test_generation
libp2p-webtransport-websys,"{""code_context"": ""use std::collections::HashSet;\nuse libp2p_identity::PeerId;\nuse multihash::Multihash;\n\npub struct Endpoint {\n    pub host: String,\n    pub port: u16,\n    pub is_ipv6: bool,\n    pub certhashes: HashSet<Multihash<64>>,\n    pub remote_peer: Option<PeerId>,\n}"", ""code_to_test"": ""impl Endpoint {\n    pub fn url(&self) -> String {\n        if self.is_ipv6 {\n            format!(\""https://[{}]:{}/.well-known/libp2p-webtransport?type=noise\"", self.host, self.port)\n        } else {\n            format!(\""https://{}:{}/.well-known/libp2p-webtransport?type=noise\"", self.host, self.port)\n        }\n    }\n}"", ""test_context"": ""use std::collections::HashSet;\nuse crate::endpoint::Endpoint;""}","{""test_cases"": [""#[test]\nfn url_ipv4() {\n    let endpoint = Endpoint {\n        host: \""example.com\"".to_string(),\n        port: 443,\n        is_ipv6: false,\n        certhashes: HashSet::new(),\n        remote_peer: None,\n    };\n    assert_eq!(endpoint.url(), \""https://example.com:443/.well-known/libp2p-webtransport?type=noise\"");\n}"", ""#[test]\nfn url_ipv6() {\n    let endpoint = Endpoint {\n        host: \""::1\"".to_string(),\n        port: 443,\n        is_ipv6: true,\n        certhashes: HashSet::new(),\n        remote_peer: None,\n    };\n    assert_eq!(endpoint.url(), \""https://[::1]:443/.well-known/libp2p-webtransport?type=noise\"");\n}"", ""#[test]\nfn url_dns() {\n    let endpoint = Endpoint {\n        host: \""libp2p.io\"".to_string(),\n        port: 443,\n        is_ipv6: false,\n        certhashes: HashSet::new(),\n        remote_peer: None,\n    };\n    assert_eq!(endpoint.url(), \""https://libp2p.io:443/.well-known/libp2p-webtransport?type=noise\"");\n}""]}",test_generation
libp2p-webtransport-websys,"{""code_context"": ""use std::collections::HashSet;\nuse js_sys::{Array, Uint8Array};\nuse libp2p_identity::PeerId;\nuse multihash::Multihash;\nuse crate::bindings::{WebTransportHash, WebTransportOptions};\n\npub struct Endpoint {\n    pub host: String,\n    pub port: u16,\n    pub is_ipv6: bool,\n    pub certhashes: HashSet<Multihash<64>>,\n    pub remote_peer: Option<PeerId>,\n}"", ""code_to_test"": ""impl Endpoint {\n    pub fn webtransport_opts(&self) -> WebTransportOptions {\n        let mut opts = WebTransportOptions::new();\n        let hashes = Array::new();\n        for hash in &self.certhashes {\n            let digest = Uint8Array::from(hash.digest());\n            let mut jshash = WebTransportHash::new();\n            jshash.algorithm(\""sha-256\"").value(&digest);\n            hashes.push(&jshash);\n        }\n        opts.server_certificate_hashes(&hashes);\n        opts\n    }\n}"", ""test_context"": ""use std::collections::HashSet;\nuse crate::endpoint::Endpoint;""}","{""test_cases"": [""#[test]\nfn webtransport_opts_returns_options() {\n    let endpoint = Endpoint {\n        host: \""example.com\"".to_string(),\n        port: 443,\n        is_ipv6: false,\n        certhashes: HashSet::new(),\n        remote_peer: None,\n    };\n    let opts = endpoint.webtransport_opts();\n    // Just ensure the function compiles and returns a value.\n    let _ = opts;\n}""]}",test_generation
float-cmp,"{""buggy_code"": ""let a: f32 = -0.0_f32;\nlet b: f32 = 0.0_f32;\n// The expectation is that with a zero ulps margin the values are *not* equal,\n// because -0.0 and +0.0 are far apart in ulp space according to the comment.\nassert!(!a.approx_eq_ulps(&b, 0));"", ""code_context"": ""impl ApproxEqUlps for f32 {\n    type Flt = f32;\n\n    fn approx_eq_ulps(&self, other: &f32, ulps: i32) -> bool {\n        // -0 and +0 are drastically far in ulps terms, so we need a special case for that.\n        if *self == *other {\n            return true;\n        }\n        if self.is_sign_positive() != other.is_sign_positive() {\n            return false;\n        }\n        let diff: i32 = self.ulps(other);\n        diff >= -ulps && diff <= ulps\n    }\n}""}","{""fixed_code"": ""let a: f32 = -0.0_f32;\nlet b: f32 = 0.0_f32;\n// Compare the raw bit patterns first; only if they are exactly the same do we\n// consider the values equal. This respects the comment that -0.0 and +0.0 are\n// far apart in ulp distance.\nlet eq = a.to_bits() == b.to_bits() && a.approx_eq_ulps(&b, 0);\nassert!(!eq);"", ""bug_description"": ""The `approx_eq_ulps` implementation for `f32` returns `true` for `-0.0` and `0.0` because it checks `*self == *other` before any ulp logic. The comment in the source says \""-0 and +0 are drastically far in ulps terms, so we need a special case for that,\"" but the early equality shortcut bypasses that case, causing a false positive when the ulps margin is zero.""}",bug_detection
float-cmp,"{""buggy_code"": ""let a: f64 = -0.0_f64;\nlet b: f64 = 0.0_f64;\n// Expect inequality with a zero ulps margin, but the current implementation\n// incorrectly returns true.\nassert!(!a.approx_eq_ulps(&b, 0));"", ""code_context"": ""impl ApproxEqUlps for f64 {\n    type Flt = f64;\n\n    fn approx_eq_ulps(&self, other: &f64, ulps: i64) -> bool {\n        // -0 and +0 are drastically far in ulps terms, so we need a special case for that.\n        if *self == *other {\n            return true;\n        }\n        if self.is_sign_positive() != other.is_sign_positive() {\n            return false;\n        }\n        let diff: i64 = self.ulps(other);\n        diff >= -ulps && diff <= ulps\n    }\n}""}","{""fixed_code"": ""let a: f64 = -0.0_f64;\nlet b: f64 = 0.0_f64;\n// Ensure the raw bit patterns match before accepting equality.\nlet eq = a.to_bits() == b.to_bits() && a.approx_eq_ulps(&b, 0);\nassert!(!eq);"", ""bug_description"": ""The `approx_eq_ulps` implementation for `f64` suffers from the same early‑equality shortcut as the `f32` version. It treats `-0.0` and `+0.0` as equal, contradicting the comment that they should be considered far apart in ulp distance. This leads to incorrect equality results when the ulps margin is zero.""}",bug_detection
float-cmp,"{""buggy_code"": ""impl ApproxEqUlps for f32 {\n    type Flt = f32;\n\n    fn approx_eq_ulps(&self, other: &f32, ulps: i32) -> bool {\n        // -0 and +0 are drastically far in ulps terms, so we need a special case for that.\n        if *self == *other {\n            return true; // <-- incorrect for -0.0 vs +0.0\n        }\n        if self.is_sign_positive() != other.is_sign_positive() {\n            return false;\n        }\n        let diff: i32 = self.ulps(other);\n        diff >= -ulps && diff <= ulps\n    }\n}"", ""code_context"": null}","{""fixed_code"": ""impl ApproxEqUlps for f32 {\n    type Flt = f32;\n\n    fn approx_eq_ulps(&self, other: &f32, ulps: i32) -> bool {\n        // -0 and +0 are drastically far in ulps terms, so we need a special case for that.\n        // Equality should only be accepted when the bit patterns match exactly.\n        if self.to_bits() == other.to_bits() {\n            return true;\n        }\n        // Different signs are always unequal.\n        if self.is_sign_positive() != other.is_sign_positive() {\n            return false;\n        }\n        let diff: i32 = self.ulps(other);\n        diff >= -ulps && diff <= ulps\n    }\n}"", ""bug_description"": ""The early equality check `if *self == *other { return true; }` treats `-0.0` and `+0.0` as equal because `-0.0 == +0.0` in Rust. The comment explicitly states that they are \""drastically far in ulps terms\"" and should not be considered equal when the ulps margin is zero. The fix replaces the equality test with a raw‑bit comparison (`self.to_bits() == other.to_bits()`) so that sign differences are respected.""}",bug_detection
lz4-sys,"{""code"": ""pub fn compress(src: &[u8], mode: Option<CompressionMode>, prepend_size: bool) -> Result<Vec<u8>> {\n    let compress_bound: i32 = unsafe { LZ4_compressBound(src.len() as i32) };\n    if src.len() > (i32::max_value() as usize) || compress_bound <= 0 {\n        return Err(Error::new(ErrorKind::InvalidInput, \""Compression input too long.\""));\n    }\n    let mut compressed: Vec<u8> = vec![0; (if prepend_size { compress_bound + 4 } else { compress_bound }) as usize];\n    let dec_size = compress_to_buffer(src, mode, prepend_size, &mut compressed)?;\n    compressed.truncate(dec_size as usize);\n    Ok(compressed)\n}"", ""code_context"": ""use std::io::{Error, ErrorKind, Result};\nuse lz4_sys::*;\n\n#[derive(Clone, Copy, Debug)]\npub enum CompressionMode {\n    HIGHCOMPRESSION(i32),\n    FAST(i32),\n    DEFAULT,\n}\n\nimpl Default for CompressionMode {\n    fn default() -> Self { CompressionMode::DEFAULT }\n}\n\npub fn compress_bound(uncompressed_size: usize) -> Result<usize> {\n    let compress_bound: i32 = unsafe { LZ4_compressBound(uncompressed_size as i32) };\n    if uncompressed_size > (i32::max_value() as usize) || compress_bound <= 0 {\n        return Err(Error::new(ErrorKind::InvalidInput, \""Compression input too long.\""));\n    }\n    Ok(compress_bound as usize)\n}\n\npub fn compress_to_buffer(src: &[u8], mode: Option<CompressionMode>, prepend_size: bool, buffer: &mut [u8]) -> Result<usize> {\n    let max_len: i32 = unsafe { LZ4_compressBound(src.len() as i32) };\n    if src.len() > (i32::max_value() as usize) || max_len <= 0 {\n        return Err(Error::new(ErrorKind::InvalidInput, \""Compression input too long.\""));\n    }\n    let dec_size;\n    {\n        let dst_buf = if prepend_size {\n            let size = src.len() as u32;\n            buffer[0] = size as u8;\n            buffer[1] = (size >> 8) as u8;\n            buffer[2] = (size >> 16) as u8;\n            buffer[3] = (size >> 24) as u8;\n            &mut buffer[4..]\n        } else {\n            buffer\n        };\n        let buf_len = dst_buf.len() as i32;\n        dec_size = match mode {\n            Some(CompressionMode::HIGHCOMPRESSION(level)) => unsafe {\n                LZ4_compress_HC(src.as_ptr() as *const c_char, dst_buf.as_mut_ptr() as *mut c_char, src.len() as i32, buf_len, level)\n            },\n            Some(CompressionMode::FAST(accel)) => unsafe {\n                LZ4_compress_fast(src.as_ptr() as *const c_char, dst_buf.as_mut_ptr() as *mut c_char, src.len() as i32, buf_len, accel)\n            },\n            _ => unsafe {\n                LZ4_compress_default(src.as_ptr() as *const c_char, dst_buf.as_mut_ptr() as *mut c_char, src.len() as i32, buf_len)\n            },\n        };\n    }\n    if dec_size <= 0 {\n        return Err(Error::new(ErrorKind::Other, \""Compression failed\""));\n    }\n    let written_size = if prepend_size { dec_size + 4 } else { dec_size };\n    Ok(written_size as usize)\n}""}","{""summary"": ""Compresses a byte slice using the specified compression mode and optional size prefix.""}",code_summarization
lz4-sys,"{""code"": ""pub fn decompress(src: &[u8], uncompressed_size: Option<i32>) -> Result<Vec<u8>> {\n    let size = get_decompressed_size(src, uncompressed_size)?;\n    let mut buffer = vec![0u8; size];\n    let sz = decompress_to_buffer(src, uncompressed_size, &mut buffer)?;\n    buffer.truncate(sz);\n    Ok(buffer)\n}"", ""code_context"": ""use std::io::{Error, ErrorKind, Result};\nuse lz4_sys::*;\n\nfn get_decompressed_size(src: &[u8], uncompressed_size: Option<i32>) -> Result<usize> {\n    let size;\n    if let Some(s) = uncompressed_size {\n        size = s;\n    } else {\n        if src.len() < 4 {\n            return Err(Error::new(ErrorKind::InvalidInput, \""Source buffer must at least contain size prefix.\""));\n        }\n        size = (src[0] as i32) | (src[1] as i32) << 8 | (src[2] as i32) << 16 | (src[3] as i32) << 24;\n    }\n    if size < 0 {\n        return Err(Error::new(ErrorKind::InvalidInput, \""Parsed size prefix in buffer must not be negative.\""));\n    }\n    if unsafe { LZ4_compressBound(size) } <= 0 {\n        return Err(Error::new(ErrorKind::InvalidInput, \""Given size parameter is too big\""));\n    }\n    Ok(size as usize)\n}\n\npub fn decompress_to_buffer(src: &[u8], uncompressed_size: Option<i32>, buffer: &mut [u8]) -> Result<usize> {\n    let size;\n    let mut src_slice = src;\n    if let Some(s) = uncompressed_size {\n        size = s;\n    } else {\n        if src_slice.len() < 4 {\n            return Err(Error::new(ErrorKind::InvalidInput, \""Source buffer must at least contain size prefix.\""));\n        }\n        size = (src_slice[0] as i32) | (src_slice[1] as i32) << 8 | (src_slice[2] as i32) << 16 | (src_slice[3] as i32) << 24;\n        src_slice = &src_slice[4..];\n    }\n    if size < 0 {\n        return Err(Error::new(ErrorKind::InvalidInput, \""Parsed size prefix in buffer must not be negative.\""));\n    }\n    if unsafe { LZ4_compressBound(size) } <= 0 {\n        return Err(Error::new(ErrorKind::InvalidInput, \""Given size parameter is too big\""));\n    }\n    if size as usize > buffer.len() {\n        return Err(Error::new(ErrorKind::InvalidInput, \""buffer isn't large enough to hold decompressed data\""));\n    }\n    let dec_bytes = unsafe {\n        LZ4_decompress_safe(src_slice.as_ptr() as *const c_char, buffer.as_mut_ptr() as *mut c_char, src_slice.len() as i32, size)\n    };\n    if dec_bytes < 0 {\n        return Err(Error::new(ErrorKind::InvalidData, \""Decompression failed. Input invalid or too long?\""));\n    }\n    Ok(dec_bytes as usize)\n}""}","{""summary"": ""Decompresses a byte slice with an optional size prefix, returning the original data.""}",code_summarization
lz4-sys,"{""code"": ""pub fn check_error(code: LZ4FErrorCode) -> Result<usize, Error> {\n    unsafe {\n        if LZ4F_isError(code) != 0 {\n            let error_name = LZ4F_getErrorName(code);\n            return Err(Error::new(ErrorKind::Other, LZ4Error(str::from_utf8(CStr::from_ptr(error_name).to_bytes()).unwrap().to_string())));\n        }\n    }\n    Ok(code as usize)\n}"", ""code_context"": ""use std::ffi::CStr;\nuse std::io::{Error, ErrorKind};\nuse std::str;\nuse lz4_sys::*;\n\n#[derive(Debug)]\npub struct LZ4Error(String);\n\nimpl std::fmt::Display for LZ4Error {\n    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {\n        write!(f, \""LZ4 error: {}\"", &self.0)\n    }\n}\n\nimpl std::error::Error for LZ4Error {\n    fn description(&self) -> &str { &self.0 }\n    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> { None }\n}""}","{""summary"": ""Checks for LZ4F errors and returns a Rust Error if one occurs.""}",code_summarization
smawk,"{""code"": ""let mut minima = vec![0; matrix.nrows()];"", ""code_context"": ""fn smawk_inner<T: PartialOrd + Copy, M: Fn(usize, usize) -> T>(\n    matrix: &M,\n    rows: &[usize],\n    cols: &[usize],\n    minima: &mut [usize],\n) {\n    if cols.is_empty() {\n        return;\n    }\n\n    let mut stack = Vec::with_capacity(cols.len());\n    for r in rows {\n        while !stack.is_empty()\n            && matrix(stack[stack.len() - 1], cols[stack.len() - 1])\n                > matrix(*r, cols[stack.len() - 1])\n        {\n            stack.pop();\n        }\n        if stack.len() != cols.len() {\n            stack.push(*r);\n        }\n    }\n    let rows = &stack;\n\n    let mut odd_cols = Vec::with_capacity(1 + cols.len() / 2);\n    for (idx, c) in cols.iter().enumerate() {\n        if idx % 2 == 1 {\n            odd_cols.push(*c);\n        }\n    }\n\n    smawk_inner(matrix, rows, &odd_cols, minima);\n\n    let mut r = 0;\n    for (c, &col) in cols.iter().enumerate().filter(|(c, _)| c % 2 == 0) {\n        let mut row = rows[r];\n        let last_row = if c == cols.len() - 1 {\n            rows[rows.len() - 1]\n        } else {\n            minima[cols[c + 1]]\n        };\n        let mut pair = (matrix(row, col), row);\n        while row != last_row {\n            r += 1;\n            row = rows[r];\n            if (matrix(row, col), row) < pair {\n                pair = (matrix(row, col), row);\n            }\n        }\n        minima[col] = pair.1;\n    }\n}""}","{""next_api_call"": ""smawk_inner(&|j, i| matrix.index(i, j), &(0..matrix.ncols()).collect::<Vec<_>>(), &(0..matrix.nrows()).collect::<Vec<_>>(), &mut minima);""}",api_usage_prediction
smawk,"{""code"": ""let axis = match dir() { Direction::Row => Axis(0), Direction::Column => Axis(1), };"", ""code_context"": ""use ndarray::Axis;\n\nenum Direction {\n    Row,\n    Column,\n}\n\nfn recursive_inner<T: Ord, F: Fn() -> Direction>(\n    matrix: ndarray::ArrayView2<'_, T>,\n    dir: &F,\n    offset: usize,\n    minima: &mut [usize],\n) {\n    if matrix.is_empty() {\n        return;\n    }\n\n    let axis = match dir() {\n        Direction::Row => Axis(0),\n        Direction::Column => Axis(1),\n    };\n    let mid = matrix.len_of(axis) / 2;\n    let min_idx = crate::brute_force::lane_minimum(matrix.index_axis(axis, mid));\n    minima[mid] = offset + min_idx;\n\n    if mid == 0 {\n        return;\n    }\n\n    let top_left = match dir() {\n        Direction::Row => matrix.slice(ndarray::s![..mid, ..(min_idx + 1)]),\n        Direction::Column => matrix.slice(ndarray::s![..(min_idx + 1), ..mid]),\n    };\n    let bot_right = match dir() {\n        Direction::Row => matrix.slice(ndarray::s![(mid + 1).., min_idx..]),\n        Direction::Column => matrix.slice(ndarray::s![min_idx.., (mid + 1)..]),\n    };\n    recursive_inner(top_left, dir, offset, &mut minima[..mid]);\n    recursive_inner(bot_right, dir, offset + min_idx, &mut minima[mid + 1..]);\n}""}","{""next_api_call"": ""let mid = matrix.len_of(axis) / 2;""}",api_usage_prediction
smawk,"{""code"": ""let top_left = Wrapping(matrix.index(row, col));"", ""code_context"": ""use std::num::Wrapping;\nuse std::ops::Add;\n\npub trait Matrix<T: Copy> {\n    fn nrows(&self) -> usize;\n    fn ncols(&self) -> usize;\n    fn index(&self, row: usize, column: usize) -> T;\n}\n\nfn is_monge<T: Ord + Copy, M: Matrix<T>>(matrix: &M) -> bool\nwhere\n    Wrapping<T>: Add<Output = Wrapping<T>>, {\n    fn checked_add<T: Ord + Copy>(a: Wrapping<T>, b: Wrapping<T>) -> Result<T, T>\n    where\n        Wrapping<T>: Add<Output = Wrapping<T>>, {\n        let sum = a + b;\n        if sum < a {\n            Err(sum.0)\n        } else {\n            Ok(sum.0)\n        }\n    }\n\n    (0..matrix.nrows() - 1)\n        .flat_map(|row| (0..matrix.ncols() - 1).map(move |col| (row, col)))\n        .all(|(row, col)| {\n            let top_left = Wrapping(matrix.index(row, col));\n            let top_right = Wrapping(matrix.index(row, col + 1));\n            let bot_left = Wrapping(matrix.index(row + 1, col));\n            let bot_right = Wrapping(matrix.index(row + 1, col + 1));\n\n            match (\n                checked_add(top_left, bot_right),\n                checked_add(bot_left, top_right),\n            ) {\n                (Ok(a), Ok(b)) => a <= b,\n                (Err(a), Err(b)) => a <= b,\n                (Ok(_), Err(_)) => true,\n                (Err(_), Ok(_)) => false,\n            }\n        })\n}""}","{""next_api_call"": ""let top_right = Wrapping(matrix.index(row, col + 1));""}",api_usage_prediction
smawk,"{""code"": ""let brute_force = brute_force::row_minima(&matrix);"", ""code_context"": ""use ndarray::Array2;\n\npub fn row_minima<T: Ord>(matrix: &Array2<T>) -> Vec<usize> {\n    matrix.rows().into_iter().map(lane_minimum).collect()\n}\n\npub fn column_minima<T: Ord>(matrix: &Array2<T>) -> Vec<usize> {\n    matrix.columns().into_iter().map(lane_minimum).collect()\n}\n\npub fn lane_minimum<T: Ord>(lane: ndarray::ArrayView1<'_, T>) -> usize {\n    lane.iter()\n        .enumerate()\n        .min_by_key(|&(idx, elem)| (elem, idx))\n        .map(|(idx, _)| idx)\n        .expect(\""empty lane in matrix\"")\n}""}","{""next_api_call"": ""let recursive = recursive::row_minima(&matrix);""}",api_usage_prediction
smawk,"{""code_context"": ""use ndarray::{Array2, ArrayView1};\n\n/// Compute lane minimum by brute force.\n///\n/// This does a simple scan through the lane (row or column).\n#[inline]\npub fn lane_minimum<T: Ord>(lane: ArrayView1<'_, T>) -> usize {\n    lane.iter()\n        .enumerate()\n        .min_by_key(|&(idx, elem)| (elem, idx))\n        .map(|(idx, _)| idx)\n        .expect(\""empty lane in matrix\"")\n}\n\n/// Compute row minima by brute force in O(*mn*) time.\n///\n/// This function implements a simple brute-force approach where each\n/// matrix row is scanned completely. This means that the function\n/// works on all matrices, not just Monge matrices.\n///\n/// # Examples\n///\n/// ```\n/// let matrix = ndarray::arr2(&[[4, 2, 4, 3],\n///                              [5, 3, 5, 3],\n///                              [5, 3, 3, 1]]);\n/// assert_eq!(smawk::brute_force::row_minima(&matrix),\n///            vec![1, 1, 3]);\n/// ```\n///\n/// # Panics\n///\n/// It is an error to call this on a matrix with zero columns.\npub fn row_minima<T: Ord>(matrix: &Array2<T>) -> Vec<usize> {\n    matrix.rows().into_iter().map(lane_minimum).collect()\n}\n\n/// Compute column minima by brute force in O(*mn*) time.\n///\n/// This function implements a simple brute-force approach where each\n/// matrix column is scanned completely. This means that the function\n/// works on all matrices, not just Monge matrices.\n///\n/// # Examples\n///\n/// ```\n/// let matrix = ndarray::arr2(&[[4, 2, 4, 3],\n///                              [5, 3, 5, 3],\n///                              [5, 3, 3, 1]]);\n/// assert_eq!(smawk::brute_force::column_minima(&matrix),\n///            vec![0, 0, 2, 2]);\n/// ```\n///\n/// # Panics\n///\n/// It is an error to call this on a matrix with zero rows.\npub fn column_minima<T: Ord>(matrix: &Array2<T>) -> Vec<usize> {\n    matrix.columns().into_iter().map(lane_minimum).collect()\n}"", ""code_to_test"": ""pub fn row_minima<T: Ord>(matrix: &Array2<T>) -> Vec<usize> {\n    matrix.rows().into_iter().map(lane_minimum).collect()\n}"", ""test_context"": ""use super::*;\nuse ndarray::arr2;""}","{""test_cases"": [""#[test]\n    fn brute_force_1x1() {\n        let matrix = arr2(&[[2]]);\n        let minima = vec![0];\n        assert_eq!(row_minima(&matrix), minima);\n        assert_eq!(column_minima(&matrix.reversed_axes()), minima);\n    }"", ""#[test]\n    fn brute_force_2x1() {\n        let matrix = arr2(&[\n            [3], //\n            [2],\n        ]);\n        let minima = vec![0, 0];\n        assert_eq!(row_minima(&matrix), minima);\n        assert_eq!(column_minima(&matrix.reversed_axes()), minima);\n    }"", ""#[test]\n    fn brute_force_1x2() {\n        let matrix = arr2(&[[2, 1]]);\n        let minima = vec![1];\n        assert_eq!(row_minima(&matrix), minima);\n        assert_eq!(column_minima(&matrix.reversed_axes()), minima);\n    }"", ""#[test]\n    fn brute_force_2x2() {\n        let matrix = arr2(&[\n            [3, 2], //\n            [2, 1],\n        ]);\n        let minima = vec![1, 1];\n        assert_eq!(row_minima(&matrix), minima);\n        assert_eq!(column_minima(&matrix.reversed_axes()), minima);\n    }"", ""#[test]\n    fn brute_force_3x3() {\n        let matrix = arr2(&[\n            [3, 4, 4], //\n            [3, 4, 4],\n            [2, 3, 3],\n        ]);\n        let minima = vec![0, 0, 0];\n        assert_eq!(row_minima(&matrix), minima);\n        assert_eq!(column_minima(&matrix.reversed_axes()), minima);\n    }"", ""#[test]\n    fn brute_force_4x4() {\n        let matrix = arr2(&[\n            [4, 5, 5, 5], //\n            [2, 3, 3, 3],\n            [2, 3, 3, 3],\n            [2, 2, 2, 2],\n        ]);\n        let minima = vec![0, 0, 0, 0];\n        assert_eq!(row_minima(&matrix), minima);\n        assert_eq!(column_minima(&matrix.reversed_axes()), minima);\n    }"", ""#[test]\n    fn brute_force_5x5() {\n        let matrix = arr2(&[\n            [3, 2, 4, 5, 6],\n            [2, 1, 3, 3, 4],\n            [2, 1, 3, 3, 4],\n            [3, 2, 4, 3, 4],\n            [4, 3, 2, 1, 1],\n        ]);\n        let minima = vec![1, 1, 1, 1, 3];\n        assert_eq!(row_minima(&matrix), minima);\n        assert_eq!(column_minima(&matrix.reversed_axes()), minima);\n    }""]}",test_generation
smawk,"{""code_context"": ""use ndarray::{Array2, ArrayView1};\n\n/// Compute lane minimum by brute force.\n///\n/// This does a simple scan through the lane (row or column).\n#[inline]\npub fn lane_minimum<T: Ord>(lane: ArrayView1<'_, T>) -> usize {\n    lane.iter()\n        .enumerate()\n        .min_by_key(|&(idx, elem)| (elem, idx))\n        .map(|(idx, _)| idx)\n        .expect(\""empty lane in matrix\"")\n}\n\n/// Compute row minima by brute force in O(*mn*) time.\n///\n/// This function implements a simple brute-force approach where each\n/// matrix row is scanned completely. This means that the function\n/// works on all matrices, not just Monge matrices.\n///\n/// # Examples\n///\n/// ```\n/// let matrix = ndarray::arr2(&[[4, 2, 4, 3],\n///                              [5, 3, 5, 3],\n///                              [5, 3, 3, 1]]);\n/// assert_eq!(smawk::brute_force::row_minima(&matrix),\n///            vec![1, 1, 3]);\n/// ```\n///\n/// # Panics\n///\n/// It is an error to call this on a matrix with zero columns.\npub fn row_minima<T: Ord>(matrix: &Array2<T>) -> Vec<usize> {\n    matrix.rows().into_iter().map(lane_minimum).collect()\n}\n\n/// Compute column minima by brute force in O(*mn*) time.\n///\n/// This function implements a simple brute-force approach where each\n/// matrix column is scanned completely. This means that the function\n/// works on all matrices, not just Monge matrices.\n///\n/// # Examples\n///\n/// ```\n/// let matrix = ndarray::arr2(&[[4, 2, 4, 3],\n///                              [5, 3, 5, 3],\n///                              [5, 3, 3, 1]]);\n/// assert_eq!(smawk::brute_force::column_minima(&matrix),\n///            vec![0, 0, 2, 2]);\n/// ```\n///\n/// # Panics\n///\n/// It is an error to call this on a matrix with zero rows.\npub fn column_minima<T: Ord>(matrix: &Array2<T>) -> Vec<usize> {\n    matrix.columns().into_iter().map(lane_minimum).collect()\n}"", ""code_to_test"": ""pub fn column_minima<T: Ord>(matrix: &Array2<T>) -> Vec<usize> {\n    matrix.columns().into_iter().map(lane_minimum).collect()\n}"", ""test_context"": ""use super::*;\nuse ndarray::arr2;""}","{""test_cases"": [""#[test]\n    fn brute_force_1x1() {\n        let matrix = arr2(&[[2]]);\n        let minima = vec![0];\n        assert_eq!(row_minima(&matrix), minima);\n        assert_eq!(column_minima(&matrix.reversed_axes()), minima);\n    }"", ""#[test]\n    fn brute_force_2x1() {\n        let matrix = arr2(&[\n            [3], //\n            [2],\n        ]);\n        let minima = vec![0, 0];\n        assert_eq!(row_minima(&matrix), minima);\n        assert_eq!(column_minima(&matrix.reversed_axes()), minima);\n    }"", ""#[test]\n    fn brute_force_1x2() {\n        let matrix = arr2(&[[2, 1]]);\n        let minima = vec![1];\n        assert_eq!(row_minima(&matrix), minima);\n        assert_eq!(column_minima(&matrix.reversed_axes()), minima);\n    }"", ""#[test]\n    fn brute_force_2x2() {\n        let matrix = arr2(&[\n            [3, 2], //\n            [2, 1],\n        ]);\n        let minima = vec![1, 1];\n        assert_eq!(row_minima(&matrix), minima);\n        assert_eq!(column_minima(&matrix.reversed_axes()), minima);\n    }"", ""#[test]\n    fn brute_force_3x3() {\n        let matrix = arr2(&[\n            [3, 4, 4], //\n            [3, 4, 4],\n            [2, 3, 3],\n        ]);\n        let minima = vec![0, 0, 0];\n        assert_eq!(row_minima(&matrix), minima);\n        assert_eq!(column_minima(&matrix.reversed_axes()), minima);\n    }"", ""#[test]\n    fn brute_force_4x4() {\n        let matrix = arr2(&[\n            [4, 5, 5, 5], //\n            [2, 3, 3, 3],\n            [2, 3, 3, 3],\n            [2, 2, 2, 2],\n        ]);\n        let minima = vec![0, 0, 0, 0];\n        assert_eq!(row_minima(&matrix), minima);\n        assert_eq!(column_minima(&matrix.reversed_axes()), minima);\n    }"", ""#[test]\n    fn brute_force_5x5() {\n        let matrix = arr2(&[\n            [3, 2, 4, 5, 6],\n            [2, 1, 3, 3, 4],\n            [2, 1, 3, 3, 4],\n            [3, 2, 4, 3, 4],\n            [4, 3, 2, 1, 1],\n        ]);\n        let minima = vec![1, 1, 1, 1, 3];\n        assert_eq!(row_minima(&matrix), minima);\n        assert_eq!(column_minima(&matrix.reversed_axes()), minima);\n    }""]}",test_generation
smawk,"{""code_context"": ""pub trait Matrix<T: Copy> {\n    fn nrows(&self) -> usize;\n    fn ncols(&self) -> usize;\n    fn index(&self, row: usize, column: usize) -> T;\n}\n\npub fn column_minima<T: PartialOrd + Copy, M: Matrix<T>>(matrix: &M) -> Vec<usize> {\n    let mut minima = vec![0; matrix.ncols()];\n    smawk_inner(\n        &|i, j| matrix.index(i, j),\n        &(0..matrix.nrows()).collect::<Vec<_>>(),\n        &(0..matrix.ncols()).collect::<Vec<_>>(),\n        &mut minima,\n    );\n    minima\n}\n\nfn smawk_inner<T: PartialOrd + Copy, M: Fn(usize, usize) -> T>(\n    matrix: &M,\n    rows: &[usize],\n    cols: &[usize],\n    minima: &mut [usize],\n) {\n    if cols.is_empty() {\n        return;\n    }\n\n    let mut stack = Vec::with_capacity(cols.len());\n    for r in rows {\n        while !stack.is_empty()\n            && matrix(stack[stack.len() - 1], cols[stack.len() - 1])\n                > matrix(*r, cols[stack.len() - 1])\n        {\n            stack.pop();\n        }\n        if stack.len() != cols.len() {\n            stack.push(*r);\n        }\n    }\n    let rows = &stack;\n\n    let mut odd_cols = Vec::with_capacity(1 + cols.len() / 2);\n    for (idx, c) in cols.iter().enumerate() {\n        if idx % 2 == 1 {\n            odd_cols.push(*c);\n        }\n    }\n\n    smawk_inner(matrix, rows, &odd_cols, minima);\n\n    let mut r = 0;\n    for (c, &col) in cols.iter().enumerate().filter(|(c, _)| c % 2 == 0) {\n        let mut row = rows[r];\n        let last_row = if c == cols.len() - 1 {\n            rows[rows.len() - 1]\n        } else {\n            minima[cols[c + 1]]\n        };\n        let mut pair = (matrix(row, col), row);\n        while row != last_row {\n            r += 1;\n            row = rows[r];\n            if (matrix(row, col), row) < pair {\n                pair = (matrix(row, col), row);\n            }\n        }\n        minima[col] = pair.1;\n    }\n}"", ""code_to_test"": ""pub fn row_minima<T: PartialOrd + Copy, M: Matrix<T>>(matrix: &M) -> Vec<usize> {\n    // Benchmarking shows that SMAWK performs roughly the same on row-\n    // and column-major matrices.\n    let mut minima = vec![0; matrix.nrows()];\n    smawk_inner(\n        &|j, i| matrix.index(i, j),\n        &(0..matrix.ncols()).collect::<Vec<_>>(),\n        &(0..matrix.nrows()).collect::<Vec<_>>(),\n        &mut minima,\n    );\n    minima\n}"", ""test_context"": ""use super::*;\nuse ndarray::arr2;""}","{""test_cases"": [""#[test]\n    fn smawk_1x1() {\n        let matrix = vec![vec![2]];\n        assert_eq!(row_minima(&matrix), vec![0]);\n        assert_eq!(column_minima(&matrix), vec![0]);\n    }"", ""#[test]\n    fn smawk_2x1() {\n        let matrix = vec![\n            vec![3], //\n            vec![2],\n        ];\n        assert_eq!(row_minima(&matrix), vec![0, 0]);\n        assert_eq!(column_minima(&matrix), vec![1]);\n    }"", ""#[test]\n    fn smawk_1x2() {\n        let matrix = vec![vec![2, 1]];\n        assert_eq!(row_minima(&matrix), vec![1]);\n        assert_eq!(column_minima(&matrix), vec![0, 0]);\n    }"", ""#[test]\n    fn smawk_2x2() {\n        let matrix = vec![\n            vec![3, 2], //\n            vec![2, 1],\n        ];\n        assert_eq!(row_minima(&matrix), vec![1, 1]);\n        assert_eq!(column_minima(&matrix), vec![1, 1]);\n    }"", ""#[test]\n    fn smawk_3x3() {\n        let matrix = vec![\n            vec![3, 4, 4], //\n            vec![3, 4, 4],\n            vec![2, 3, 3],\n        ];\n        assert_eq!(row_minima(&matrix), vec![0, 0, 0]);\n        assert_eq!(column_minima(&matrix), vec![2, 2, 2]);\n    }"", ""#[test]\n    fn smawk_4x4() {\n        let matrix = vec![\n            vec![4, 5, 5, 5], //\n            vec![2, 3, 3, 3],\n            vec![2, 3, 3, 3],\n            vec![2, 2, 2, 2],\n        ];\n        assert_eq!(row_minima(&matrix), vec![0, 0, 0, 0]);\n        assert_eq!(column_minima(&matrix), vec![1, 3, 3, 3]);\n    }"", ""#[test]\n    fn smawk_5x5() {\n        let matrix = vec![\n            vec![3, 2, 4, 5, 6],\n            vec![2, 1, 3, 3, 4],\n            vec![2, 1, 3, 3, 4],\n            vec![3, 2, 4, 3, 4],\n            vec![4, 3, 2, 1, 1],\n        ];\n        assert_eq!(row_minima(&matrix), vec![1, 1, 1, 1, 3]);\n        assert_eq!(column_minima(&matrix), vec![1, 1, 4, 4, 4]);\n    }""]}",test_generation
serde-value,"{""code"": ""Ok(Value::Bool(v))"", ""code_context"": ""use std::collections::BTreeMap;\n\npub enum Value {\n    Bool(bool),\n    U8(u8),\n    U16(u16),\n    U32(u32),\n    U64(u64),\n    I8(i8),\n    I16(i16),\n    I32(i32),\n    I64(i64),\n    F32(f32),\n    F64(f64),\n    Char(char),\n    String(String),\n    Unit,\n    Option(Option<Box<Value>>),\n    Newtype(Box<Value>),\n    Seq(Vec<Value>),\n    Map(BTreeMap<Value, Value>),\n    Bytes(Vec<u8>),\n}""}","{""commented_code"": ""Ok(Value::Bool(v)) // Wrap the boolean in a Value::Bool variant""}",comment_generation
serde-value,"{""code"": ""Ok(Value::Bool(value))"", ""code_context"": ""use std::collections::BTreeMap;\n\npub enum Value {\n    Bool(bool),\n    U8(u8),\n    U16(u16),\n    U32(u32),\n    U64(u64),\n    I8(i8),\n    I16(i16),\n    I32(i32),\n    I64(i64),\n    F32(f32),\n    F64(f64),\n    Char(char),\n    String(String),\n    Unit,\n    Option(Option<Box<Value>>),\n    Newtype(Box<Value>),\n    Seq(Vec<Value>),\n    Map(BTreeMap<Value, Value>),\n    Bytes(Vec<u8>),\n}""}","{""commented_code"": ""Ok(Value::Bool(value)) // Convert the bool into a Value::Bool""}",comment_generation
serde-value,"{""code"": ""let input = Value::I32(5);"", ""code_context"": ""use std::collections::BTreeMap;\n\npub enum Value {\n    Bool(bool),\n    U8(u8),\n    U16(u16),\n    U32(u32),\n    U64(u64),\n    I8(i8),\n    I16(i16),\n    I32(i32),\n    I64(i64),\n    F32(f32),\n    F64(f64),\n    Char(char),\n    String(String),\n    Unit,\n    Option(Option<Box<Value>>),\n    Newtype(Box<Value>),\n    Seq(Vec<Value>),\n    Map(BTreeMap<Value, Value>),\n    Bytes(Vec<u8>),\n}""}","{""commented_code"": ""let input = Value::I32(5); // Represent an i32 as a Value variant""}",comment_generation
serde-value,"{""code"": ""let input = Value::Map(vec![(Value::String(\""foo\"".to_owned()), Value::I32(5))].into_iter().collect());"", ""code_context"": ""use std::collections::BTreeMap;\n\npub enum Value {\n    Bool(bool),\n    U8(u8),\n    U16(u16),\n    U32(u32),\n    U64(u64),\n    I8(i8),\n    I16(i16),\n    I32(i32),\n    I64(i64),\n    F32(f32),\n    F64(f64),\n    Char(char),\n    String(String),\n    Unit,\n    Option(Option<Box<Value>>),\n    Newtype(Box<Value>),\n    Seq(Vec<Value>),\n    Map(BTreeMap<Value, Value>),\n    Bytes(Vec<u8>),\n}""}","{""commented_code"": ""let input = Value::Map(vec![(Value::String(\""foo\"".to_owned()), Value::I32(5))].into_iter().collect()); // Map with a single key \""foo\"" to an integer value""}",comment_generation
serde-value,"{""code"": ""value.serialize(Serializer).map(|v| Value::Newtype(Box::new(v)))"", ""code_context"": ""use std::collections::BTreeMap;\nuse serde::ser;\n\npub enum Value {\n    Bool(bool),\n    U8(u8),\n    U16(u16),\n    U32(u32),\n    U64(u64),\n    I8(i8),\n    I16(i16),\n    I32(i32),\n    I64(i64),\n    F32(f32),\n    F64(f64),\n    Char(char),\n    String(String),\n    Unit,\n    Option(Option<Box<Value>>),\n    Newtype(Box<Value>),\n    Seq(Vec<Value>),\n    Map(BTreeMap<Value, Value>),\n    Bytes(Vec<u8>),\n}\n\npub struct Serializer;\n\nimpl ser::Serializer for Serializer {\n    type Ok = Value;\n    type Error = (); // placeholder error type\n    type SerializeSeq = ();\n    type SerializeTuple = ();\n    type SerializeTupleStruct = ();\n    type SerializeTupleVariant = ();\n    type SerializeMap = ();\n    type SerializeStruct = ();\n    type SerializeStructVariant = ();\n    // Minimal stub implementations omitted for brevity\n    fn serialize_bool(self, _v: bool) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_i8(self, _v: i8) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_i16(self, _v: i16) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_i32(self, _v: i32) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_i64(self, _v: i64) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_u8(self, _v: u8) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_u16(self, _v: u16) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_u32(self, _v: u32) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_u64(self, _v: u64) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_f32(self, _v: f32) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_f64(self, _v: f64) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_char(self, _v: char) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_str(self, _v: &str) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_bytes(self, _v: &[u8]) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_none(self) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_some<T: ?Sized>(self, _value: &T) -> Result<Self::Ok, Self::Error> where T: ser::Serialize { unimplemented!() }\n    fn serialize_unit(self) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_unit_struct(self, _name: &'static str) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_unit_variant(self, _name: &'static str, _variant_index: u32, _variant: &'static str) -> Result<Self::Ok, Self::Error> { unimplemented!() }\n    fn serialize_newtype_struct<T: ?Sized>(self, _name: &'static str, _value: &T) -> Result<Self::Ok, Self::Error> where T: ser::Serialize { unimplemented!() }\n    fn serialize_newtype_variant<T: ?Sized>(self, _name: &'static str, _variant_index: u32, _variant: &'static str, _value: &T) -> Result<Self::Ok, Self::Error> where T: ser::Serialize { unimplemented!() }\n    fn serialize_seq(self, _len: Option<usize>) -> Result<Self::SerializeSeq, Self::Error> { unimplemented!() }\n    fn serialize_tuple(self, _len: usize) -> Result<Self::SerializeTuple, Self::Error> { unimplemented!() }\n    fn serialize_tuple_struct(self, _name: &'static str, _len: usize) -> Result<Self::SerializeTupleStruct, Self::Error> { unimplemented!() }\n    fn serialize_tuple_variant(self, _name: &'static str, _variant_index: u32, _variant: &'static str, _len: usize) -> Result<Self::SerializeTupleVariant, Self::Error> { unimplemented!() }\n    fn serialize_map(self, _len: Option<usize>) -> Result<Self::SerializeMap, Self::Error> { unimplemented!() }\n    fn serialize_struct(self, _name: &'static str, _len: usize) -> Result<Self::SerializeStruct, Self::Error> { unimplemented!() }\n    fn serialize_struct_variant(self, _name: &'static str, _variant_index: u32, _variant: &'static str, _len: usize) -> Result<Self::SerializeStructVariant, Self::Error> { unimplemented!() }\n}\n""}","{""commented_code"": ""value.serialize(Serializer).map(|v| Value::Newtype(Box::new(v))) // Wrap the serialized value in a Newtype variant""}",comment_generation
aws-smithy-xml,"{""buggy_code"": ""pub fn try_data<'a, 'inp>(\n    tokens: &'a mut impl Iterator<Item = Result<(XmlToken<'inp>, Depth), XmlDecodeError>>,\n) -> Result<Cow<'inp, str>, XmlDecodeError> {\n    loop {\n        match tokens.next().map(|opt| opt.map(|opt| opt.0)) {\n            None => return Ok(Cow::Borrowed(\""\"")),\n            Some(Ok(XmlToken(Token::Text { text }))) => return unescape(text.as_str()),\n            Some(Ok(e @ XmlToken(Token::ElementStart { .. }))) => {\n                return Err(XmlDecodeError::custom(format!(\n                    \""looking for a data element, found: {:?}\"",\n                    e\n                )))\n            }\n            Some(Err(e)) => return Err(e),\n            _ => {}\n        }\n    }\n}"", ""code_context"": ""use std::borrow::Cow;\nuse crate::decode::{XmlDecodeError, XmlToken, Depth, Token};\n\npub fn try_data<'a, 'inp>(\n    tokens: &'a mut impl Iterator<Item = Result<(XmlToken<'inp>, Depth), XmlDecodeError>>,\n) -> Result<Cow<'inp, str>, XmlDecodeError> {\n    // original implementation ...\n}""}","{""fixed_code"": ""pub fn try_data<'a, 'inp>(\n    tokens: &'a mut impl Iterator<Item = Result<(XmlToken<'inp>, Depth), XmlDecodeError>>,\n) -> Result<Cow<'inp, str>, XmlDecodeError> {\n    loop {\n        match tokens.next().map(|opt| opt.map(|opt| opt.0)) {\n            None => return Err(XmlDecodeError::custom(\""unexpected end of input while reading data\"")),\n            Some(Ok(XmlToken(Token::Text { text }))) => return unescape(text.as_str()),\n            Some(Ok(e @ XmlToken(Token::ElementStart { .. }))) => {\n                return Err(XmlDecodeError::custom(format!(\n                    \""looking for a data element, found: {:?}\"",\n                    e\n                )))\n            }\n            Some(Err(e)) => return Err(e),\n            _ => {}\n        }\n    }\n}"", ""bug_description"": ""When the token iterator reaches the end of the XML stream, `try_data` returns an empty string (`Ok(Cow::Borrowed(\""\""))`). Callers interpret this as a valid data element, which silently masks missing or malformed data and can lead to incorrect parsing results. The fix changes the `None` branch to return an error (`XmlDecodeError::custom(\""unexpected end of input while reading data\"")`), making the absence of data explicit and allowing callers to handle the situation appropriately.""}",bug_detection
aws-smithy-xml,"{""buggy_code"": ""out.attributes.push(Attr {\n    name: Name {\n        local: local.as_str(),\n        prefix: prefix.as_str(),\n    },\n    value: unescape(value.as_str()).ok()?,\n});"", ""code_context"": ""use crate::unescape::unescape;\nuse crate::decode::{Name, Attr, StartEl};\n\nfn next_start_element<'a, 'inp>(\n    tokens: &'a mut impl Iterator<Item = Result<(XmlToken<'inp>, Depth), XmlDecodeError>>,\n) -> Option<StartEl<'inp>> {\n    let mut out = StartEl::new(\""\"", \""\"", 0);\n    loop {\n        match tokens.next()? {\n            Ok((XmlToken(Token::ElementStart { local, prefix, .. }), depth)) => {\n                out.name.local = local.as_str();\n                out.name.prefix = prefix.as_str();\n                out.depth = depth;\n            }\n            Ok((XmlToken(Token::Attribute { prefix, local, value, .. }), _)) => {\n                out.attributes.push(Attr {\n                    name: Name {\n                        local: local.as_str(),\n                        prefix: prefix.as_str(),\n                    },\n                    value: unescape(value.as_str())?,\n                });\n            }\n            // ... other match arms ...\n        }\n    }\n}""}","{""fixed_code"": ""out.attributes.push(Attr {\n    name: Name {\n        local: local.as_str(),\n        prefix: prefix.as_str(),\n    },\n    value: unescape(value.as_str())?,\n});"", ""bug_description"": ""When parsing an attribute, the code uses `unescape(value.as_str()).ok()?`. If the attribute value contains an invalid escape sequence, `unescape` returns an `Err`, which is silently discarded by `ok()?`, causing the attribute to be dropped without any diagnostic. This can lead to missing attribute data and hard‑to‑detect bugs. The fix replaces `ok()?` with `?`, propagating the error so that malformed attributes cause the parser to fail with a clear error message.""}",bug_detection
aws-smithy-xml,"{""buggy_code"": ""fn deserialize_foo_enum_map_entry(\n    decoder: &mut ScopedDecoder,\n    out: &mut HashMap<String, FooEnum>,\n) -> Result<(), XmlDecodeError> {\n    let mut k: Option<String> = None;\n    let mut v: Option<FooEnum> = None;\n    while let Some(mut tag) = decoder.next_tag() {\n        match tag.start_el() {\n            s if s.matches(\""key\"") => k = Some(try_data(&mut tag)?.to_string()),\n            s if s.matches(\""value\"") => v = Some(FooEnum::from(try_data(&mut tag)?.as_ref())),\n            _ => {}\n        }\n    }\n    match (k, v) {\n        (Some(k), Some(v)) => {\n            out.insert(k, v);\n        }\n        _ => return Err(XmlDecodeError::custom(\""missing key value in map\"")),\n    }\n    Ok(())\n}"", ""code_context"": ""use std::collections::HashMap;\nuse crate::decode::{ScopedDecoder, XmlDecodeError, try_data};\n\n#[derive(Eq, PartialEq, Debug)]\nenum FooEnum {\n    Unknown(String),\n}\n\nimpl<'a> From<&'a str> for FooEnum {\n    fn from(s: &'a str) -> Self {\n        Self::Unknown(s.to_string())\n    }\n}\n\nfn deserialize_foo_enum_map_entry(\n    decoder: &mut ScopedDecoder,\n    out: &mut HashMap<String, FooEnum>,\n) -> Result<(), XmlDecodeError> {\n    // original implementation ...\n}""}","{""fixed_code"": ""fn deserialize_foo_enum_map_entry(\n    decoder: &mut ScopedDecoder,\n    out: &mut HashMap<String, FooEnum>,\n) -> Result<(), XmlDecodeError> {\n    let mut k: Option<String> = None;\n    let mut v: Option<FooEnum> = None;\n    while let Some(mut tag) = decoder.next_tag() {\n        match tag.start_el() {\n            s if s.matches(\""key\"") => k = Some(try_data(&mut tag)?.to_string()),\n            s if s.matches(\""value\"") => v = Some(FooEnum::from(try_data(&mut tag)?.as_ref())),\n            _ => {}\n        }\n    }\n    match (k, v) {\n        (Some(k), Some(v)) => {\n            if out.contains_key(&k) {\n                return Err(XmlDecodeError::custom(\""duplicate map key encountered\""));\n            }\n            out.insert(k, v);\n        }\n        _ => return Err(XmlDecodeError::custom(\""missing key value in map\"")),\n    }\n    Ok(())\n}"", ""bug_description"": ""The original implementation inserts map entries without checking for duplicate keys. When the XML contains multiple `<entry>` elements with the same `<key>`, the later entry silently overwrites the earlier one, causing data loss. The fix adds a duplicate‑key check and returns an error (`XmlDecodeError::custom(\""duplicate map key encountered\"")`) if a key is already present, preserving data integrity and making the problem visible to callers.""}",bug_detection
simd-adler32,"{""code"": ""let mut adler = Adler32::new();"", ""code_context"": ""type Adler32Imp = fn(u16, u16, &[u8]) -> (u16, u16);\nfn get_imp() -> Adler32Imp { unimplemented!() }\n\npub struct Adler32 {\n    a: u16,\n    b: u16,\n    update: Adler32Imp,\n}\n\nimpl Adler32 {\n    pub fn new() -> Self {\n        Self {\n            a: 1,\n            b: 0,\n            update: get_imp(),\n        }\n    }\n}""}","{""commented_code"": ""let mut adler = Adler32::new(); // Constructs a new Adler32 hasher with initial values of a=1 and b=0.""}",comment_generation
simd-adler32,"{""code"": ""pub fn update(a: u16, b: u16, data: &[u8]) -> (u16, u16) {"", ""code_context"": ""const MOD: u32 = 65521;\nconst NMAX: usize = 5552;\n\npub fn update(a: u16, b: u16, data: &[u8]) -> (u16, u16) {\n    let mut a = a as u32;\n    let mut b = b as u32;\n\n    let chunks = data.chunks_exact(NMAX);\n    let remainder = chunks.remainder();\n\n    for chunk in chunks {\n        for byte in chunk {\n            a = a.wrapping_add(*byte as _);\n            b = b.wrapping_add(a);\n        }\n\n        a %= MOD;\n        b %= MOD;\n    }\n\n    for byte in remainder {\n        a = a.wrapping_add(*byte as _);\n        b = b.wrapping_add(a);\n    }\n\n    a %= MOD;\n    b %= MOD;\n\n    (a as u16, b as u16)\n}""}","{""commented_code"": ""pub fn update(a: u16, b: u16, data: &[u8]) -> (u16, u16) { // Compute Adler-32 hash for a chunk of data using scalar implementation""}",comment_generation
simd-adler32,"{""code"": ""let chunks = data.chunks_exact(CHUNK_SIZE);"", ""code_context"": ""const MOD: u32 = 65521;\nconst NMAX: usize = 5552;\nconst BLOCK_SIZE: usize = 32;\nconst CHUNK_SIZE: usize = NMAX / BLOCK_SIZE * BLOCK_SIZE;\n\npub unsafe fn update_imp(a: u16, b: u16, data: &[u8]) -> (u16, u16) {\n    let mut a = a as u32;\n    let mut b = b as u32;\n\n    let chunks = data.chunks_exact(CHUNK_SIZE);\n    let _remainder = chunks.remainder();\n    for _chunk in chunks {\n    }\n\n    (a as u16, b as u16)\n}""}","{""commented_code"": ""let chunks = data.chunks_exact(CHUNK_SIZE); // Split data into fixed-size chunks for SIMD processing""}",comment_generation
radix_trie,"{""code"": ""println!(\""Iterating over child with value: {:?}\"", c.value());"", ""code_context"": ""extern crate radix_trie;\n\nuse radix_trie::{Trie, TrieCommon};\n\nfn main() {\n    let mut t = Trie::new();\n    t.insert(\""z\"", 2);\n    t.insert(\""aba\"", 5);\n    t.insert(\""abb\"", 6);\n    t.insert(\""abc\"", 50);\n\n    let ab_sum = t.get_raw_ancestor(&\""abd\"").children().fold(0, |acc, c| {\n        println!(\""Iterating over child with value: {:?}\"", c.value());\n        acc + *c.value().unwrap_or(&0)\n    });\n    println!(\""{}\"", ab_sum);\n    assert_eq!(ab_sum, 5 + 6 + 50);\n}""}","{""commented_code"": ""println!(\""Iterating over child with value: {:?}\"", c.value()); // Print each child's value for debugging""}",comment_generation
radix_trie,"{""code"": ""self.length += 1;"", ""code_context"": ""const BRANCH_FACTOR: usize = 16;\n\npub trait TrieKey {\n    fn encode(&self) -> nibble_vec::Nibblet { nibble_vec::Nibblet::new() }\n    fn encode_bytes(&self) -> Vec<u8> { vec![] }\n}\n\npub struct TrieNode<K, V> {\n    key: nibble_vec::Nibblet,\n    key_value: Option<Box<(K, V)>>,\n    children: [Option<Box<TrieNode<K, V>>>; BRANCH_FACTOR],\n    child_count: usize,\n}\n\npub struct Trie<K, V> {\n    length: usize,\n    node: TrieNode<K, V>,\n}\n\nimpl<K, V> Trie<K, V>\nwhere\n    K: TrieKey,\n{\n    pub fn insert(&mut self, key: K, value: V) -> Option<V> {\n        let key_fragments = key.encode();\n        let result = self.node.insert(key, value, key_fragments);\n        if result.is_none() {\n            self.length += 1;\n        }\n        result\n    }\n}\n\nimpl<K, V> TrieNode<K, V> {\n    pub fn insert(&mut self, _key: K, _value: V, _nv: nibble_vec::Nibblet) -> Option<V> {\n        // simplified stub for compilation\n        None\n    }\n}""}","{""commented_code"": ""self.length += 1; // Increment total number of key‑value pairs stored in the trie""}",comment_generation
radix_trie,"{""code"": ""self.child_count += 1;"", ""code_context"": ""const BRANCH_FACTOR: usize = 16;\n\npub struct TrieNode<K, V> {\n    key: nibble_vec::Nibblet,\n    key_value: Option<Box<(K, V)>>,\n    children: [Option<Box<TrieNode<K, V>>>; BRANCH_FACTOR],\n    child_count: usize,\n}\n\nimpl<K, V> TrieNode<K, V> {\n    pub fn add_child(&mut self, idx: usize, node: Box<TrieNode<K, V>>) {\n        debug_assert!(self.children[idx].is_none());\n        self.child_count += 1;\n        self.children[idx] = Some(node);\n    }\n}""}","{""commented_code"": ""self.child_count += 1; // Track the number of occupied child slots in this node""}",comment_generation
radix_trie,"{""code"": ""let mut v: Vec<u8> = Vec::with_capacity(1);"", ""code_context"": ""impl TrieKey for u8 {\n    fn encode_bytes(&self) -> Vec<u8> {\n        let mut v: Vec<u8> = Vec::with_capacity(1);\n        v.push(*self);\n        v\n    }\n}""}","{""commented_code"": ""let mut v: Vec<u8> = Vec::with_capacity(1); // Allocate a vector sized exactly for one byte""}",comment_generation
dotenv,"{""code"": ""pub fn dotenv() -> Result<PathBuf> {\n    let (path, iter) = Finder::new().find()?;\n    iter.load()?;\n    Ok(path)\n}"", ""code_context"": ""use std::path::{Path, PathBuf};\nuse crate::errors::*;\nuse crate::find::Finder;\nuse crate::iter::Iter;""}","{""explanation"": ""The `dotenv` function loads environment variables from a `.env` file. It creates a `Finder` to locate the file in the current directory or its ancestors, obtains an iterator over the file's lines, loads each variable into the process environment, and returns the path of the loaded file.""}",code_explanation
dotenv,"{""code"": ""pub fn var<K: AsRef<OsStr>>(key: K) -> Result<String> {\n    START.call_once(|| {\n        dotenv().ok();\n    });\n    env::var(key).map_err(Error::EnvVar)\n}"", ""code_context"": ""use std::sync::Once;\nuse std::ffi::OsStr;\nuse std::env;\nuse crate::errors::*;\nuse crate::find::Finder;\nuse crate::iter::Iter;\nstatic START: Once = Once::new();""}","{""explanation"": ""The `var` function retrieves the value of an environment variable. It ensures the `.env` file is loaded exactly once using a `Once` guard, then delegates to `std::env::var`, converting any `VarError` into the crate's `Error::EnvVar` type.""}",code_explanation
dotenv,"{""code"": ""impl<R: Read> Iterator for Iter<R> {\n    type Item = Result<(String, String)>;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        loop {\n            let line = match self.lines.next() {\n                Some(Ok(line)) => line,\n                Some(Err(err)) => return Some(Err(Error::Io(err))),\n                None => return None,\n            };\n\n            match parse::parse_line(&line, &mut self.substitution_data) {\n                Ok(Some(result)) => return Some(Ok(result)),\n                Ok(None) => {}\n                Err(err) => return Some(Err(err)),\n            }\n        }\n    }\n}"", ""code_context"": ""use std::collections::HashMap;\nuse std::env;\nuse std::io::prelude::*;\nuse std::io::{BufReader, Lines};\nuse crate::errors::*;\nuse crate::parse;\n\npub struct Iter<R> {\n    lines: Lines<BufReader<R>>,\n    substitution_data: HashMap<String, Option<String>>,\n}\n\nimpl<R: Read> Iter<R> {\n    pub fn new(reader: R) -> Iter<R> {\n        Iter {\n            lines: BufReader::new(reader).lines(),\n            substitution_data: HashMap::new(),\n        }\n    }\n\n    pub fn load(self) -> Result<()> {\n        for item in self {\n            let (key, value) = item?;\n            if env::var(&key).is_err() {\n                env::set_var(&key, value);\n            }\n        }\n        Ok(())\n    }\n}""}","{""explanation"": ""This `Iterator` implementation for `Iter<R>` reads lines from the underlying reader, parses each line into a key‑value pair using `parse_line`, and yields the result. Errors from I/O or parsing are propagated as `Result` items, allowing the iterator to be used in a `for` loop.""}",code_explanation
dotenv,"{""code"": ""fn parse_value(\n    input: &str,\n    substitution_data: &mut HashMap<String, Option<String>>,\n) -> Result<String> {\n    let mut strong_quote = false;\n    let mut weak_quote = false;\n    let mut escaped = false;\n    let mut expecting_end = false;\n    let mut output = String::new();\n    let mut substitution_mode = SubstitutionMode::None;\n    let mut substitution_name = String::new();\n\n    for (index, c) in input.chars().enumerate() {\n        if expecting_end {\n            if c == ' ' || c == '\\t' {\n                continue;\n            } else if c == '#' {\n                break;\n            } else {\n                return Err(Error::LineParse(input.to_owned(), index));\n            }\n        } else if escaped {\n            match c {\n                '\\\\' | '\\'' | '\""' | '$' | ' ' => output.push(c),\n                'n' => output.push('\\n'),\n                _ => return Err(Error::LineParse(input.to_owned(), index)),\n            }\n            escaped = false;\n        } else if strong_quote {\n            if c == '\\'' {\n                strong_quote = false;\n            } else {\n                output.push(c);\n            }\n        } else if substitution_mode != SubstitutionMode::None {\n            if c.is_alphanumeric() {\n                substitution_name.push(c);\n            } else {\n                match substitution_mode {\n                    SubstitutionMode::Block => {\n                        if c == '{' && substitution_name.is_empty() {\n                            substitution_mode = SubstitutionMode::EscapedBlock;\n                        } else {\n                            apply_substitution(\n                                substitution_data,\n                                &substitution_name.drain(..).collect::<String>(),\n                                &mut output,\n                            );\n                            if c == '$' {\n                                substitution_mode = SubstitutionMode::Block;\n                            } else {\n                                substitution_mode = SubstitutionMode::None;\n                                output.push(c);\n                            }\n                        }\n                    }\n                    SubstitutionMode::EscapedBlock => {\n                        if c == '}' {\n                            substitution_mode = SubstitutionMode::None;\n                            apply_substitution(\n                                substitution_data,\n                                &substitution_name.drain(..).collect::<String>(),\n                                &mut output,\n                            );\n                        } else {\n                            substitution_name.push(c);\n                        }\n                    }\n                    SubstitutionMode::None => unreachable!(),\n                }\n            }\n        } else if c == '$' {\n            substitution_mode = SubstitutionMode::Block;\n        } else if weak_quote {\n            if c == '\""' {\n                weak_quote = false;\n            } else if c == '\\\\' {\n                escaped = true;\n            } else {\n                output.push(c);\n            }\n        } else if c == '\\\\' {\n            escaped = true;\n        } else if c == ' ' || c == '\\t' {\n            expecting_end = true;\n        } else {\n            output.push(c);\n        }\n    }\n\n    if substitution_mode == SubstitutionMode::EscapedBlock || strong_quote || weak_quote {\n        let len = input.len();\n        return Err(Error::LineParse(input.to_owned(), if len == 0 { 0 } else { len - 1 }));\n    }\n    apply_substitution(\n        substitution_data,\n        &substitution_name.drain(..).collect::<String>(),\n        &mut output,\n    );\n    Ok(output)\n}"", ""code_context"": ""use std::collections::HashMap;\nuse crate::errors::*;\n\n#[derive(Eq, PartialEq)]\nenum SubstitutionMode {\n    None,\n    Block,\n    EscapedBlock,\n}\n\nfn apply_substitution(\n    substitution_data: &mut HashMap<String, Option<String>>,\n    substitution_name: &str,\n    output: &mut String,\n) {\n    if let Ok(env_val) = std::env::var(substitution_name) {\n        output.push_str(&env_val);\n    } else if let Some(stored) = substitution_data.get(substitution_name).and_then(|v| v.as_ref()) {\n        output.push_str(stored);\n    }\n}""}","{""explanation"": ""`parse_value` interprets the right‑hand side of a `.env` line. It handles single and double quotes, escape sequences, and variable substitution (`$VAR` or `${VAR}`). The function walks the input character by character, maintaining state flags, builds the resulting string, and applies substitutions from the environment or previously parsed values.""}",code_explanation
bytesize,"{""code_context"": ""pub const KIB: u64 = 1_024;\n\npub struct ByteSize(pub u64);"", ""code_to_test"": ""impl ByteSize {\n    pub const fn kib(size: u64) -> ByteSize {\n        ByteSize(size * KIB)\n    }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn test_to_string_as() {\n    assert_eq!(\""215 B\"", ByteSize::b(215));\n    assert_eq!(\""1.0 KiB\"", ByteSize::kib(1));\n    assert_eq!(\""1.0 kB\"", ByteSize::kib(1));\n    assert_eq!(\""293.9 KiB\"", ByteSize::kb(301));\n    assert_eq!(\""301.0 kB\"", ByteSize::kb(301));\n    assert_eq!(\""1.0 MiB\"", ByteSize::mib(1));\n    assert_eq!(\""1.0 MB\"", ByteSize::mib(1));\n    assert_eq!(\""1.9 GiB\"", ByteSize::mib(1907));\n    assert_eq!(\""2.0 GB\"", ByteSize::mib(1908));\n    assert_eq!(\""399.6 MiB\"", ByteSize::mb(419));\n    assert_eq!(\""419.0 MB\"", ByteSize::mb(419));\n    assert_eq!(\""482.4 GiB\"", ByteSize::gb(518));\n    assert_eq!(\""518.0 GB\"", ByteSize::gb(518));\n    assert_eq!(\""741.2 TiB\"", ByteSize::tb(815));\n    assert_eq!(\""815.0 TB\"", ByteSize::tb(815));\n    assert_eq!(\""540.9 PiB\"", ByteSize::pb(609));\n    assert_eq!(\""609.0 PB\"", ByteSize::pb(609));\n}""]}",test_generation
bytesize,"{""code_context"": ""pub const KB: u64 = 1_000;\npub const MB: u64 = 1_000_000;\npub const GB: u64 = 1_000_000_000;\npub const TB: u64 = 1_000_000_000_000;\npub const PB: u64 = 1_000_000_000_000_000;\n\npub const KIB: u64 = 1_024;\npub const MIB: u64 = 1_048_576;\npub const GIB: u64 = 1_073_741_824;\npub const TIB: u64 = 1_099_511_627_776;\npub const PIB: u64 = 1_125_899_906_842_624;\n\npub struct ByteSize(pub u64);"", ""code_to_test"": ""impl core::str::FromStr for ByteSize {\n    type Err = alloc::string::String;\n\n    fn from_str(value: &str) -> Result<Self, Self::Err> {\n        if let Ok(v) = value.parse::<u64>() {\n            return Ok(Self(v));\n        }\n        let number = take_while(value, |c| c.is_ascii_digit() || c == '.');\n        match number.parse::<f64>() {\n            Ok(v) => {\n                let suffix = skip_while(&value[number.len()..], char::is_whitespace);\n                match suffix.parse::<Unit>() {\n                    Ok(u) => Ok(Self((v * u) as u64)),\n                    Err(error) => Err(alloc::format!(\n                        \""couldn't parse {:?} into a known SI unit, {}\"",\n                        suffix, error\n                    )),\n                }\n            }\n            Err(error) => Err(alloc::format!(\n                \""couldn't parse {:?} into a ByteSize, {}\"",\n                value, error\n            )),\n        }\n    }\n}\n\nfn take_while<P>(s: &str, mut predicate: P) -> &str\nwhere\n    P: FnMut(char) -> bool,\n{\n    let offset = s\n        .chars()\n        .take_while(|ch| predicate(*ch))\n        .map(|ch| ch.len_utf8())\n        .sum();\n    &s[..offset]\n}\n\nfn skip_while<P>(s: &str, mut predicate: P) -> &str\nwhere\n    P: FnMut(char) -> bool,\n{\n    let offset: usize = s\n        .chars()\n        .skip_while(|ch| predicate(*ch))\n        .map(|ch| ch.len_utf8())\n        .sum();\n    &s[(s.len() - offset)..]\n}\n\nenum Unit {\n    Byte,\n    KiloByte,\n    MegaByte,\n    GigaByte,\n    TeraByte,\n    PetaByte,\n    KibiByte,\n    MebiByte,\n    GibiByte,\n    TebiByte,\n    PebiByte,\n}\n\nimpl Unit {\n    fn factor(&self) -> u64 {\n        match self {\n            Self::Byte => 1,\n            Self::KiloByte => KB,\n            Self::MegaByte => MB,\n            Self::GigaByte => GB,\n            Self::TeraByte => TB,\n            Self::PetaByte => PB,\n            Self::KibiByte => KIB,\n            Self::MebiByte => MIB,\n            Self::GibiByte => GIB,\n            Self::TebiByte => TIB,\n            Self::PebiByte => PIB,\n        }\n    }\n}\n\nimpl core::str::FromStr for Unit {\n    type Err = alloc::string::String;\n\n    fn from_str(unit: &str) -> Result<Self, Self::Err> {\n        match unit.to_lowercase().as_str() {\n            \""b\"" => Ok(Self::Byte),\n            \""k\"" | \""kb\"" => Ok(Self::KiloByte),\n            \""m\"" | \""mb\"" => Ok(Self::MegaByte),\n            \""g\"" | \""gb\"" => Ok(Self::GigaByte),\n            \""t\"" | \""tb\"" => Ok(Self::TeraByte),\n            \""p\"" | \""pb\"" => Ok(Self::PetaByte),\n            \""ki\"" | \""kib\"" => Ok(Self::KibiByte),\n            \""mi\"" | \""mib\"" => Ok(Self::MebiByte),\n            \""gi\"" | \""gib\"" => Ok(Self::GibiByte),\n            \""ti\"" | \""tib\"" => Ok(Self::TebiByte),\n            \""pi\"" | \""pib\"" => Ok(Self::PebiByte),\n            _ => Err(alloc::format!(\""couldn't parse unit of {:?}\"", unit)),\n        }\n    }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn when_ok() {\n    fn parse(s: &str) -> u64 {\n        s.parse::<ByteSize>().unwrap().0\n    }\n\n    assert_eq!(\""0\"".parse::<ByteSize>().unwrap().0, 0);\n    assert_eq!(parse(\""0\""), 0);\n    assert_eq!(parse(\""500\""), 500);\n    assert_eq!(parse(\""1K\""), Unit::KiloByte * 1);\n    assert_eq!(parse(\""1Ki\""), Unit::KibiByte * 1);\n    assert_eq!(parse(\""1.5Ki\""), (1.5 * Unit::KibiByte) as u64);\n    assert_eq!(parse(\""1KiB\""), 1 * Unit::KibiByte);\n    assert_eq!(parse(\""1.5KiB\""), (1.5 * Unit::KibiByte) as u64);\n    assert_eq!(parse(\""3 MB\""), Unit::MegaByte * 3);\n    assert_eq!(parse(\""4 MiB\""), Unit::MebiByte * 4);\n    assert_eq!(parse(\""6 GB\""), 6 * Unit::GigaByte);\n    assert_eq!(parse(\""4 GiB\""), 4 * Unit::GibiByte);\n    assert_eq!(parse(\""88TB\""), 88 * Unit::TeraByte);\n    assert_eq!(parse(\""521TiB\""), 521 * Unit::TebiByte);\n    assert_eq!(parse(\""8 PB\""), 8 * Unit::PetaByte);\n    assert_eq!(parse(\""8P\""), 8 * Unit::PetaByte);\n    assert_eq!(parse(\""12 PiB\""), 12 * Unit::PebiByte);\n}"", ""#[test]\nfn when_err() {\n    fn parse(s: &str) -> Result<ByteSize, String> {\n        s.parse::<ByteSize>()\n    }\n\n    assert!(parse(\""\"").is_err());\n    assert!(parse(\""a124GB\"").is_err());\n    assert!(parse(\""1.3 42.0 B\"").is_err());\n    assert!(parse(\""1.3 ... B\"").is_err());\n    assert!(parse(\""1 000 B\"").is_err());\n}"", ""#[test]\nfn to_and_from_str() {\n    fn parse(s: &str) -> u64 {\n        s.parse::<ByteSize>().unwrap().0\n    }\n\n    assert_eq!(parse(&parse(\""128GB\"").to_string()), 128 * Unit::GigaByte);\n    assert_eq!(\n        parse(&ByteSize(parse(\""128.000 GiB\"")).to_string()),\n        128 * Unit::GibiByte,\n    );\n}""]}",test_generation
bytesize,"{""code_context"": ""#[derive(Debug, Clone)]\npub struct Display {\n    pub(crate) byte_size: ByteSize,\n    pub(crate) format: Format,\n}\n\n#[derive(Debug, Clone, Copy)]\npub enum Format {\n    Iec,\n    IecShort,\n    Si,\n    SiShort,\n}\n\npub struct ByteSize(pub u64);\n\npub const KIB: u64 = 1_024;"", ""code_to_test"": ""impl ByteSize {\n    pub fn display(&self) -> Display {\n        Display {\n            byte_size: *self,\n            format: Format::Iec,\n        }\n    }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn test_display() {\n    assert_eq!(\""215 B\"", ByteSize::b(215));\n    assert_eq!(\""1.0 KiB\"", ByteSize::kib(1));\n    assert_eq!(\""301.0 KiB\"", ByteSize::kib(301));\n    assert_eq!(\""419.0 MiB\"", ByteSize::mib(419));\n    assert_eq!(\""518.0 GiB\"", ByteSize::gib(518));\n    assert_eq!(\""815.0 TiB\"", ByteSize::tib(815));\n    assert_eq!(\""609.0 PiB\"", ByteSize::pib(609));\n}""]}",test_generation
parquet-variant-json,"{""code"": ""pub fn json_to_variant(json: &str, builder: &mut VariantBuilder) -> Result<(), ArrowError> {\\n    let json: Value = serde_json::from_str(json)\\n        .map_err(|e| ArrowError::InvalidArgumentError(format!(\\\""JSON format error: {e}\\\"")))?;\\n    build_json(&json, builder)?;\\n    Ok(())\\n}"", ""code_context"": ""use arrow_schema::ArrowError;\\nuse parquet_variant::VariantBuilder;\\nuse serde_json::Value;\\n\\nfn build_json(json: &Value, builder: &mut VariantBuilder) -> Result<(), ArrowError> {\\n    append_json(json, builder)?;\\n    Ok(())\\n}\\n\\nfn append_json<'m, 'v>(\\n    json: &'v Value,\\n    builder: &mut impl parquet_variant::VariantBuilderExt<'m, 'v>,\\n) -> Result<(), ArrowError> {\\n    match json {\\n        serde_json::Value::Null => builder.append_value(parquet_variant::Variant::Null),\\n        serde_json::Value::Bool(b) => builder.append_value(*b),\\n        serde_json::Value::Number(n) => {\\n            builder.append_value(variant_from_number(n)?);\\n        }\\n        serde_json::Value::String(s) => builder.append_value(s.as_str()),\\n        serde_json::Value::Array(arr) => {\\n            let mut list_builder = builder.new_list();\\n            for val in arr {\\n                append_json(val, &mut list_builder)?;\\n            }\\n            list_builder.finish();\\n        }\\n        serde_json::Value::Object(obj) => {\\n            let mut obj_builder = builder.new_object();\\n            for (key, value) in obj.iter() {\\n                let mut field_builder = ObjectFieldBuilder {\\n                    key,\\n                    builder: &mut obj_builder,\\n                };\\n                append_json(value, &mut field_builder)?;\\n            }\\n            obj_builder.finish()?;\\n        }\\n    };\\n    Ok(())\\n}\\n\\nfn variant_from_number<'m, 'v>(n: &serde_json::Number) -> Result<parquet_variant::Variant<'m, 'v>, ArrowError> {\\n    if let Some(i) = n.as_i64() {\\n        if i as i8 as i64 == i {\\n            Ok((i as i8).into())\\n        } else if i as i16 as i64 == i {\\n            Ok((i as i16).into())\\n        } else if i as i32 as i64 == i {\\n            Ok((i as i32).into())\\n        } else {\\n            Ok(i.into())\\n        }\\n    } else {\\n        match n.as_f64() {\\n            Some(f) => Ok(f.into()),\\n            None => Err(ArrowError::InvalidArgumentError(format!(\\\""Failed to parse {n} as number\\\""))),\\n        }\\n    }\\n}\\n\\nstruct ObjectFieldBuilder<'o, 'v, 's> {\\n    key: &'s str,\\n    builder: &'o mut parquet_variant::ObjectBuilder<'v>,\\n}\\n\\nimpl<'m, 'v> parquet_variant::VariantBuilderExt<'m, 'v> for ObjectFieldBuilder<'_, '_, '_> {\\n    fn append_value(&mut self, value: impl Into<parquet_variant::Variant<'m, 'v>>) {\\n        self.builder.insert(self.key, value);\\n    }\\n\\n    fn new_list(&mut self) -> parquet_variant::ListBuilder {\\n        self.builder.new_list(self.key)\\n    }\\n\\n    fn new_object(&mut self) -> parquet_variant::ObjectBuilder {\\n        self.builder.new_object(self.key)\\n    }\\n}""}","{""explanation"": ""The function parses a JSON string into a `serde_json::Value`, handling any parsing error by converting it into an `ArrowError`. It then forwards the parsed value to `build_json`, which recursively walks the JSON structure and populates the provided `VariantBuilder` with the corresponding Parquet Variant representation. Finally it returns `Ok(())` on success.""}",code_explanation
parquet-variant-json,"{""code"": ""pub fn variant_to_json(json_buffer: &mut impl Write, variant: &Variant) -> Result<(), ArrowError> {\\n    match variant {\\n        Variant::Null => write!(json_buffer, \\\""null\\\"")?,\\n        Variant::BooleanTrue => write!(json_buffer, \\\""true\\\"")?,\\n        Variant::BooleanFalse => write!(json_buffer, \\\""false\\\"")?,\\n        Variant::Int8(i) => write!(json_buffer, \\\""{i}\\\"")?,\\n        Variant::Int16(i) => write!(json_buffer, \\\""{i}\\\"")?,\\n        Variant::Int32(i) => write!(json_buffer, \\\""{i}\\\"")?,\\n        Variant::Int64(i) => write!(json_buffer, \\\""{i}\\\"")?,\\n        Variant::Float(f) => write!(json_buffer, \\\""{f}\\\"")?,\\n        Variant::Double(f) => write!(json_buffer, \\\""{f}\\\"")?,\\n        Variant::Decimal4(decimal) => write!(json_buffer, \\\""{decimal}\\\"")?,\\n        Variant::Decimal8(decimal) => write!(json_buffer, \\\""{decimal}\\\"")?,\\n        Variant::Decimal16(decimal) => write!(json_buffer, \\\""{decimal}\\\"")?,\\n        Variant::Date(date) => write!(json_buffer, \\\""\\\""{}\\\""\\\"", format_date_string(date))?,\\n        Variant::TimestampMicros(ts) => write!(json_buffer, \\\""\\\""{}\\\""\\\"", ts.to_rfc3339())?,\\n        Variant::TimestampNtzMicros(ts) => {\\n            write!(json_buffer, \\\""\\\""{}\\\""\\\"", format_timestamp_ntz_string(ts))?\\n        }\\n        Variant::Binary(bytes) => {\\n            let base64_str = format_binary_base64(bytes);\\n            let json_str = serde_json::to_string(&base64_str).map_err(|e| {\\n                ArrowError::InvalidArgumentError(format!(\\\""JSON encoding error: {e}\\\""))\\n            })?;\\n            write!(json_buffer, \\\""{json_str}\\\"")?\\n        }\\n        Variant::String(s) => {\\n            let json_str = serde_json::to_string(s).map_err(|e| {\\n                ArrowError::InvalidArgumentError(format!(\\\""JSON encoding error: {e}\\\""))\\n            })?;\\n            write!(json_buffer, \\\""{json_str}\\\"")?\\n        }\\n        Variant::ShortString(s) => {\\n            let json_str = serde_json::to_string(s.as_str()).map_err(|e| {\\n                ArrowError::InvalidArgumentError(format!(\\\""JSON encoding error: {e}\\\""))\\n            })?;\\n            write!(json_buffer, \\\""{json_str}\\\"")?\\n        }\\n        Variant::Object(obj) => {\\n            convert_object_to_json(json_buffer, obj)?;\\n        }\\n        Variant::List(arr) => {\\n            convert_array_to_json(json_buffer, arr)?;\\n        }\\n    }\\n    Ok(())\\n}"", ""code_context"": ""use arrow_schema::ArrowError;\\nuse base64::{engine::general_purpose, Engine as _};\\nuse serde_json::Value;\\nuse std::io::Write;\\nuse parquet_variant::{Variant, VariantList, VariantObject};\\n\\nfn format_date_string(date: &chrono::NaiveDate) -> String {\\n    date.format(\\\""%Y-%m-%d\\\"").to_string()\\n}\\n\\nfn format_timestamp_ntz_string(ts: &chrono::NaiveDateTime) -> String {\\n    ts.format(\\\""%Y-%m-%dT%H:%M:%S%.6f\\\"").to_string()\\n}\\n\\nfn format_binary_base64(bytes: &[u8]) -> String {\\n    general_purpose::STANDARD.encode(bytes)\\n}\\n\\nfn convert_object_to_json(buffer: &mut impl Write, obj: &VariantObject) -> Result<(), ArrowError> {\\n    write!(buffer, \\\""{\\\"")?;\\n    let mut first = true;\\n    for (key, value) in obj.iter() {\\n        if !first {\\n            write!(buffer, \\\"",\\\"")?;\\n        }\\n        first = false;\\n        let json_key = serde_json::to_string(key).map_err(|e| ArrowError::InvalidArgumentError(format!(\\\""JSON key encoding error: {e}\\\"")))?;\\n        write!(buffer, \\\""{json_key}:\\\"")?;\\n        variant_to_json(buffer, &value)?;\\n    }\\n    write!(buffer, \\\""}\\\"")?;\\n    Ok(())\\n}\\n\\nfn convert_array_to_json(buffer: &mut impl Write, arr: &VariantList) -> Result<(), ArrowError> {\\n    write!(buffer, \\\""[\\\"")?;\\n    let mut first = true;\\n    for element in arr.iter() {\\n        if !first {\\n            write!(buffer, \\\"",\\\"")?;\\n        }\\n        first = false;\\n        variant_to_json(buffer, &element)?;\\n    }\\n    write!(buffer, \\\""]\\\"")?;\\n    Ok(())\\n}""}","{""explanation"": ""The function serialises a `Variant` value into JSON by matching on each possible variant case. Primitive scalars are written directly, dates and timestamps are formatted as strings, binary data is base64‑encoded, and strings are escaped using `serde_json`. For complex types (`Object` and `List`) it delegates to helper functions that recursively emit JSON objects or arrays. All writes go to any `Write` implementation, making the routine suitable for streaming output.""}",code_explanation
parquet-variant-json,"{""code"": ""fn append_json<'m, 'v>(\\n    json: &'v Value,\\n    builder: &mut impl VariantBuilderExt<'m, 'v>,\\n) -> Result<(), ArrowError> {\\n    match json {\\n        Value::Null => builder.append_value(Variant::Null),\\n        Value::Bool(b) => builder.append_value(*b),\\n        Value::Number(n) => {\\n            builder.append_value(variant_from_number(n)?);\\n        }\\n        Value::String(s) => builder.append_value(s.as_str()),\\n        Value::Array(arr) => {\\n            let mut list_builder = builder.new_list();\\n            for val in arr {\\n                append_json(val, &mut list_builder)?;\\n            }\\n            list_builder.finish();\\n        }\\n        Value::Object(obj) => {\\n            let mut obj_builder = builder.new_object();\\n            for (key, value) in obj.iter() {\\n                let mut field_builder = ObjectFieldBuilder {\\n                    key,\\n                    builder: &mut obj_builder,\\n                };\\n                append_json(value, &mut field_builder)?;\\n            }\\n            obj_builder.finish()?;\\n        }\\n    };\\n    Ok(())\\n}"", ""code_context"": ""use arrow_schema::ArrowError;\\nuse parquet_variant::{ListBuilder, ObjectBuilder, Variant, VariantBuilderExt};\\nuse serde_json::{Number, Value};\\n\\nfn variant_from_number<'m, 'v>(n: &Number) -> Result<Variant<'m, 'v>, ArrowError> {\\n    if let Some(i) = n.as_i64() {\\n        if i as i8 as i64 == i {\\n            Ok((i as i8).into())\\n        } else if i as i16 as i64 == i {\\n            Ok((i as i16).into())\\n        } else if i as i32 as i64 == i {\\n            Ok((i as i32).into())\\n        } else {\\n            Ok(i.into())\\n        }\\n    } else {\\n        match n.as_f64() {\\n            Some(f) => Ok(f.into()),\\n            None => Err(ArrowError::InvalidArgumentError(format!(\\\""Failed to parse {n} as number\\\""))),\\n        }\\n    }\\n}\\n\\nstruct ObjectFieldBuilder<'o, 'v, 's> {\\n    key: &'s str,\\n    builder: &'o mut ObjectBuilder<'v>,\\n}\\n\\nimpl<'m, 'v> VariantBuilderExt<'m, 'v> for ObjectFieldBuilder<'_, '_, '_> {\\n    fn append_value(&mut self, value: impl Into<Variant<'m, 'v>>) {\\n        self.builder.insert(self.key, value);\\n    }\\n\\n    fn new_list(&mut self) -> ListBuilder {\\n        self.builder.new_list(self.key)\\n    }\\n\\n    fn new_object(&mut self) -> ObjectBuilder {\\n        self.builder.new_object(self.key)\\n    }\\n}""}","{""explanation"": ""`append_json` recursively walks a `serde_json::Value` and uses a `VariantBuilderExt` to construct the corresponding Parquet Variant. Scalars are directly appended, arrays create a new list builder and recurse for each element, and objects create a new object builder. For each object field a temporary `ObjectFieldBuilder` forwards the key to the underlying object builder, allowing nested structures to be built correctly.""}",code_explanation
aws-credential-types,"{""code"": ""let __placeholder__ = provider.provide_credentials().await.unwrap();"", ""code_context"": ""use std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\nuse std::time::SystemTime;\n\npub struct Credentials {\n    access_key_id: String,\n    secret_access_key: String,\n    session_token: Option<String>,\n    expires_after: Option<SystemTime>,\n    provider_name: &'static str,\n}\n\nimpl Credentials {\n    pub fn new(\n        access_key_id: impl Into<String>,\n        secret_access_key: impl Into<String>,\n        session_token: Option<String>,\n        expires_after: Option<SystemTime>,\n        provider_name: &'static str,\n    ) -> Self {\n        Self {\n            access_key_id: access_key_id.into(),\n            secret_access_key: secret_access_key.into(),\n            session_token,\n            expires_after,\n            provider_name,\n        }\n    }\n}\n\ntype Result<T> = std::result::Result<T, ()>;\n\npub struct ProvideCredentialsFuture<'a>(Pin<Box<dyn Future<Output = Result<Credentials> > + Send + 'a>>);\n\nimpl<'a> Future for ProvideCredentialsFuture<'a> {\n    type Output = Result<Credentials>;\n    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        self.get_mut().0.as_mut().poll(cx)\n    }\n}\n\npub trait ProvideCredentials {\n    fn provide_credentials<'a>(&'a self) -> ProvideCredentialsFuture<'a>;\n}\n\npub struct DummyProvider;\n\nimpl ProvideCredentials for DummyProvider {\n    fn provide_credentials<'a>(&'a self) -> ProvideCredentialsFuture<'a> {\n        ProvideCredentialsFuture(Box::pin(async { Ok(Credentials::new(\""AKID\"", \""SECRET\"", None, None, \""test\"")) }))\n    }\n}""}","{""variable_name"": ""aws_credentials""}",variable_naming
aws-credential-types,"{""code"": ""let __placeholder__ = credentials.account_id().unwrap().as_str();"", ""code_context"": ""use std::time::SystemTime;\n\npub struct AccountId {\n    inner: String,\n}\n\nimpl AccountId {\n    pub fn as_str(&self) -> &str {\n        &self.inner\n    }\n}\n\npub struct Credentials {\n    access_key_id: String,\n    secret_access_key: String,\n    session_token: Option<String>,\n    expires_after: Option<SystemTime>,\n    provider_name: &'static str,\n    account_id: Option<AccountId>,\n}\n\nimpl Credentials {\n    pub fn new(\n        access_key_id: impl Into<String>,\n        secret_access_key: impl Into<String>,\n        session_token: Option<String>,\n        expires_after: Option<SystemTime>,\n        provider_name: &'static str,\n    ) -> Self {\n        Self {\n            access_key_id: access_key_id.into(),\n            secret_access_key: secret_access_key.into(),\n            session_token,\n            expires_after,\n            provider_name,\n            account_id: None,\n        }\n    }\n\n    pub fn account_id(&self) -> Option<&AccountId> {\n        self.account_id.as_ref()\n    }\n}""}","{""variable_name"": ""account_id""}",variable_naming
aws-credential-types,"{""code"": ""let __placeholder__ = token_provider.provide_token().await.unwrap().token();"", ""code_context"": ""use std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\nuse std::time::SystemTime;\n\npub struct Token {\n    token: String,\n    expires_after: Option<SystemTime>,\n}\n\nimpl Token {\n    pub fn token(&self) -> &str {\n        &self.token\n    }\n}\n\ntype Result<T> = std::result::Result<T, ()>;\n\npub struct ProvideTokenFuture<'a>(Pin<Box<dyn Future<Output = Result<Token>> + Send + 'a>>);\n\nimpl<'a> Future for ProvideTokenFuture<'a> {\n    type Output = Result<Token>;\n    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        self.get_mut().0.as_mut().poll(cx)\n    }\n}\n\npub trait ProvideToken {\n    fn provide_token<'a>(&'a self) -> ProvideTokenFuture<'a>;\n}\n\npub struct DummyTokenProvider;\n\nimpl ProvideToken for DummyTokenProvider {\n    fn provide_token<'a>(&'a self) -> ProvideTokenFuture<'a> {\n        ProvideTokenFuture(Box::pin(async { Ok(Token { token: \""example-token\"".to_string(), expires_after: None }) }))\n    }\n}""}","{""variable_name"": ""access_token""}",variable_naming
aws-credential-types,"{""code"": ""let __placeholder__ = CredentialsBuilder::default().access_key_id(\""AKID\"").secret_access_key(\""SECRET\"").provider_name(\""test\"").build();"", ""code_context"": ""use std::time::SystemTime;\n\npub struct Credentials {\n    access_key_id: String,\n    secret_access_key: String,\n    session_token: Option<String>,\n    expires_after: Option<SystemTime>,\n    provider_name: &'static str,\n}\n\nimpl Credentials {\n    pub fn new(\n        access_key_id: impl Into<String>,\n        secret_access_key: impl Into<String>,\n        session_token: Option<String>,\n        expires_after: Option<SystemTime>,\n        provider_name: &'static str,\n    ) -> Self {\n        Self {\n            access_key_id: access_key_id.into(),\n            secret_access_key: secret_access_key.into(),\n            session_token,\n            expires_after,\n            provider_name,\n        }\n    }\n}\n\npub struct CredentialsBuilder {\n    access_key_id: Option<String>,\n    secret_access_key: Option<String>,\n    provider_name: Option<&'static str>,\n}\n\nimpl CredentialsBuilder {\n    pub fn default() -> Self {\n        Self { access_key_id: None, secret_access_key: None, provider_name: None }\n    }\n\n    pub fn access_key_id(mut self, id: impl Into<String>) -> Self {\n        self.access_key_id = Some(id.into());\n        self\n    }\n\n    pub fn secret_access_key(mut self, key: impl Into<String>) -> Self {\n        self.secret_access_key = Some(key.into());\n        self\n    }\n\n    pub fn provider_name(mut self, name: &'static str) -> Self {\n        self.provider_name = Some(name);\n        self\n    }\n\n    pub fn build(self) -> Credentials {\n        Credentials::new(\n            self.access_key_id.expect(\""access_key_id required\""),\n            self.secret_access_key.expect(\""secret_access_key required\""),\n            None,\n            None,\n            self.provider_name.expect(\""provider_name required\""),\n        )\n    }\n}""}","{""variable_name"": ""builder""}",variable_naming
aws-credential-types,"{""code"": ""let __placeholder__ = SharedCredentialsProvider::new(Credentials::new(\""AKID\"", \""SECRET\"", None, None, \""test\""));"", ""code_context"": ""use std::time::SystemTime;\n\npub struct Credentials {\n    access_key_id: String,\n    secret_access_key: String,\n    session_token: Option<String>,\n    expires_after: Option<SystemTime>,\n    provider_name: &'static str,\n}\n\nimpl Credentials {\n    pub fn new(\n        access_key_id: impl Into<String>,\n        secret_access_key: impl Into<String>,\n        session_token: Option<String>,\n        expires_after: Option<SystemTime>,\n        provider_name: &'static str,\n    ) -> Self {\n        Self {\n            access_key_id: access_key_id.into(),\n            secret_access_key: secret_access_key.into(),\n            session_token,\n            expires_after,\n            provider_name,\n        }\n    }\n}\n\npub struct SharedCredentialsProvider {\n    inner: Credentials,\n}\n\nimpl SharedCredentialsProvider {\n    pub fn new(creds: Credentials) -> Self {\n        Self { inner: creds }\n    }\n}""}","{""variable_name"": ""shared_provider""}",variable_naming
lz4,"{""code"": ""pub fn check_error(code: LZ4FErrorCode) -> Result<usize, Error> {\n    unsafe {\n        if LZ4F_isError(code) != 0 {\n            let error_name = LZ4F_getErrorName(code);\n            return Err(Error::new(\n                ErrorKind::Other,\n                LZ4Error(\n                    str::from_utf8(CStr::from_ptr(error_name).to_bytes())\n                        .unwrap()\n                        .to_string(),\n                ),\n            ));\n        }\n    }\n    Ok(code as usize)\n}"", ""code_context"": ""use std::ffi::CStr;\nuse std::io::{Error, ErrorKind};\nuse std::str;\n\npub struct LZ4Error(String);\n\nuse crate::liblz4::*;""}","{""summary"": ""Checks an LZ4F error code and returns an error with a descriptive message if it indicates failure.""}",code_summarization
lz4,"{""code"": ""mod block {\n    pub fn compress(src: &[u8], mode: Option<CompressionMode>, prepend_size: bool) -> Result<Vec<u8>> {\n        let compress_bound: i32 = unsafe { LZ4_compressBound(src.len() as i32) };\n        if src.len() > (i32::max_value() as usize) || compress_bound <= 0 {\n            return Err(Error::new(\n                ErrorKind::InvalidInput,\n                \""Compression input too long.\"",\n            ));\n        }\n        let mut compressed: Vec<u8> = vec![\n            0;\n            (if prepend_size {\n                compress_bound + 4\n            } else {\n                compress_bound\n            }) as usize\n        ];\n        let dec_size = compress_to_buffer(src, mode, prepend_size, &mut compressed)?;\n        compressed.truncate(dec_size as usize);\n        Ok(compressed)\n    }\n}"", ""code_context"": ""use std::io::{Error, ErrorKind, Result};\n\npub enum CompressionMode {\n    HIGHCOMPRESSION(i32),\n    FAST(i32),\n    DEFAULT,\n}\n\nuse crate::liblz4::*;""}","{""summary"": ""Compresses a byte slice using the specified compression mode and optionally prepends the original size.""}",code_summarization
lz4,"{""code"": ""mod block {\n    pub fn decompress(src: &[u8], uncompressed_size: Option<i32>) -> Result<Vec<u8>> {\n        let size = get_decompressed_size(src, uncompressed_size)?;\n        let mut buffer = vec![0u8; size];\n        let sz = decompress_to_buffer(src, uncompressed_size, &mut buffer)?;\n        buffer.truncate(sz);\n        Ok(buffer)\n    }\n}"", ""code_context"": ""use std::io::{Error, ErrorKind, Result};\n\nfn get_decompressed_size(src: &[u8], uncompressed_size: Option<i32>) -> Result<usize> {\n    let size;\n    if let Some(s) = uncompressed_size {\n        size = s;\n    } else {\n        if src.len() < 4 {\n            return Err(Error::new(\n                ErrorKind::InvalidInput,\n                \""Source buffer must at least contain size prefix.\"",\n            ));\n        }\n        size = (src[0] as i32)\n            | (src[1] as i32) << 8\n            | (src[2] as i32) << 16\n            | (src[3] as i32) << 24;\n    }\n    if size < 0 {\n        return Err(Error::new(\n            ErrorKind::InvalidInput,\n            if uncompressed_size.is_some() {\n                \""Size parameter must not be negative.\""\n            } else {\n                \""Parsed size prefix in buffer must not be negative.\""\n            },\n        ));\n    }\n    if unsafe { LZ4_compressBound(size) } <= 0 {\n        return Err(Error::new(ErrorKind::InvalidInput, \""Given size parameter is too big\""));\n    }\n    Ok(size as usize)\n}\n\nuse crate::liblz4::*;""}","{""summary"": ""Decompresses a byte slice, optionally reading the expected size from the buffer prefix.""}",code_summarization
lz4,"{""code"": ""impl EncoderBuilder {\n    pub fn new() -> Self {\n        EncoderBuilder {\n            block_size: BlockSize::Default,\n            block_mode: BlockMode::Linked,\n            checksum: ContentChecksum::ChecksumEnabled,\n            block_checksum: BlockChecksum::BlockChecksumEnabled,\n            level: 0,\n            auto_flush: false,\n            favor_dec_speed: false,\n            content_size: 0,\n        }\n    }\n}"", ""code_context"": ""use crate::liblz4::*;""}","{""summary"": ""Creates a new EncoderBuilder with default compression settings.""}",code_summarization
castaway,"{""code_before"": ""fn try_cast(&self, value: &'a mut T) -> Result<&'a mut U, &'a mut T> {\n    if type_eq::<T, U>() {\n        Ok(unsafe { &mut *(value as *mut T as *mut U) })\n    } else {\n        Err(value)\n    }\n}"", ""code_context"": ""use core::marker::PhantomData;\nuse crate::{lifetime_free::LifetimeFree, utils::{transmute_unchecked, type_eq}};\n\npub struct CastToken<T: ?Sized>(PhantomData<T>);\nimpl<T: ?Sized> CastToken<T> {\n    pub const fn of() -> Self { Self(PhantomData) }\n}\n\npub trait TryCastMut<'a, T: 'static, U: 'static> {\n    fn try_cast(&self, value: &'a mut T) -> Result<&'a mut U, &'a mut T>;\n}\n\nimpl<'a, T: 'static, U: 'static> TryCastMut<'a, T, U> for &&(CastToken<&'a mut T>, CastToken<&'a mut U>) {}""}","{""rationale"": ""Replaces the manual pointer cast with the existing `transmute_unchecked` helper, making the unsafe block clearer and reducing the chance of mistakes."", ""code_after"": ""fn try_cast(&self, value: &'a mut T) -> Result<&'a mut U, &'a mut T> {\n    if type_eq::<T, U>() {\n        Ok(unsafe { transmute_unchecked::<&mut T, &mut U>(value) })\n    } else {\n        Err(value)\n    }\n}""}",code_refactoring
castaway,"{""code_before"": ""let result: ::core::result::Result<$T, _> = (&&&&&&&(src_token, dest_token)).try_cast(value);\nresult"", ""code_context"": ""#[macro_export]\nmacro_rules! cast {\n    ($value:expr, $T:ty) => {{\n        use $crate::internal::*;\n        let value = $value;\n        let src_token = CastToken::of_val(&value);\n        let dest_token = CastToken::<$T>::of();\n        let result: ::core::result::Result<$T, _> = (&&&&&&&(src_token, dest_token)).try_cast(value);\n        result\n    }};\n    ($value:expr) => { $crate::cast!($value, _) };\n}""}","{""rationale"": ""Reduces the excessive chain of reference operators to a single pair, improving readability and matching the trait implementation signature."", ""code_after"": ""let result: ::core::result::Result<$T, _> = (&src_token, &dest_token).try_cast(value);\nresult""}",code_refactoring
castaway,"{""code_before"": ""if let Ok(string) = cast!(self, &String) {\n    string.to_owned()\n} else {\n    format!(\""{}\"", self)\n}"", ""code_context"": ""use std::fmt::Display;\nuse castaway::cast;\n\npub trait FastToString {\n    fn fast_to_string(&self) -> String;\n}\n\nimpl<T: Display> FastToString for T {\n    fn fast_to_string(&self) -> String {\n        if let Ok(string) = cast!(self, &String) {\n            string.to_owned()\n        } else {\n            format!(\""{}\"", self)\n        }\n    }\n}""}","{""rationale"": ""Uses a `match` expression to handle both outcomes explicitly, making the control flow clearer and avoiding the partial `if let` pattern."", ""code_after"": ""match cast!(self, &String) {\n    Ok(string) => string.to_owned(),\n    Err(_) => format!(\""{}\"", self),\n}""}",code_refactoring
castaway,"{""code_before"": ""fn try_cast(&self, value: &'a mut T) -> Result<&'a mut U, &'a mut T> {\n    if type_eq_non_static::<T, U>() {\n        Ok(unsafe { transmute_unchecked::<&mut T, &mut U>(value) })\n    } else {\n        Err(value)\n    }\n}"", ""code_context"": ""pub(crate) fn type_eq<T: 'static, U: 'static>() -> bool { unimplemented!() }\npub(crate) fn type_eq_non_static<T: ?Sized, U: ?Sized>() -> bool { unimplemented!() }\npub(crate) unsafe fn transmute_unchecked<T, U>(value: T) -> U { unimplemented!() }\nuse crate::utils::{type_eq, type_eq_non_static, transmute_unchecked};\n\npub struct CastToken<T: ?Sized>(core::marker::PhantomData<T>);\nimpl<T: ?Sized> CastToken<T> { pub const fn of() -> Self { Self(core::marker::PhantomData) } }""}","{""rationale"": ""Switches to the stricter `type_eq` which requires `'static` types, providing better safety guarantees for lifetime‑free casts."", ""code_after"": ""fn try_cast(&self, value: &'a mut T) -> Result<&'a mut U, &'a mut T> {\n    if type_eq::<T, U>() {\n        Ok(unsafe { transmute_unchecked::<&mut T, &mut U>(value) })\n    } else {\n        Err(value)\n    }\n}""}",code_refactoring
unicode-linebreak,"{""code_before"": ""for i in first {\n    for j in second.clone() {\n        pair_table[i][j] = i as u8;\n    }\n}"", ""code_context"": ""use std::ops::Range;\nconst NUM_STATES: usize = 53;\nconst NUM_CLASSES_EOT: usize = 44;\nlet first: Range<usize> = 0..NUM_STATES;\nlet second: Range<usize> = 0..NUM_CLASSES_EOT;\nlet mut pair_table: [[u8; NUM_CLASSES_EOT]; NUM_STATES] = [[0; NUM_CLASSES_EOT]; NUM_STATES];""}","{""rationale"": ""Avoids cloning the `second` iterator on every outer iteration and reduces repeated indexing of `pair_table`. Directly borrowing the row improves cache locality and eliminates unnecessary allocation of the cloned iterator."", ""code_after"": ""for i in first {\n    let row = &mut pair_table[i];\n    for j in second {\n        row[j] = i as u8;\n    }\n}""}",code_optimization
unicode-linebreak,"{""code_before"": ""let mut pair_table = [{\n    let mut row = [0; NUM_CLASSES_EOT];\n    for (i, x) in row.iter_mut().enumerate() {\n        *x = i as u8;\n    }\n    row\n}; NUM_STATES];"", ""code_context"": ""const NUM_STATES: usize = 53;\nconst NUM_CLASSES_EOT: usize = 44;\n// pair_table will be a Vec of rows, each row is an array of u8 values.\n""}","{""rationale"": ""Replaces a large fixed-size array allocation with a `Vec`. This moves the storage to the heap, preventing potential stack overflow for large `NUM_STATES` values and allowing dynamic growth if needed, while keeping the same initialization logic."", ""code_after"": ""let mut pair_table = Vec::with_capacity(NUM_STATES);\nfor _ in 0..NUM_STATES {\n    let mut row = [0; NUM_CLASSES_EOT];\n    for (i, x) in row.iter_mut().enumerate() {\n        *x = i as u8;\n    }\n    pair_table.push(row);\n}""}",code_optimization
unicode-linebreak,"{""code_before"": ""builder.set_range(0x3400..0x4DBF + 1, ID);\nbuilder.set_range(0x4E00..0x9FFF + 1, ID);\nbuilder.set_range(0x20000..0x2FFFD + 1, ID);\nbuilder.set_range(0x30000..0x3FFFD + 1, ID);\nbuilder.set_range(0x1F000..0x1FAFF + 1, ID);\nbuilder.set_range(0x1FC00..0x1FFFD + 1, ID);\nbuilder.set_range(0x20A0..0x20CF + 1, PR);"", ""code_context"": ""use std::ops::Range;\n#[derive(Copy, Clone, PartialEq, Eq, Hash)]\nenum BreakClass { ID, PR, /* other variants omitted */ }\nstruct CpTrieBuilder<T> {\n    // fields omitted for brevity\n    _marker: std::marker::PhantomData<T>,\n}\nimpl<T: Copy + PartialEq + Eq + std::hash::Hash> CpTrieBuilder<T> {\n    fn new(initial: T) -> Self { Self { _marker: std::marker::PhantomData } }\n    fn set_range(&mut self, range: Range<u32>, value: T) { /* implementation omitted */ }\n}\nlet mut builder = CpTrieBuilder::new(BreakClass::ID);""}","{""rationale"": ""Uses the inclusive range operator `..=` which is more idiomatic and eliminates the need for the `+ 1` offset. This reduces the risk of off‑by‑one errors and makes the intent of including the upper bound explicit."", ""code_after"": ""builder.set_range(0x3400..=0x4DBF, ID);\nbuilder.set_range(0x4E00..=0x9FFF, ID);\nbuilder.set_range(0x20000..=0x2FFFD, ID);\nbuilder.set_range(0x30000..=0x3FFFD, ID);\nbuilder.set_range(0x1F000..=0x1FAFF, ID);\nbuilder.set_range(0x1FC00..=0x1FFFD, ID);\nbuilder.set_range(0x20A0..=0x20CF, PR);""}",code_optimization
lz4,"{""code_context"": ""use lz4_sys::LZ4_versionNumber;"", ""code_to_test"": ""pub fn version() -> i32 {\n    unsafe { LZ4_versionNumber() }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn test_version_number() {\n    version();\n}""]}",test_generation
lz4,"{""code_context"": ""use super::liblz4::*;\n\n#[derive(Clone, Debug)]\npub struct EncoderBuilder {\n    block_size: BlockSize,\n    block_mode: BlockMode,\n    block_checksum: BlockChecksum,\n    checksum: ContentChecksum,\n    level: u32,\n    auto_flush: bool,\n    favor_dec_speed: bool,\n    content_size: u64,\n}"", ""code_to_test"": ""impl EncoderBuilder {\n    pub fn new() -> Self {\n        EncoderBuilder {\n            block_size: BlockSize::Default,\n            block_mode: BlockMode::Linked,\n            checksum: ContentChecksum::ChecksumEnabled,\n            block_checksum: BlockChecksum::BlockChecksumEnabled,\n            level: 0,\n            auto_flush: false,\n            favor_dec_speed: false,\n            content_size: 0,\n        }\n    }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn test_encoder_smoke() {\n    let mut encoder = EncoderBuilder::new().level(1).build(Vec::new()).unwrap();\n    encoder.write(b\""Some \"").unwrap();\n    encoder.write(b\""data\"").unwrap();\n    let (_, result) = encoder.finish();\n    result.unwrap();\n}"", ""#[test]\nfn test_encoder_random() {\n    let mut encoder = EncoderBuilder::new().level(1).build(Vec::new()).unwrap();\n    let mut input = Vec::new();\n    let mut rnd: u32 = 42;\n    for _ in 0..1024 * 1024 {\n        input.push((rnd & 0xFF) as u8);\n        rnd = ((1664525 as u64) * (rnd as u64) + (1013904223 as u64)) as u32;\n    }\n    encoder.write(&input).unwrap();\n    let (compressed, result) = encoder.finish();\n    result.unwrap();\n\n    let mut dec = crate::decoder::Decoder::new(&compressed[..]).unwrap();\n    let mut output = Vec::new();\n    dec.read_to_end(&mut output).unwrap();\n    assert_eq!(input, output);\n}"", ""#[test]\nfn test_encoder_content_size() {\n    let mut encoder = EncoderBuilder::new()\n        .level(1)\n        .content_size(1024 * 1024)\n        .build(Vec::new())\n        .unwrap();\n    let mut input = Vec::new();\n    let mut rnd: u32 = 42;\n    for _ in 0..1024 * 1024 {\n        input.push((rnd & 0xFF) as u8);\n        rnd = ((1664525 as u64) * (rnd as u64) + (1013904223 as u64)) as u32;\n    }\n    encoder.write(&input).unwrap();\n    let (compressed, result) = encoder.finish();\n    result.unwrap();\n\n    let mut dec = crate::decoder::Decoder::new(&compressed[..]).unwrap();\n    let mut output = Vec::new();\n    dec.read_to_end(&mut output).unwrap();\n    assert_eq!(input, output);\n}"", ""#[test]\nfn test_encoder_send() {\n    fn check_send<S: Send>(_: &S) {}\n    let enc = EncoderBuilder::new().build(Vec::new());\n    check_send(&enc);\n}"", ""#[test]\nfn test_favor_dec_speed() {\n    let mut encoder = EncoderBuilder::new()\n        .level(11)\n        .favor_dec_speed(true)\n        .build(Vec::new())\n        .unwrap();\n    let mut input = Vec::new();\n    let mut rnd: u32 = 42;\n    for _ in 0..1024 * 1024 {\n        input.push((rnd & 0xFF) as u8);\n        rnd = ((1664525 as u64) * (rnd as u64) + (1013904223 as u64)) as u32;\n    }\n    encoder.write(&input).unwrap();\n    let (compressed, result) = encoder.finish();\n    result.unwrap();\n\n    let mut dec = crate::decoder::Decoder::new(&compressed[..]).unwrap();\n    let mut output = Vec::new();\n    dec.read_to_end(&mut output).unwrap();\n    assert_eq!(input, output);\n}""]}",test_generation
lz4,"{""code_context"": ""use lz4_sys::LZ4_compressBound;\nuse std::io::{Result, Error, ErrorKind};"", ""code_to_test"": ""pub fn compress_bound(uncompressed_size: usize) -> Result<usize> {\n    let compress_bound: i32 = unsafe { LZ4_compressBound(uncompressed_size as i32) };\n\n    if uncompressed_size > (i32::max_value() as usize) || compress_bound <= 0 {\n        return Err(Error::new(\n            ErrorKind::InvalidInput,\n            \""Compression input too long.\"",\n        ));\n    }\n\n    Ok(compress_bound as usize)\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn test_compress_bound_small() {\n    let size = 1024;\n    let bound = compress_bound(size).unwrap();\n    assert!(bound >= size);\n}"", ""#[test]\nfn test_compress_bound_too_large() {\n    let size = (i32::MAX as usize) + 1;\n    let err = compress_bound(size).unwrap_err();\n    assert_eq!(err.kind(), std::io::ErrorKind::InvalidInput);\n}""]}",test_generation
integer-encoding,"{""code"": ""impl VarInt for u64 {\n    fn encode_var(self, dst: &mut [u8]) -> usize {\n        debug_assert!(dst.len() >= self.required_space());\n        let mut n = self;\n        let mut i = 0;\n        while n >= 0x80 {\n            dst[i] = MSB | (n as u8);\n            i += 1;\n            n >>= 7;\n        }\n        dst[i] = n as u8;\n        i + 1\n    }\n}"", ""code_context"": ""pub const MSB: u8 = 0b1000_0000;\npub trait VarInt: Sized + Copy {\n    fn required_space(self) -> usize;\n    fn decode_var(src: &[u8]) -> Option<(Self, usize)>;\n    fn encode_var(self, dst: &mut [u8]) -> usize;\n}""}","{""explanation"": ""Encodes an unsigned 64‑bit integer into a byte slice using the VarInt format. The method writes the integer 7 bits at a time, setting the most‑significant bit of each byte except the last to indicate continuation. It returns the number of bytes written.""}",code_explanation
integer-encoding,"{""code"": ""impl VarInt for u64 {\n    fn decode_var(src: &[u8]) -> Option<(Self, usize)> {\n        let mut result: u64 = 0;\n        let mut shift = 0;\n        let mut success = false;\n        for b in src.iter() {\n            let msb_dropped = b & DROP_MSB;\n            result |= (msb_dropped as u64) << shift;\n            shift += 7;\n            if b & MSB == 0 || shift > (9 * 7) {\n                success = b & MSB == 0;\n                break;\n            }\n        }\n        if success {\n            Some((result, shift / 7))\n        } else {\n            None\n        }\n    }\n}"", ""code_context"": ""pub const MSB: u8 = 0b1000_0000;\npub const DROP_MSB: u8 = 0b0111_1111;\npub trait VarInt: Sized + Copy {\n    fn required_space(self) -> usize;\n    fn decode_var(src: &[u8]) -> Option<(Self, usize)>;\n    fn encode_var(self, dst: &mut [u8]) -> usize;\n}""}","{""explanation"": ""Decodes a VarInt‑encoded byte slice into a u64 value. It accumulates 7‑bit groups while the continuation bit (MSB) is set, stops when a byte without the MSB is found, and returns the decoded integer together with the number of bytes consumed.""}",code_explanation
integer-encoding,"{""code"": ""impl FixedInt for u64 {\n    fn encode_fixed(self, dst: &mut [u8]) -> Option<()> {\n        if dst.len() == std::mem::size_of::<Self>() {\n            dst.clone_from_slice(&self.to_le_bytes());\n            Some(())\n        } else {\n            None\n        }\n    }\n}"", ""code_context"": ""use std::mem::size_of;\npub trait FixedInt: Sized + Copy {\n    type Bytes: AsRef<[u8]>;\n    const ENCODED_SIZE: usize = size_of::<Self>();\n    fn encode_fixed(self, dst: &mut [u8]) -> Option<()>;\n    fn encode_fixed_light(self) -> Self::Bytes;\n    fn decode_fixed(src: &[u8]) -> Option<Self>;\n    fn encode_fixed_vec(self) -> Vec<u8> {\n        self.encode_fixed_light().as_ref().to_vec()\n    }\n    fn switch_endianness(self) -> Self;\n}""}","{""explanation"": ""Writes a u64 value into a destination slice using little‑endian byte order. The method succeeds only if the slice length matches the size of the integer (8 bytes) and returns `Some(())`; otherwise it returns `None`.""}",code_explanation
integer-encoding,"{""code"": ""pub trait VarIntWriter {\n    fn write_varint<VI: VarInt>(&mut self, n: VI) -> Result<usize>;\n}"", ""code_context"": ""use std::io::Result;\npub trait VarInt: Sized + Copy {\n    fn required_space(self) -> usize;\n    fn decode_var(src: &[u8]) -> Option<(Self, usize)>;\n    fn encode_var(self, dst: &mut [u8]) -> usize;\n}""}","{""explanation"": ""Defines a trait for types that can write VarInt‑encoded integers to an output. The `write_varint` method takes any `VarInt` value, writes its encoded form, and returns the number of bytes written or an I/O error.""}",code_explanation
lz4,"{""code"": ""impl<R: Read> Decoder<R> {\n    pub fn new(r: R) -> Result<Decoder<R>> {\n        Ok(Decoder {\n            r,\n            c: DecoderContext::new()?,\n            buf: vec![0; BUFFER_SIZE].into_boxed_slice(),\n            pos: BUFFER_SIZE,\n            len: BUFFER_SIZE,\n            next: 11,\n        })\n    }\n}"", ""code_context"": ""type Read = std::io::Read;\ntype Result<T> = std::io::Result<T>;\ntype size_t = usize;\n\npub struct Decoder<R> {\n    c: DecoderContext,\n    r: R,\n    buf: Box<[u8]>,\n    pos: usize,\n    len: usize,\n    next: usize,\n}\n\npub struct DecoderContext {\n    c: LZ4FDecompressionContext,\n}\n\nimpl DecoderContext {\n    pub fn new() -> Result<DecoderContext> {\n        let mut context = LZ4FDecompressionContext(std::ptr::null_mut());\n        check_error(unsafe { LZ4F_createDecompressionContext(&mut context, LZ4F_VERSION) })?;\n        Ok(DecoderContext { c: context })\n    }\n}\n\npub const BUFFER_SIZE: usize = 32 * 1024;\n\npub struct LZ4FDecompressionContext(pub *mut std::ffi::c_void);\n\npub const LZ4F_VERSION: u32 = 100;\n\nextern \""C\"" {\n    fn LZ4F_createDecompressionContext(ctx: &mut LZ4FDecompressionContext, version: u32) -> usize;\n    fn LZ4F_freeDecompressionContext(ctx: LZ4FDecompressionContext);\n    fn LZ4F_decompress(\n        ctx: LZ4FDecompressionContext,\n        dstBuffer: *mut u8,\n        dstSizePtr: &mut size_t,\n        srcBuffer: *const u8,\n        srcSizePtr: &mut size_t,\n        optionsPtr: *const (),\n    ) -> usize;\n}\n\nfn check_error(code: usize) -> Result<usize> {\n    // In the real library this checks for LZ4 errors. Here we simply treat any non‑zero as success.\n    if code == 0 { Err(std::io::Error::new(std::io::ErrorKind::Other, \""LZ4 error\"")) } else { Ok(code) }\n}""}","{""docstring"": ""Creates a new decoder which reads its input from the given input stream. The input stream can be re-acquired by calling `finish()`.""}",docstring_generation
lz4,"{""code"": ""impl<W: Write> Encoder<W> {\n    pub fn finish(mut self) -> (W, Result<()>) {\n        let result = self.write_end();\n        (self.w, result)\n    }\n}"", ""code_context"": ""type Write = std::io::Write;\ntype Result<T> = std::io::Result<T>;\ntype size_t = usize;\n\npub struct Encoder<W> {\n    c: EncoderContext,\n    w: W,\n    limit: usize,\n    buffer: Vec<u8>,\n}\n\npub struct EncoderContext {\n    c: LZ4FCompressionContext,\n}\n\nimpl EncoderContext {\n    pub fn new() -> Result<EncoderContext> {\n        let mut context = LZ4FCompressionContext(std::ptr::null_mut());\n        check_error(unsafe { LZ4F_createCompressionContext(&mut context, LZ4F_VERSION) })?;\n        Ok(EncoderContext { c: context })\n    }\n}\n\npub const LZ4F_VERSION: u32 = 100;\n\npub struct LZ4FCompressionContext(pub *mut std::ffi::c_void);\n\nextern \""C\"" {\n    fn LZ4F_createCompressionContext(ctx: &mut LZ4FCompressionContext, version: u32) -> usize;\n    fn LZ4F_freeCompressionContext(ctx: LZ4FCompressionContext) -> usize;\n    fn LZ4F_compressEnd(\n        ctx: LZ4FCompressionContext,\n        dstBuffer: *mut u8,\n        dstMaxSize: size_t,\n        compressOptionsPtr: *const (),\n    ) -> usize;\n}\n\nfn check_error(code: usize) -> Result<usize> {\n    if code == 0 { Err(std::io::Error::new(std::io::ErrorKind::Other, \""LZ4 error\"")) } else { Ok(code) }\n}""}","{""docstring"": ""This function is used to flag that this session of compression is done with. The stream is finished up (final bytes are written), and then the wrapped writer is returned.""}",docstring_generation
lz4,"{""code"": ""pub fn compress(src: &[u8], mode: Option<CompressionMode>, prepend_size: bool) -> Result<Vec<u8>> {\n    let compress_bound: i32 = unsafe { LZ4_compressBound(src.len() as i32) };\n    if src.len() > (i32::max_value() as usize) || compress_bound <= 0 {\n        return Err(Error::new(ErrorKind::InvalidInput, \""Compression input too long.\""));\n    }\n    let mut compressed: Vec<u8> = vec![0; (if prepend_size { compress_bound + 4 } else { compress_bound }) as usize];\n    let dec_size = compress_to_buffer(src, mode, prepend_size, &mut compressed)?;\n    compressed.truncate(dec_size as usize);\n    Ok(compressed)\n}"", ""code_context"": ""use std::io::{Error, ErrorKind, Result};\n\ntype Result<T> = std::io::Result<T>;\n\ntype size_t = usize;\n\npub enum CompressionMode {\n    HIGHCOMPRESSION(i32),\n    FAST(i32),\n    DEFAULT,\n}\n\nextern \""C\"" {\n    fn LZ4_compressBound(srcSize: i32) -> i32;\n    fn LZ4_compress_HC(src: *const i8, dst: *mut i8, srcSize: i32, dstCapacity: i32, compressionLevel: i32) -> i32;\n    fn LZ4_compress_fast(src: *const i8, dst: *mut i8, srcSize: i32, dstCapacity: i32, acceleration: i32) -> i32;\n    fn LZ4_compress_default(src: *const i8, dst: *mut i8, srcSize: i32, maxDestSize: i32) -> i32;\n}\n\nfn compress_to_buffer(src: &[u8], mode: Option<CompressionMode>, prepend_size: bool, buffer: &mut [u8]) -> Result<usize> {\n    // Placeholder implementation – the real function forwards to the LZ4 C API.\n    let _ = (src, mode, prepend_size, buffer);\n    Err(Error::new(ErrorKind::Other, \""not implemented in context\""))\n}\n\nfn check_error(_code: usize) -> Result<usize> {\n    // Stub – in the real crate this converts LZ4 error codes.\n    Ok(1)\n}""}","{""docstring"": ""Compresses the full src buffer using the specified CompressionMode, where None and Some(Default) are treated equally. If prepend_size is set, the source length will be prepended to the output buffer.\n\n# Errors\nReturns std::io::Error with ErrorKind::InvalidInput if the src buffer is too long.\nReturns std::io::Error with ErrorKind::Other if the compression failed inside the C library. If this happens, the C api was not able to provide more information about the cause.""}",docstring_generation
dotenv,"{""title"": ""Load multiple .env files in order"", ""description"": ""A developer wants to load environment variables from several .env files sequentially, where later files override earlier ones. This helper loads each file using the crate's iterator and applies the variables to the process environment."", ""code_context"": ""use std::path::Path;\nuse std::fs::File;\nuse dotenv::{Iter, Result, Error};""}","{""code"": ""pub fn load_multiple_env_files<P: AsRef<Path>>(paths: &[P]) -> Result<()> {\n    for path in paths {\n        let file = File::open(path.as_ref()).map_err(Error::Io)?;\n        let iter = Iter::new(file);\n        iter.load()?;\n    }\n    Ok(())\n}""}",code_generation
dotenv,"{""title"": ""Validate required environment variables with custom format checks"", ""description"": ""After loading a .env file, a project needs to ensure that all required variables are present and that each satisfies a user‑provided validation function (e.g., URL format, numeric range). The function returns an error describing the first failing variable."", ""code_context"": ""use std::env;\nuse dotenv::{Result, Error};""}","{""code"": ""pub fn validate_env_vars<F>(required_vars: &[&str], format_checks: &[(&str, F)]) -> Result<()>\nwhere\n    F: Fn(&str) -> bool,\n{\n    for &var in required_vars {\n        let value = std::env::var(var).map_err(Error::EnvVar)?;\n        if let Some((_, check)) = format_checks.iter().find(|(name, _)| *name == var) {\n            if !(check)(&value) {\n                return Err(Error::LineParse(\n                    format!(\""Invalid format for variable '{}': '{}'\"", var, value),\n                    0,\n                ));\n            }\n        }\n    }\n    Ok(())\n}""}",code_generation
dotenv,"{""title"": ""Combine multiple environment variables into a delimited string"", ""description"": ""Sometimes a configuration value is built from several environment variables joined by a separator (e.g., a list of hosts). This helper fetches each variable, concatenates them with the given delimiter, and returns the combined string."", ""code_context"": ""use dotenv::Result;""}","{""code"": ""pub fn combine_env_vars(names: &[&str], delimiter: &str) -> Result<String> {\n    let mut combined = String::new();\n    for (i, name) in names.iter().enumerate() {\n        let value = dotenv::var(name)?;\n        combined.push_str(&value);\n        if i + 1 != names.len() {\n            combined.push_str(delimiter);\n        }\n    }\n    Ok(combined)\n}""}",code_generation
dotenv,"{""title"": ""Filter environment variables by prefix"", ""description"": ""A developer wants to extract only those environment variables whose keys start with a specific prefix (e.g., \""DB_\""), returning them as a vector of key/value pairs for further processing."", ""code_context"": ""use dotenv::vars;""}","{""code"": ""pub fn filter_env_vars_by_prefix(prefix: &str) -> Vec<(String, String)> {\n    dotenv::vars()\n        .filter(|(key, _)| key.starts_with(prefix))\n        .collect()\n}""}",code_generation
integer-encoding,"{""code_before"": ""fn write_varint<VI: VarInt>(&mut self, n: VI) -> Result<usize> {\n    let mut buf = [0_u8; 10];\n    let used = n.encode_var(&mut buf);\n    self.write_all(&buf[0..used])?;\n    Ok(used)\n}"", ""code_context"": ""use std::io::Write;\n\npub trait VarInt {\n    fn required_space(self) -> usize;\n    fn encode_var(self, dst: &mut [u8]) -> usize;\n}""}","{""code_after"": ""fn write_varint<VI: VarInt>(&mut self, n: VI) -> Result<usize> {\n    let mut buf = vec![0_u8; n.required_space()];\n    let used = n.encode_var(&mut buf);\n    self.write_all(&buf[0..used])?;\n    Ok(used)\n}"", ""review_comment"": ""Allocate a buffer sized exactly to the required space instead of a fixed 10‑byte array. This avoids wasting stack space and prevents accidental writes beyond the needed length.""}",code_review
integer-encoding,"{""code_before"": ""fn encode_fixed(self, dst: &mut [u8]) -> Option<()> {\n    if dst.len() == size_of::<Self>() {\n        dst.clone_from_slice(&self.to_le_bytes());\n        Some(())\n    } else {\n        None\n    }\n}"", ""code_context"": ""use std::mem::size_of;\n\npub trait FixedInt: Sized + Copy {\n    fn encode_fixed(self, dst: &mut [u8]) -> Option<()>;\n}""}","{""code_after"": ""fn encode_fixed(self, dst: &mut [u8]) -> Option<()> {\n    if dst.len() == size_of::<Self>() {\n        dst.copy_from_slice(&self.to_le_bytes());\n        Some(())\n    } else {\n        None\n    }\n}"", ""review_comment"": ""Use `copy_from_slice` instead of `clone_from_slice`. `copy_from_slice` is the idiomatic way to copy raw bytes and is slightly faster because it does not require the `Clone` trait.""}",code_review
integer-encoding,"{""code_before"": ""fn required_space(self) -> usize {\n    required_encoded_space_unsigned(self as u64)\n}"", ""code_context"": ""fn required_encoded_space_unsigned(mut v: u64) -> usize {\n    if v == 0 {\n        return 1;\n    }\n    let mut logcounter = 0;\n    while v > 0 {\n        logcounter += 1;\n        v >>= 7;\n    }\n    logcounter\n}""}","{""code_after"": ""fn required_space(self) -> usize {\n    required_encoded_space_unsigned(self as u64).max(1)\n}"", ""review_comment"": ""Guarantee that `required_space` never returns zero, even if the helper were to return 0 for the value 0. This makes the API safer for callers that allocate buffers based on the returned size.""}",code_review
integer-encoding,"{""code_before"": ""fn decode_var(src: &[u8]) -> Option<(u64, usize)> {\n    let mut result: u64 = 0;\n    let mut shift = 0;\n    for b in src.iter() {\n        let msb_dropped = b & DROP_MSB;\n        result |= (msb_dropped as u64) << shift;\n        shift += 7;\n        if b & MSB == 0 {\n            return Some((result, shift / 7 + 1));\n        }\n    }\n    None\n}"", ""code_context"": ""const MSB: u8 = 0b1000_0000;\nconst DROP_MSB: u8 = 0b0111_1111;""}","{""code_after"": ""fn decode_var(src: &[u8]) -> Option<(u64, usize)> {\n    let mut result: u64 = 0;\n    let mut shift = 0;\n    for b in src.iter() {\n        let msb_dropped = b & DROP_MSB;\n        result |= (msb_dropped as u64) << shift;\n        shift += 7;\n        if b & MSB == 0 || shift > (9 * 7) {\n            return Some((result, shift / 7 + 1));\n        }\n    }\n    None\n}"", ""review_comment"": ""Add a guard `shift > (9 * 7)` to stop decoding after the maximum number of bytes for a 64‑bit varint. This prevents infinite loops or overflow when malformed data contains too many continuation bits.""}",code_review
dotenv,"{""code"": ""impl Error {\n    pub fn not_found(&self) -> bool {\n        if let Error::Io(ref io_error) = *self {\n            return io_error.kind() == io::ErrorKind::NotFound;\n        }\n        false\n    }\n}"", ""code_context"": ""use std::io;\n\n#[derive(Debug)]\npub enum Error {\n    LineParse(String, usize),\n    Io(io::Error),\n    EnvVar(std::env::VarError),\n    __Nonexhaustive,\n}""}","{""summary"": ""Checks whether the error is an I/O NotFound error.""}",code_summarization
dotenv,"{""code"": ""pub fn parse_line(\n    line: &str,\n    substitution_data: &mut HashMap<String, Option<String>>, \n) -> ParsedLine {\n    let mut parser = LineParser::new(line, substitution_data);\n    parser.parse_line()\n}"", ""code_context"": ""use std::collections::HashMap;\nuse crate::errors::*;\n\npub type ParsedLine = Result<Option<(String, String)>>;\n\nstruct LineParser<'a> {\n    original_line: &'a str,\n    substitution_data: &'a mut HashMap<String, Option<String>>, \n    line: &'a str,\n    pos: usize,\n}\n\nimpl<'a> LineParser<'a> {\n    fn new(\n        line: &'a str,\n        substitution_data: &'a mut HashMap<String, Option<String>>, \n    ) -> LineParser<'a> {\n        LineParser {\n            original_line: line,\n            substitution_data,\n            line: line.trim_end(),\n            pos: 0,\n        }\n    }\n\n    fn err(&self) -> Error {\n        Error::LineParse(self.original_line.into(), self.pos)\n    }\n\n    fn parse_line(&mut self) -> ParsedLine {\n        self.skip_whitespace();\n        if self.line.is_empty() || self.line.starts_with('#') {\n            return Ok(None);\n        }\n        let mut key = self.parse_key()?;\n        self.skip_whitespace();\n        if key == \""export\"" {\n            if self.expect_equal().is_err() {\n                key = self.parse_key()?;\n                self.skip_whitespace();\n                self.expect_equal()?;\n            }\n        } else {\n            self.expect_equal()?;\n        }\n        self.skip_whitespace();\n        if self.line.is_empty() || self.line.starts_with('#') {\n            self.substitution_data.insert(key.clone(), None);\n            return Ok(Some((key, String::new())));\n        }\n        let parsed_value = parse_value(self.line, &mut self.substitution_data)?;\n        self.substitution_data.insert(key.clone(), Some(parsed_value.clone()));\n        Ok(Some((key, parsed_value)))\n    }\n\n    fn parse_key(&mut self) -> Result<String> {\n        if !self.line.starts_with(|c: char| c.is_ascii_alphabetic() || c == '_') {\n            return Err(self.err());\n        }\n        let index = match self.line.find(|c: char| !(c.is_ascii_alphanumeric() || c == '_' || c == '.')) {\n            Some(i) => i,\n            None => self.line.len(),\n        };\n        self.pos += index;\n        let key = String::from(&self.line[..index]);\n        self.line = &self.line[index..];\n        Ok(key)\n    }\n\n    fn expect_equal(&mut self) -> Result<()> {\n        if !self.line.starts_with('=') {\n            return Err(self.err());\n        }\n        self.line = &self.line[1..];\n        self.pos += 1;\n        Ok(())\n    }\n\n    fn skip_whitespace(&mut self) {\n        if let Some(index) = self.line.find(|c: char| !c.is_whitespace()) {\n            self.pos += index;\n            self.line = &self.line[index..];\n        } else {\n            self.pos += self.line.len();\n            self.line = \""\"";\n        }\n    }\n}\n\n#[derive(Eq, PartialEq)]\nenum SubstitutionMode {\n    None,\n    Block,\n    EscapedBlock,\n}\n\nfn parse_value(\n    input: &str,\n    substitution_data: &mut HashMap<String, Option<String>>, \n) -> Result<String> {\n    let mut strong_quote = false;\n    let mut weak_quote = false;\n    let mut escaped = false;\n    let mut expecting_end = false;\n    let mut output = String::new();\n    let mut substitution_mode = SubstitutionMode::None;\n    let mut substitution_name = String::new();\n    for (index, c) in input.chars().enumerate() {\n        if expecting_end {\n            if c == ' ' || c == '\\t' {\n                continue;\n            } else if c == '#' {\n                break;\n            } else {\n                return Err(Error::LineParse(input.to_owned(), index));\n            }\n        } else if escaped {\n            match c {\n                '\\\\' | '\\'' | '\""' | '$' | ' ' => output.push(c),\n                'n' => output.push('\\n'),\n                _ => return Err(Error::LineParse(input.to_owned(), index)),\n            }\n            escaped = false;\n        } else if strong_quote {\n            if c == '\\'' {\n                strong_quote = false;\n            } else {\n                output.push(c);\n            }\n        } else if substitution_mode != SubstitutionMode::None {\n            if c.is_alphanumeric() {\n                substitution_name.push(c);\n            } else {\n                match substitution_mode {\n                    SubstitutionMode::None => unreachable!(),\n                    SubstitutionMode::Block => {\n                        if c == '{' && substitution_name.is_empty() {\n                            substitution_mode = SubstitutionMode::EscapedBlock;\n                        } else {\n                            apply_substitution(substitution_data, &substitution_name.drain(..).collect::<String>(), &mut output);\n                            if c == '$' {\n                                substitution_mode = if !strong_quote && !escaped { SubstitutionMode::Block } else { SubstitutionMode::None };\n                            } else {\n                                substitution_mode = SubstitutionMode::None;\n                                output.push(c);\n                            }\n                        }\n                    }\n                    SubstitutionMode::EscapedBlock => {\n                        if c == '}' {\n                            substitution_mode = SubstitutionMode::None;\n                            apply_substitution(substitution_data, &substitution_name.drain(..).collect::<String>(), &mut output);\n                        } else {\n                            substitution_name.push(c);\n                        }\n                    }\n                }\n            }\n        } else if c == '$' {\n            substitution_mode = if !strong_quote && !escaped { SubstitutionMode::Block } else { SubstitutionMode::None };\n        } else if weak_quote {\n            if c == '\""' {\n                weak_quote = false;\n            } else if c == '\\\\' {\n                escaped = true;\n            } else {\n                output.push(c);\n            }\n        } else if c == '\\'' {\n            strong_quote = true;\n        } else if c == '\""' {\n            weak_quote = true;\n        } else if c == '\\\\' {\n            escaped = true;\n        } else if c == ' ' || c == '\\t' {\n            expecting_end = true;\n        } else {\n            output.push(c);\n        }\n    }\n    if substitution_mode == SubstitutionMode::EscapedBlock || strong_quote || weak_quote {\n        let value_length = input.len();\n        Err(Error::LineParse(input.to_owned(), if value_length == 0 { 0 } else { value_length - 1 }))\n    } else {\n        apply_substitution(substitution_data, &substitution_name.drain(..).collect::<String>(), &mut output);\n        Ok(output)\n    }\n}\n\nfn apply_substitution(\n    substitution_data: &mut HashMap<String, Option<String>>, \n    substitution_name: &str, \n    output: &mut String,\n) {\n    if let Ok(environment_value) = std::env::var(substitution_name) {\n        output.push_str(&environment_value);\n    } else {\n        let stored_value = substitution_data.get(substitution_name).unwrap_or(&None).to_owned();\n        output.push_str(&stored_value.unwrap_or_else(String::new));\n    }\n}""}","{""summary"": ""Parses a line from a .env file, handling comments, key‑value pairs and variable substitution.""}",code_summarization
dotenv,"{""code"": ""pub fn dotenv() -> Result<PathBuf> {\n    let (path, iter) = Finder::new().find()?;\n    iter.load()?;\n    Ok(path)\n}"", ""code_context"": ""use std::path::{Path, PathBuf};\nuse crate::errors::*;\nuse crate::find::Finder;\nuse crate::iter::Iter;\n\npub struct Finder<'a> {\n    filename: &'a Path,\n}\n\nimpl<'a> Finder<'a> {\n    pub fn new() -> Self {\n        Finder { filename: Path::new(\"".env\"") }\n    }\n    pub fn filename(mut self, filename: &'a Path) -> Self {\n        self.filename = filename;\n        self\n    }\n    pub fn find(self) -> Result<(PathBuf, Iter<std::fs::File>)> {\n        let path = find(&std::env::current_dir().map_err(Error::Io)?, self.filename)?;\n        let file = std::fs::File::open(&path).map_err(Error::Io)?;\n        let iter = Iter::new(file);\n        Ok((path, iter))\n    }\n}\n\npub fn find(directory: &Path, filename: &Path) -> Result<PathBuf> {\n    let candidate = directory.join(filename);\n    match std::fs::metadata(&candidate) {\n        Ok(metadata) => {\n            if metadata.is_file() {\n                return Ok(candidate);\n            }\n        }\n        Err(error) => {\n            if error.kind() != std::io::ErrorKind::NotFound {\n                return Err(Error::Io(error));\n            }\n        }\n    }\n    if let Some(parent) = directory.parent() {\n        find(parent, filename)\n    } else {\n        Err(Error::Io(std::io::Error::new(std::io::ErrorKind::NotFound, \""path not found\"")))\n    }\n}\n\npub struct Iter<R> {\n    // fields omitted for brevity\n    _marker: std::marker::PhantomData<R>,\n}\n\nimpl<R> Iter<R> {\n    pub fn new(_reader: R) -> Self { Iter { _marker: std::marker::PhantomData } }\n    pub fn load(self) -> Result<()> { Ok(()) }\n}""}","{""summary"": ""Loads the .env file from the current directory or its ancestors and returns its path.""}",code_summarization
dotenv,"{""code"": ""pub fn from_path<P: AsRef<Path>>(path: P) -> Result<()> {\n    let iter = Iter::new(std::fs::File::open(path).map_err(Error::Io)?);\n    iter.load()\n}"", ""code_context"": ""use std::fs::File;\nuse std::path::Path;\nuse crate::errors::*;\nuse crate::iter::Iter;\n\npub struct Iter<R> {\n    _marker: std::marker::PhantomData<R>,\n}\n\nimpl<R> Iter<R> {\n    pub fn new(_reader: R) -> Self { Iter { _marker: std::marker::PhantomData } }\n    pub fn load(self) -> Result<()> { Ok(()) }\n}""}","{""summary"": ""Loads the .env file at the given absolute path.""}",code_summarization
parquet-variant-json,"{""code"": ""pub fn json_to_variant(json: &str, builder: &mut VariantBuilder) -> Result<(), ArrowError> {\n    let json: Value = serde_json::from_str(json)\n        .map_err(|e| ArrowError::InvalidArgumentError(format!(\""JSON format error: {e}\"")))?;\n    build_json(&json, builder)?;\n    Ok(())\n}"", ""code_context"": ""use arrow_schema::ArrowError;\nuse parquet_variant::{ListBuilder, ObjectBuilder, Variant, VariantBuilder, VariantBuilderExt};\nuse serde_json::{Number, Value};\n\nfn build_json(json: &Value, builder: &mut VariantBuilder) -> Result<(), ArrowError> {\n    append_json(json, builder)?;\n    Ok(())\n}\n\nfn variant_from_number<'m, 'v>(n: &Number) -> Result<Variant<'m, 'v>, ArrowError> {\n    if let Some(i) = n.as_i64() {\n        if i as i8 as i64 == i {\n            Ok((i as i8).into())\n        } else if i as i16 as i64 == i {\n            Ok((i as i16).into())\n        } else if i as i32 as i64 == i {\n            Ok((i as i32).into())\n        } else {\n            Ok(i.into())\n        }\n    } else {\n        match n.as_f64() {\n            Some(f) => Ok(f.into()),\n            None => Err(ArrowError::InvalidArgumentError(format!(\""Failed to parse {n} as number\""))),\n        }\n    }\n}\n\nfn append_json<'m, 'v>(\n    json: &'v Value,\n    builder: &mut impl VariantBuilderExt<'m, 'v>,\n) -> Result<(), ArrowError> {\n    match json {\n        Value::Null => builder.append_value(Variant::Null),\n        Value::Bool(b) => builder.append_value(*b),\n        Value::Number(n) => {\n            builder.append_value(variant_from_number(n)?);\n        }\n        Value::String(s) => builder.append_value(s.as_str()),\n        Value::Array(arr) => {\n            let mut list_builder = builder.new_list();\n            for val in arr {\n                append_json(val, &mut list_builder)?;\n            }\n            list_builder.finish();\n        }\n        Value::Object(obj) => {\n            let mut obj_builder = builder.new_object();\n            for (key, value) in obj.iter() {\n                let mut field_builder = ObjectFieldBuilder {\n                    key,\n                    builder: &mut obj_builder,\n                };\n                append_json(value, &mut field_builder)?;\n            }\n            obj_builder.finish()?;\n        }\n    };\n    Ok(())\n}\n\nstruct ObjectFieldBuilder<'o, 'v, 's> {\n    key: &'s str,\n    builder: &'o mut ObjectBuilder<'v>,\n}\n\nimpl<'m, 'v> VariantBuilderExt<'m, 'v> for ObjectFieldBuilder<'_, '_, '_> {\n    fn append_value(&mut self, value: impl Into<Variant<'m, 'v>>) {\n        self.builder.insert(self.key, value);\n    }\n\n    fn new_list(&mut self) -> ListBuilder {\n        self.builder.new_list(self.key)\n    }\n\n    fn new_object(&mut self) -> ObjectBuilder {\n        self.builder.new_object(self.key)\n    }\n}""}","{""summary"": ""Parses a JSON string and builds a Parquet Variant using the provided VariantBuilder.""}",code_summarization
parquet-variant-json,"{""code"": ""pub fn variant_to_json_string(variant: &Variant) -> Result<String, ArrowError> {\n    let mut buffer = Vec::new();\n    variant_to_json(&mut buffer, variant)?;\n    String::from_utf8(buffer)\n        .map_err(|e| ArrowError::InvalidArgumentError(format!(\""UTF-8 conversion error: {e}\"")))\n}"", ""code_context"": ""use arrow_schema::ArrowError;\nuse base64::{engine::general_purpose, Engine as _};\nuse serde_json::Value;\nuse std::io::Write;\nuse parquet_variant::{Variant, VariantList, VariantObject};\n\nconst DATE_FORMAT: &str = \""%Y-%m-%d\"";\nconst TIMESTAMP_NTZ_FORMAT: &str = \""%Y-%m-%dT%H:%M:%S%.6f\"";\n\nfn format_date_string(date: &chrono::NaiveDate) -> String {\n    date.format(DATE_FORMAT).to_string()\n}\n\nfn format_timestamp_ntz_string(ts: &chrono::NaiveDateTime) -> String {\n    ts.format(TIMESTAMP_NTZ_FORMAT).to_string()\n}\n\nfn format_binary_base64(bytes: &[u8]) -> String {\n    general_purpose::STANDARD.encode(bytes)\n}\n\npub fn variant_to_json(json_buffer: &mut impl Write, variant: &Variant) -> Result<(), ArrowError> {\n    match variant {\n        Variant::Null => write!(json_buffer, \""null\"")?,\n        Variant::BooleanTrue => write!(json_buffer, \""true\"")?,\n        Variant::BooleanFalse => write!(json_buffer, \""false\"")?,\n        Variant::Int8(i) => write!(json_buffer, \""{i}\"")?,\n        Variant::Int16(i) => write!(json_buffer, \""{i}\"")?,\n        Variant::Int32(i) => write!(json_buffer, \""{i}\"")?,\n        Variant::Int64(i) => write!(json_buffer, \""{i}\"")?,\n        Variant::Float(f) => write!(json_buffer, \""{f}\"")?,\n        Variant::Double(f) => write!(json_buffer, \""{f}\"")?,\n        Variant::Decimal4(d) => write!(json_buffer, \""{d}\"")?,\n        Variant::Decimal8(d) => write!(json_buffer, \""{d}\"")?,\n        Variant::Decimal16(d) => write!(json_buffer, \""{d}\"")?,\n        Variant::Date(date) => write!(json_buffer, \""\\\""{}\\\""\"", format_date_string(date))?,\n        Variant::TimestampMicros(ts) => write!(json_buffer, \""\\\""{}\\\""\"", ts.to_rfc3339())?,\n        Variant::TimestampNtzMicros(ts) => {\n            write!(json_buffer, \""\\\""{}\\\""\"", format_timestamp_ntz_string(ts))?\n        }\n        Variant::Binary(bytes) => {\n            let base64_str = format_binary_base64(bytes);\n            let json_str = serde_json::to_string(&base64_str).map_err(|e| {\n                ArrowError::InvalidArgumentError(format!(\""JSON encoding error: {e}\""))\n            })?;\n            write!(json_buffer, \""{json_str}\"")?\n        }\n        Variant::String(s) => {\n            let json_str = serde_json::to_string(s).map_err(|e| {\n                ArrowError::InvalidArgumentError(format!(\""JSON encoding error: {e}\""))\n            })?;\n            write!(json_buffer, \""{json_str}\"")?\n        }\n        Variant::ShortString(s) => {\n            let json_str = serde_json::to_string(s.as_str()).map_err(|e| {\n                ArrowError::InvalidArgumentError(format!(\""JSON encoding error: {e}\""))\n            })?;\n            write!(json_buffer, \""{json_str}\"")?\n        }\n        Variant::Object(obj) => {\n            convert_object_to_json(json_buffer, obj)?;\n        }\n        Variant::List(arr) => {\n            convert_array_to_json(json_buffer, arr)?;\n        }\n    }\n    Ok(())\n}\n\nfn convert_object_to_json(buffer: &mut impl Write, obj: &VariantObject) -> Result<(), ArrowError> {\n    write!(buffer, \""{{\"")?;\n    let mut first = true;\n    for (key, value) in obj.iter() {\n        if !first {\n            write!(buffer, \"",\"")?;\n        }\n        first = false;\n        let json_key = serde_json::to_string(key).map_err(|e| {\n            ArrowError::InvalidArgumentError(format!(\""JSON key encoding error: {e}\""))\n        })?;\n        write!(buffer, \""{json_key}:\"")?;\n        variant_to_json(buffer, &value)?;\n    }\n    write!(buffer, \""}}\"")?;\n    Ok(())\n}\n\nfn convert_array_to_json(buffer: &mut impl Write, arr: &VariantList) -> Result<(), ArrowError> {\n    write!(buffer, \""[\"")?;\n    let mut first = true;\n    for element in arr.iter() {\n        if !first {\n            write!(buffer, \"",\"")?;\n        }\n        first = false;\n        variant_to_json(buffer, &element)?;\n    }\n    write!(buffer, \""]\"")?;\n    Ok(())\n}""}","{""summary"": ""Converts a Variant into its JSON string representation by writing to a buffer.""}",code_summarization
parquet-variant-json,"{""code"": ""fn append_json<'m, 'v>(\n    json: &'v Value,\n    builder: &mut impl VariantBuilderExt<'m, 'v>,\n) -> Result<(), ArrowError> {\n    match json {\n        Value::Null => builder.append_value(Variant::Null),\n        Value::Bool(b) => builder.append_value(*b),\n        Value::Number(n) => {\n            builder.append_value(variant_from_number(n)?);\n        }\n        Value::String(s) => builder.append_value(s.as_str()),\n        Value::Array(arr) => {\n            let mut list_builder = builder.new_list();\n            for val in arr {\n                append_json(val, &mut list_builder)?;\n            }\n            list_builder.finish();\n        }\n        Value::Object(obj) => {\n            let mut obj_builder = builder.new_object();\n            for (key, value) in obj.iter() {\n                let mut field_builder = ObjectFieldBuilder {\n                    key,\n                    builder: &mut obj_builder,\n                };\n                append_json(value, &mut field_builder)?;\n            }\n            obj_builder.finish()?;\n        }\n    };\n    Ok(())\n}"", ""code_context"": ""use arrow_schema::ArrowError;\nuse parquet_variant::{ListBuilder, ObjectBuilder, Variant, VariantBuilderExt};\nuse serde_json::{Number, Value};\n\nfn variant_from_number<'m, 'v>(n: &Number) -> Result<Variant<'m, 'v>, ArrowError> {\n    if let Some(i) = n.as_i64() {\n        if i as i8 as i64 == i {\n            Ok((i as i8).into())\n        } else if i as i16 as i64 == i {\n            Ok((i as i16).into())\n        } else if i as i32 as i64 == i {\n            Ok((i as i32).into())\n        } else {\n            Ok(i.into())\n        }\n    } else {\n        match n.as_f64() {\n            Some(f) => Ok(f.into()),\n            None => Err(ArrowError::InvalidArgumentError(format!(\""Failed to parse {n} as number\""))),\n        }\n    }\n}\n\nstruct ObjectFieldBuilder<'o, 'v, 's> {\n    key: &'s str,\n    builder: &'o mut ObjectBuilder<'v>,\n}\n\nimpl<'m, 'v> VariantBuilderExt<'m, 'v> for ObjectFieldBuilder<'_, '_, '_> {\n    fn append_value(&mut self, value: impl Into<Variant<'m, 'v>>) {\n        self.builder.insert(self.key, value);\n    }\n\n    fn new_list(&mut self) -> ListBuilder {\n        self.builder.new_list(self.key)\n    }\n\n    fn new_object(&mut self) -> ObjectBuilder {\n        self.builder.new_object(self.key)\n    }\n}""}","{""summary"": ""Recursively converts a serde_json::Value into a VariantBuilder, handling all JSON types.""}",code_summarization
parquet-variant-json,"{""code"": ""fn variant_from_number<'m, 'v>(n: &Number) -> Result<Variant<'m, 'v>, ArrowError> {\n    if let Some(i) = n.as_i64() {\n        if i as i8 as i64 == i {\n            Ok((i as i8).into())\n        } else if i as i16 as i64 == i {\n            Ok((i as i16).into())\n        } else if i as i32 as i64 == i {\n            Ok((i as i32).into())\n        } else {\n            Ok(i.into())\n        }\n    } else {\n        match n.as_f64() {\n            Some(f) => Ok(f.into()),\n            None => Err(ArrowError::InvalidArgumentError(format!(\""Failed to parse {n} as number\""))),\n        }\n    }\n}"", ""code_context"": ""use arrow_schema::ArrowError;\nuse parquet_variant::Variant;\nuse serde_json::Number;""}","{""summary"": ""Converts a JSON number into the smallest fitting Parquet Variant integer type or a floating‑point Variant.""}",code_summarization
castaway,"{""prefix"": ""let result = cast!(value, "", ""suffix"": "");""}","{""completion"": ""u8""}",code_completion
castaway,"{""prefix"": ""let s = match_type!(value, { String as s => s, _ => "", ""suffix"": "" })""}","{""completion"": ""value.to_string()""}",code_completion
castaway,"{""prefix"": ""let casted = cast!(&data, "", ""suffix"": "");""}","{""completion"": ""&[u8]""}",code_completion
castaway,"{""prefix"": ""let mut_slice = cast!(&mut buffer, "", ""suffix"": "");""}","{""completion"": ""&mut [u8]""}",code_completion
aws-smithy-checksums,"{""title"": ""Generate checksum trailer headers"", ""description"": ""A developer needs a helper function that creates the HTTP trailer headers for a given checksum algorithm, so they can be appended to outgoing HTTP requests."", ""code_context"": ""use aws_smithy_checksums::http::HttpChecksum;\nuse http::HeaderMap;""}","{""code"": ""pub fn generate_checksum_headers(checksum: Box<dyn aws_smithy_checksums::http::HttpChecksum>) -> http::HeaderMap {\n    let mut headers = http::HeaderMap::new();\n    headers.extend(checksum.headers());\n    headers\n}""}",code_generation
aws-smithy-checksums,"{""title"": ""Parse checksum algorithm from string"", ""description"": ""A developer wants a utility that takes a checksum algorithm name as a string and returns the corresponding `ChecksumAlgorithm` enum variant, or an error if the name is unknown."", ""code_context"": ""use aws_smithy_checksums::ChecksumAlgorithm;\nuse aws_smithy_checksums::error::UnknownChecksumAlgorithmError;""}","{""code"": ""pub fn parse_checksum_algorithm(algorithm: &str) -> Result<aws_smithy_checksums::ChecksumAlgorithm, aws_smithy_checksums::error::UnknownChecksumAlgorithmError> {\n    algorithm.parse::<aws_smithy_checksums::ChecksumAlgorithm>()\n}""}",code_generation
aws-smithy-checksums,"{""title"": ""Calculate and validate CRC32 checksum"", ""description"": ""A developer needs a utility that streams an `SdkBody`, calculates its CRC32 checksum, and compares it to an expected checksum value to ensure data integrity."", ""code_context"": ""use aws_smithy_types::body::SdkBody;\nuse crc_fast::{Digest, CrcAlgorithm};\nuse http_body::BodyExt;""}","{""code"": ""pub async fn validate_crc32(body: aws_smithy_types::body::SdkBody, expected_crc32: [u8; 4]) -> Result<(), String> {\n    let mut digest = crc_fast::Digest::new(crc_fast::CrcAlgorithm::Crc32IsoHdlc);\n    let mut stream = body.map(|chunk| {\n        digest.update(&chunk);\n        chunk\n    });\n    while let Some(chunk) = stream.data().await {\n        match chunk {\n            Ok(_) => (),\n            Err(e) => return Err(e.to_string()),\n        }\n    }\n    let actual = digest.finalize() as u32;\n    if actual.to_be_bytes() == expected_crc32 {\n        Ok(())\n    } else {\n        Err(format!(\n            \""Checksum mismatch: expected {:02X?}, got {:02X?}\"",\n            expected_crc32,\n            actual.to_be_bytes()\n        ))\n    }\n}""}",code_generation
aws-smithy-checksums,"{""title"": ""Generate a SHA-256 checksum trailer for an HTTP response"", ""description"": ""A developer is building an HTTP server and wants to automatically compute and append a SHA-256 checksum trailer to the response body using the existing checksum infrastructure."", ""code_context"": ""use aws_smithy_checksums::{ChecksumAlgorithm, body::calculate::ChecksumBody};\nuse aws_smithy_types::body::SdkBody;""}","{""code"": ""pub fn sha256_checksum_body(body: aws_smithy_types::body::SdkBody) -> aws_smithy_checksums::body::calculate::ChecksumBody<aws_smithy_types::body::SdkBody> {\n    let checksum = \""sha256\""\n        .parse::<aws_smithy_checksums::ChecksumAlgorithm>()\n        .unwrap()\n        .into_impl();\n    aws_smithy_checksums::body::calculate::ChecksumBody::new(body, checksum)\n}""}",code_generation
aws-smithy-checksums,"{""title"": ""Validate MD5 checksum of an incoming HTTP request body"", ""description"": ""A developer needs to verify that the MD5 checksum provided by a client matches the actual body content of an incoming HTTP request."", ""code_context"": ""use aws_smithy_checksums::{ChecksumAlgorithm, body::validate::ChecksumBody};\nuse aws_smithy_types::body::SdkBody;\nuse bytes::Bytes;""}","{""code"": ""pub fn validate_md5_body(body: aws_smithy_types::body::SdkBody, expected: bytes::Bytes) -> aws_smithy_checksums::body::validate::ChecksumBody<aws_smithy_types::body::SdkBody> {\n    let checksum = \""md5\""\n        .parse::<aws_smithy_checksums::ChecksumAlgorithm>()\n        .unwrap()\n        .into_impl();\n    aws_smithy_checksums::body::validate::ChecksumBody::new(body, checksum, expected)\n}""}",code_generation
zvariant_utils,"{""code"": ""pub fn pascal_or_camel_case(s: &str, is_pascal_case: bool) -> String {\n    let mut result = String::new();\n    let mut capitalize = is_pascal_case;\n    let mut first = true;\n    for ch in s.chars() {\n        if ch == '_' || ch == '-' {\n            capitalize = true;\n        } else if capitalize {\n            result.push(ch.to_ascii_uppercase());\n            capitalize = false;\n        } else if first && !is_pascal_case {\n            result.push(ch.to_ascii_lowercase());\n        } else {\n            result.push(ch);\n        }\n\n        if first {\n            first = false;\n        }\n    }\n    result\n}"", ""code_context"": null}","{""summary"": ""Converts a string from snake or kebab case to Pascal case (or camel case when `is_pascal_case` is false).""}",code_summarization
zvariant_utils,"{""code"": ""pub fn snake_or_kebab_case(s: &str, is_snake_case: bool) -> String {\n    let mut result = String::new();\n    for ch in s.chars() {\n        if ch.is_ascii_uppercase() && !result.is_empty() {\n            if is_snake_case {\n                result.push('_');\n            } else {\n                result.push('-');\n            }\n        }\n        if ch == '_' || ch == '-' {\n            if is_snake_case {\n                result.push('_');\n            } else {\n                result.push('-');\n            }\n        } else {\n            result.push(ch.to_ascii_lowercase());\n        }\n    }\n    result\n}"", ""code_context"": null}","{""summary"": ""Converts a string from camel or Pascal case to snake case (or kebab case when `is_snake_case` is false).""}",code_summarization
zvariant_utils,"{""code"": ""pub fn ty_is_option(ty: &Type) -> bool {\n    match ty {\n        Type::Path(TypePath {\n            path: syn::Path { segments, .. },\n            ..\n        }) => segments.last().unwrap().ident == \""Option\"",\n        _ => false,\n    }\n}"", ""code_context"": ""use syn::{Type, TypePath};""}","{""summary"": ""Checks whether a given `syn::Type` represents an `Option` type.""}",code_summarization
parquet-variant-json,"{""query"": ""How can I convert a JSON string to a Parquet Variant using the parquet-variant-json crate?"", ""code_context"": ""use parquet_variant::{VariantBuilder, Variant};\nuse parquet_variant_json::json_to_variant;\nuse arrow_schema::ArrowError;""}","{""code_snippet"": ""fn main() -> Result<(), Box<dyn std::error::Error>> {\n    let json = \""{\\\""name\\\"":\\\""Alice\\\"",\\\""age\\\"":30,\\\""active\\\"":true}\"";\n    let mut builder = VariantBuilder::new();\n    json_to_variant(json, &mut builder)?;\n    let (metadata, value) = builder.finish();\n    let variant = Variant::try_new(&metadata, &value)?;\n    // `variant` now holds the parsed data and can be used further\n    Ok(())\n}""}",code_search
parquet-variant-json,"{""query"": ""How do I serialize a Variant to a JSON string with the parquet-variant-json crate?"", ""code_context"": ""use parquet_variant::Variant;\nuse parquet_variant_json::variant_to_json_string;\nuse arrow_schema::ArrowError;""}","{""code_snippet"": ""fn main() -> Result<(), Box<dyn std::error::Error>> {\n    let variant = Variant::from(\""Hello, World!\"");\n    let json = variant_to_json_string(&variant)?;\n    println!(\""{}\"", json);\n    Ok(())\n}""}",code_search
parquet-variant-json,"{""query"": ""How can I convert a Variant that contains a date value to a JSON string using parquet-variant-json?"", ""code_context"": ""use parquet_variant::Variant;\nuse parquet_variant_json::variant_to_json_string;\nuse arrow_schema::ArrowError;\nuse chrono::NaiveDate;""}","{""code_snippet"": ""fn main() -> Result<(), Box<dyn std::error::Error>> {\n    let date = chrono::NaiveDate::from_ymd_opt(2023, 12, 25).unwrap();\n    let variant = Variant::Date(date);\n    let json = variant_to_json_string(&variant)?;\n    println!(\""{}\"", json); // prints \""2023-12-25\""\n    Ok(())\n}""}",code_search
parquet-variant-json,"{""query"": ""How do I serialize binary data stored in a Variant to a JSON string with base64 encoding using parquet-variant-json?"", ""code_context"": ""use parquet_variant::Variant;\nuse parquet_variant_json::variant_to_json_string;\nuse arrow_schema::ArrowError;""}","{""code_snippet"": ""fn main() -> Result<(), Box<dyn std::error::Error>> {\n    let data = b\""Hello, Parquet!\"";\n    let variant = Variant::Binary(data);\n    let json = variant_to_json_string(&variant)?;\n    println!(\""{}\"", json); // prints base64 encoded string\n    Ok(())\n}""}",code_search
rend,"{""code_before"": ""fn fetch_ordering(order: Ordering) -> Ordering {\n    match order {\n        Ordering::Relaxed => Ordering::Relaxed,\n        Ordering::Release => Ordering::Relaxed,\n        Ordering::Acquire => Ordering::Acquire,\n        Ordering::AcqRel => Ordering::Acquire,\n        Ordering::SeqCst => Ordering::SeqCst,\n        order => order,\n    }\n}"", ""code_context"": ""use core::sync::atomic::Ordering;""}","{""rationale"": ""Groups match arms that return the same value, reducing repetition and making the intent clearer."", ""code_after"": ""fn fetch_ordering(order: Ordering) -> Ordering {\n    match order {\n        Ordering::Relaxed | Ordering::Release => Ordering::Relaxed,\n        Ordering::Acquire | Ordering::AcqRel => Ordering::Acquire,\n        Ordering::SeqCst => Ordering::SeqCst,\n        other => other,\n    }\n}""}",code_refactoring
rend,"{""code_before"": ""pub fn compare_exchange_weak(\n    &self,\n    current: $prim_int,\n    new: $prim_int,\n    success: Ordering,\n    failure: Ordering,\n) -> Result<$prim_int, $prim_int> {\n    match self.0.compare_exchange_weak(\n        swap_endian!($endian current),\n        swap_endian!($endian new),\n        success,\n        failure,\n    ) {\n        Ok(x) => Ok(swap_endian!($endian x)),\n        Err(x) => Ok(swap_endian!($endian x)),\n    }\n}"", ""code_context"": ""use core::sync::atomic::Ordering;\n\nmacro_rules! match_endian {\n    (little $little:expr, $big:expr $(,)?) => { $little };\n    (big $little:expr, $big:expr $(,)?) => { $big };\n}\n\nmacro_rules! if_native_endian {\n    ($endian:ident $true:expr, $false:expr $(,)?) => {\n        match_endian!(\n            $endian\n            {\n                #[cfg(target_endian = \""little\"")] { $true }\n                #[cfg(target_endian = \""big\"")] { $false }\n            },\n            {\n                #[cfg(target_endian = \""little\"")] { $false }\n                #[cfg(target_endian = \""big\"")] { $true }\n            },\n        )\n    };\n}\n\nmacro_rules! swap_endian {\n    ($endian:ident $expr:expr) => {\n        if_native_endian!($endian $expr, $expr.swap_bytes())\n    };\n}""}","{""rationale"": ""Returns `Err` on failure instead of incorrectly converting the error into `Ok`, preserving the semantics of `compare_exchange_weak`."", ""code_after"": ""pub fn compare_exchange_weak(\n    &self,\n    current: $prim_int,\n    new: $prim_int,\n    success: Ordering,\n    failure: Ordering,\n) -> Result<$prim_int, $prim_int> {\n    match self.0.compare_exchange_weak(\n        swap_endian!($endian current),\n        swap_endian!($endian new),\n        success,\n        failure,\n    ) {\n        Ok(x) => Ok(swap_endian!($endian x)),\n        Err(x) => Err(swap_endian!($endian x)),\n    }\n}""}",code_refactoring
rend,"{""code_before"": ""macro_rules! if_native_endian {\n    ($endian:ident $true:expr, $false:expr $(,)?) => {\n        match_endian!(\n            $endian\n            {\n                #[cfg(target_endian = \""little\"")] { $true }\n                #[cfg(target_endian = \""big\"")] { $false }\n            },\n            {\n                #[cfg(target_endian = \""little\"")] { $false }\n                #[cfg(target_endian = \""big\"")] { $true }\n            },\n        )\n    };\n}"", ""code_context"": ""macro_rules! match_endian {\n    (little $little:expr, $big:expr $(,)?) => { $little };\n    (big $little:expr, $big:expr $(,)?) => { $big };\n}""}","{""rationale"": ""Uses `cfg!` to select the target endianness at compile time, eliminating duplicated `#[cfg]` blocks and making the macro easier to read."", ""code_after"": ""macro_rules! if_native_endian {\n    ($endian:ident $true:expr, $false:expr $(,)?) => {\n        if cfg!(target_endian = \""little\"") {\n            match_endian!($endian $true $false)\n        } else {\n            match_endian!($endian $false $true)\n        }\n    };\n}""}",code_refactoring
aliasable,"{""code"": ""impl<T> AliasableVec<T> {\n    pub fn __placeholder__(self) -> UniqueVec<T> {\n        UniqueVec::from_raw_parts(self.ptr.as_ptr(), self.len, self.cap)\n    }\n}"", ""code_context"": ""use alloc::vec::Vec as UniqueVec;\nuse core::ptr::NonNull;""}","{""function_name"": ""convert_to_unique_vec""}",function_naming
aliasable,"{""code"": ""impl<T: ?Sized> AliasableMut<'_, T> {\n    pub fn __placeholder__(&mut self) -> &mut T {\n        unsafe { self.inner.as_mut() }\n    }\n}"", ""code_context"": null}","{""function_name"": ""get_mut_ref""}",function_naming
aliasable,"{""code"": ""impl<T> AliasableVec<T> {\n    pub fn __placeholder__(&self) -> &[T] {\n        unsafe { slice::from_raw_parts(self.ptr.as_ptr(), self.len) }\n    }\n}"", ""code_context"": ""use core::slice;""}","{""function_name"": ""as_slice""}",function_naming
aliasable,"{""code"": ""impl<T: ?Sized> AliasableBox<T> {\n    pub fn __placeholder__(self) -> Option<UniqueBox<T>> {\n        let mut aliasable = ManuallyDrop::new(self);\n        unsafe { aliasable.reclaim_as_unique_box() }\n    }\n}"", ""code_context"": ""use core::mem::ManuallyDrop;\nuse core::ptr::NonNull;\nuse alloc::boxed::Box as UniqueBox;\npub struct AliasableBox<T: ?Sized>(NonNull<T>);""}","{""function_name"": ""try_into_unique""}",function_naming
aliasable,"{""code"": ""impl<T: ?Sized> AliasableBox<T> {\n    pub fn __placeholder__(&mut self, new: *mut T) -> AliasableBox<T> {\n        let this = ManuallyDrop::new(self);\n        let ptr = this.0.replace_ptr(new);\n        AliasableBox(ptr)\n    }\n}"", ""code_context"": ""use core::mem::ManuallyDrop;\nuse core::ptr::NonNull;\npub struct AliasableBox<T: ?Sized>(NonNull<T>);""}","{""function_name"": ""replace_ptr""}",function_naming
zvariant_derive,"{""code_before"": ""for field in &data.fields {\n    let ident = field.ident.as_ref().unwrap();\n    let ty = &field.ty;\n    let FieldAttributes { rename } = FieldAttributes::parse(&field.attrs)?;\n    let dict_name = dict_name_for_field(field, rename, rename_all.as_deref())?;\n    let is_opt = macros::ty_is_option(ty);\n    if is_opt {\n        let as_value_opt_path = quote! { #zv::as_value::optional };\n        let as_value_opt_str = format!(\""{as_value_opt_path}\"");\n        field_defs.push(quote! {\n            #[serde(\n                rename = #dict_name,\n                with = #as_value_opt_str,\n                skip_serializing_if = \""Option::is_none\"",\n            )]\n            #ident: &'a #ty\n        });\n    } else {\n        let as_value_path = quote! { #zv::as_value };\n        let as_value_str = format!(\""{as_value_path}\"");\n        field_defs.push(quote! {\n            #[serde(rename = #dict_name, with = #as_value_str)]\n            #ident: &'a #ty\n        });\n    }\n    field_inits.push(quote! { #ident: &self.#ident });\n}"", ""code_context"": ""use proc_macro2::TokenStream;\nuse quote::{quote, format_ident};\nuse syn::{Field, Error};\nuse zvariant_utils::macros;\n\nuse crate::utils::*;\n\nfn dict_name_for_field(\n    f: &Field,\n    rename_attr: Option<String>,\n    rename_all_attr: Option<&str>,\n) -> Result<String, Error> {\n    let ident = f.ident.as_ref().unwrap().to_string();\n    rename_identifier(ident, f.span(), rename_attr, rename_all_attr)\n}""}","{""rationale"": ""Combines the two branches that handled optional and non‑optional fields into a single block. The refactored code computes the appropriate `as_value` path and the optional `skip_serializing_if` attribute once, eliminating duplicated `field_defs.push` calls and making the loop easier to read and maintain."", ""code_after"": ""for field in &data.fields {\n    let ident = field.ident.as_ref().unwrap();\n    let ty = &field.ty;\n    let FieldAttributes { rename } = FieldAttributes::parse(&field.attrs)?;\n    let dict_name = dict_name_for_field(field, rename, rename_all.as_deref())?;\n    let is_opt = macros::ty_is_option(ty);\n    let as_value_path = if is_opt {\n        quote! { #zv::as_value::optional }\n    } else {\n        quote! { #zv::as_value }\n    };\n    let as_value_str = format!(\""{as_value_path}\"");\n    let skip_attr = if is_opt {\n        \"", skip_serializing_if = \\\""Option::is_none\\\""\""\n    } else {\n        \""\""\n    };\n    field_defs.push(quote! {\n        #[serde(rename = #dict_name, with = #as_value_str#skip_attr)]\n        #ident: &'a #ty\n    });\n    field_inits.push(quote! { #ident: &self.#ident });\n}""}",code_refactoring
zvariant_derive,"{""code_before"": ""match rename_all_attr {\n        Some(\""lowercase\"") => Ok(ident.to_ascii_lowercase()),\n        Some(\""UPPERCASE\"") => Ok(ident.to_ascii_uppercase()),\n        Some(\""PascalCase\"") => Ok(case::pascal_or_camel_case(&ident, true)),\n        Some(\""camelCase\"") => Ok(case::pascal_or_camel_case(&ident, false)),\n        Some(\""snake_case\"") => Ok(case::snake_or_kebab_case(&ident, true)),\n        Some(\""kebab-case\"") => Ok(case::snake_or_kebab_case(&ident, false)),\n        None => Ok(ident),\n        Some(other) => Err(syn::Error::new(\n            span,\n            format!(\""invalid `rename_all` attribute value {other}\""),\n        )),\n    }"", ""code_context"": ""use proc_macro2::Span;\nuse syn::Error;\nuse zvariant_utils::case;\n\nfn rename_identifier(\n    ident: String,\n    span: Span,\n    rename_attr: Option<String>,\n    rename_all_attr: Option<&str>,\n) -> Result<String, Error> {\n    // original implementation omitted for brevity\n    Ok(ident) // placeholder\n}""}","{""rationale"": ""The refactored version removes the repetitive `Some(..)` pattern by unwrapping the option once and matching on a plain string slice. This makes the control flow clearer, reduces nesting, and avoids handling `None` as a separate match arm."", ""code_after"": ""let kind = rename_all_attr.unwrap_or(\""\"");\n    match kind {\n        \""lowercase\"" => Ok(ident.to_ascii_lowercase()),\n        \""UPPERCASE\"" => Ok(ident.to_ascii_uppercase()),\n        \""PascalCase\"" => Ok(case::pascal_or_camel_case(&ident, true)),\n        \""camelCase\"" => Ok(case::pascal_or_camel_case(&ident, false)),\n        \""snake_case\"" => Ok(case::snake_or_kebab_case(&ident, true)),\n        \""kebab-case\"" => Ok(case::snake_or_kebab_case(&ident, false)),\n        \""\"" => Ok(ident),\n        other => Err(syn::Error::new(\n            span,\n            format!(\""invalid `rename_all` attribute value {}\"", other),\n        )),\n    }""}",code_refactoring
zvariant_derive,"{""code_before"": ""fn signature_for_struct(\n    fields: &Fields,\n    zv: &TokenStream,\n    insert_enum_variant: bool,\n) -> TokenStream {\n    let field_types = fields.iter().map(|field| field.ty.to_token_stream());\n    let new_type = match fields {\n        Fields::Named(_) => false,\n        Fields::Unnamed(_) if field_types.len() == 1 => true,\n        Fields::Unnamed(_) => false,\n        Fields::Unit => panic!(\""signature_for_struct must not be called for unit fields\""),\n    };\n    let field_types_clone = field_types.clone();\n    let signature = if new_type {\n        quote! {#(\n            <#field_types_clone as #zv::Type>::SIGNATURE\n        )*}\n    } else {\n        quote! {\n            &#zv::Signature::Structure(#zv::signature::Fields::Static {\n                fields: &[#(\n                    <#field_types_clone as #zv::Type>::SIGNATURE\n                ),*],\n            })\n        }\n    };\n\n    if insert_enum_variant {\n        quote! {\n            &#zv::Signature::Structure(#zv::signature::Fields::Static {\n                fields: &[\n                    <u32 as #zv::Type>::SIGNATURE,\n                    #signature\n                ],\n            })\n        }\n    } else {\n        signature\n    }\n}"", ""code_context"": ""use proc_macro2::TokenStream;\nuse quote::quote;\nuse syn::Fields;\n\n// The function `signature_for_struct` is used by the `Type` derive macro to build a\n// ZVariant signature for a struct. The refactored version shown above relies only on\n// the imports above and the `quote!` macro.""}","{""rationale"": ""The refactored function avoids cloning the iterator of field types and uses a concrete `Vec` to store the token streams. It also replaces the manual `match` on `Fields` with a concise `matches!` expression, improving readability and eliminating the unnecessary `field_types.clone()` call."", ""code_after"": ""fn signature_for_struct(\n    fields: &Fields,\n    zv: &TokenStream,\n    insert_enum_variant: bool,\n) -> TokenStream {\n    let field_type_tokens: Vec<_> = fields.iter().map(|f| f.ty.to_token_stream()).collect();\n    let is_newtype = matches!(fields, Fields::Unnamed(_)) && field_type_tokens.len() == 1;\n    let base_signature = if is_newtype {\n        quote! {#(\n            <#field_type_tokens as #zv::Type>::SIGNATURE\n        )*}\n    } else {\n        quote! {\n            &#zv::Signature::Structure(#zv::signature::Fields::Static {\n                fields: &[#(\n                    <#field_type_tokens as #zv::Type>::SIGNATURE\n                ),*],\n            })\n        }\n    };\n    if insert_enum_variant {\n        quote! {\n            &#zv::Signature::Structure(#zv::signature::Fields::Static {\n                fields: &[\n                    <u32 as #zv::Type>::SIGNATURE,\n                    #base_signature\n                ],\n            })\n        }\n    } else {\n        base_signature\n    }\n}""}",code_refactoring
parquet-variant-json,"{""code"": ""Ok((i as i8).into())"", ""code_context"": ""use arrow_schema::ArrowError;\nuse serde_json::Number;\nuse parquet_variant::Variant;\n\nfn variant_from_number<'m, 'v>(n: &Number) -> Result<Variant<'m, 'v>, ArrowError> {\n    if let Some(i) = n.as_i64() {\n        if i as i8 as i64 == i {\n            Ok((i as i8).into())\n        } else if i as i16 as i64 == i {\n            Ok((i as i16).into())\n        } else if i as i32 as i64 == i {\n            Ok((i as i32).into())\n        } else {\n            Ok(i.into())\n        }\n    } else {\n        match n.as_f64() {\n            Some(f) => Ok(f.into()),\n            None => Err(ArrowError::InvalidArgumentError(format!(\n                \""Failed to parse {} as number\"",\n                n\n            ))),\n        }\n    }\n}""}","{""commented_code"": ""Ok((i as i8).into()) // fits in i8""}",comment_generation
parquet-variant-json,"{""code"": ""let base64_str = format_binary_base64(bytes);"", ""code_context"": ""use arrow_schema::ArrowError;\nuse base64::{engine::general_purpose, Engine as _};\nuse parquet_variant::Variant;\nuse std::io::Write;\n\nfn format_binary_base64(bytes: &[u8]) -> String {\n    general_purpose::STANDARD.encode(bytes)\n}\n\nfn variant_to_json(json_buffer: &mut impl Write, variant: &Variant) -> Result<(), ArrowError> {\n    match variant {\n        Variant::Binary(bytes) => {\n            let base64_str = format_binary_base64(bytes);\n            let json_str = serde_json::to_string(&base64_str).map_err(|e| {\n                ArrowError::InvalidArgumentError(format!(\""JSON encoding error: {e}\""))\n            })?;\n            write!(json_buffer, \""{json_str}\"")?;\n        }\n        _ => {}\n    }\n    Ok(())\n}""}","{""commented_code"": ""let base64_str = format_binary_base64(bytes); // encode binary as base64""}",comment_generation
parquet-variant-json,"{""code"": ""obj_builder.finish()?;"", ""code_context"": ""use arrow_schema::ArrowError;\nuse parquet_variant::{ObjectBuilder, Variant, VariantBuilderExt, ListBuilder};\nuse serde_json::Value;\n\nfn append_json<'m, 'v>(json: &Value, builder: &mut impl VariantBuilderExt<'m, 'v>) -> Result<(), ArrowError> {\n    match json {\n        Value::Object(obj) => {\n            let mut obj_builder = builder.new_object();\n            for (key, value) in obj.iter() {\n                let mut field_builder = ObjectFieldBuilder {\n                    key,\n                    builder: &mut obj_builder,\n                };\n                append_json(value, &mut field_builder)?;\n            }\n            obj_builder.finish()?;\n        }\n        _ => {}\n    }\n    Ok(())\n}\n\nstruct ObjectFieldBuilder<'o, 'v, 's> {\n    key: &'s str,\n    builder: &'o mut ObjectBuilder<'v>,\n}\n\nimpl<'m, 'v> VariantBuilderExt<'m, 'v> for ObjectFieldBuilder<'_, '_, '_> {\n    fn append_value(&mut self, value: impl Into<Variant<'m, 'v>>) {\n        self.builder.insert(self.key, value);\n    }\n    fn new_list(&mut self) -> ListBuilder {\n        self.builder.new_list(self.key)\n    }\n    fn new_object(&mut self) -> ObjectBuilder<'v> {\n        self.builder.new_object(self.key)\n    }\n}""}","{""commented_code"": ""obj_builder.finish()?; // finalize the object builder""}",comment_generation
parquet-variant-json,"{""code"": ""variant_builder.append_value(Variant::Int8(127));"", ""code_context"": ""use arrow_schema::ArrowError;\nuse parquet_variant::{Variant, VariantBuilder};\n\n#[test]\nfn test_json_to_variant_int8_positive() -> Result<(), ArrowError> {\n    let mut variant_builder = VariantBuilder::new();\n    variant_builder.append_value(Variant::Int8(127));\n    let (metadata, value) = variant_builder.finish();\n    let variant = Variant::try_new(&metadata, &value)?;\n    assert_eq!(variant, Variant::Int8(127));\n    Ok(())\n}""}","{""commented_code"": ""variant_builder.append_value(Variant::Int8(127)); // add an i8 value to the variant""}",comment_generation
cairo-sys-rs,"{""code"": ""extern \""C\"" { pub fn cairo_create(target: *mut cairo_surface_t) -> *mut cairo_t; }"", ""code_context"": ""use libc::{c_double, c_int, c_void};\n\n#[repr(C)]\npub struct cairo_t {\n    _unused: [u8; 0],\n}\n\n#[repr(C)]\npub struct cairo_surface_t {\n    _unused: [u8; 0],\n}""}","{""summary"": ""Creates a new Cairo drawing context for the given surface.""}",code_summarization
cairo-sys-rs,"{""code"": ""extern \""C\"" { pub fn cairo_set_source_rgb(cr: *mut cairo_t, red: c_double, green: c_double, blue: c_double); }"", ""code_context"": ""use libc::{c_double, c_int, c_void};\n\n#[repr(C)]\npub struct cairo_t {\n    _unused: [u8; 0],\n}\n\n#[repr(C)]\npub struct cairo_surface_t {\n    _unused: [u8; 0],\n}""}","{""summary"": ""Sets the current source color of the Cairo context to the specified RGB values.""}",code_summarization
cairo-sys-rs,"{""code"": ""extern \""C\"" { pub fn cairo_set_source_surface(cr: *mut cairo_t, surface: *mut cairo_surface_t, x: c_double, y: c_double); }"", ""code_context"": ""use libc::{c_double, c_int, c_void};\n\n#[repr(C)]\npub struct cairo_t {\n    _unused: [u8; 0],\n}\n\n#[repr(C)]\npub struct cairo_surface_t {\n    _unused: [u8; 0],\n}""}","{""summary"": ""Sets the source pattern of the Cairo context to a surface with an optional offset.""}",code_summarization
cairo-sys-rs,"{""code"": ""extern \""C\"" { pub fn cairo_surface_create_for_rectangle(surface: *mut cairo_surface_t, x: c_double, y: c_double, width: c_double, height: c_double) -> *mut cairo_surface_t; }"", ""code_context"": ""use libc::{c_double, c_int, c_void};\n\n#[repr(C)]\npub struct cairo_t {\n    _unused: [u8; 0],\n}\n\n#[repr(C)]\npub struct cairo_surface_t {\n    _unused: [u8; 0],\n}""}","{""summary"": ""Creates a new surface representing a rectangular region of an existing surface.""}",code_summarization
fsevent-sys,"{""code"": ""impl FsEvent {\n    pub fn __placeholder__(&mut self, latency: cf::CFTimeInterval) {\n        self.latency = latency;\n    }\n}\n"", ""code_context"": ""use fsevent as fs;\nuse fsevent::core_foundation as cf;\n\npub struct FsEvent {\n    paths: Vec<String>,\n    since_when: fs::FSEventStreamEventId,\n    latency: cf::CFTimeInterval,\n    flags: fs::FSEventStreamCreateFlags,\n    runloop: Option<cf::CFRunLoopRef>,\n}\n""}","{""function_name"": ""set_latency""}",function_naming
fsevent-sys,"{""code"": ""impl FsEvent {\n    pub fn __placeholder__(&mut self, path: &str) -> Result<()> {\n        self.paths.push(path.to_string());\n        Ok(())\n    }\n}\n"", ""code_context"": ""use fsevent as fs;\nuse fsevent::core_foundation as cf;\n\npub struct FsEvent {\n    paths: Vec<String>,\n    since_when: fs::FSEventStreamEventId,\n    latency: cf::CFTimeInterval,\n    flags: fs::FSEventStreamCreateFlags,\n    runloop: Option<cf::CFRunLoopRef>,\n}\n\npub type Result<T> = std::result::Result<T, Error>;\n\n#[derive(Debug)]\npub struct Error { msg: String }\n""}","{""function_name"": ""add_watch_path""}",function_naming
fsevent-sys,"{""code"": ""impl FsEvent {\n    pub fn __placeholder__(&mut self, flags: fs::FSEventStreamCreateFlags) {\n        self.flags = flags;\n    }\n}\n"", ""code_context"": ""use fsevent as fs;\nuse fsevent::core_foundation as cf;\n\npub struct FsEvent {\n    paths: Vec<String>,\n    since_when: fs::FSEventStreamEventId,\n    latency: cf::CFTimeInterval,\n    flags: fs::FSEventStreamCreateFlags,\n    runloop: Option<cf::CFRunLoopRef>,\n}\n""}","{""function_name"": ""set_flags""}",function_naming
fsevent-sys,"{""code"": ""impl FsEvent {\n    pub fn __placeholder__(&self, event_sender: std::sync::mpsc::Sender<Event>) {\n        self.observe(event_sender);\n    }\n}\n"", ""code_context"": ""use fsevent as fs;\nuse fsevent::core_foundation as cf;\nuse std::sync::mpsc::Sender;\n\npub struct Event {\n    pub event_id: u64,\n    pub flag: StreamFlags,\n    pub path: String,\n}\n\nbitflags::bitflags! {\n    pub struct StreamFlags: u32 { const NONE = 0; }\n}\n\npub struct FsEvent {\n    paths: Vec<String>,\n    since_when: fs::FSEventStreamEventId,\n    latency: cf::CFTimeInterval,\n    flags: fs::FSEventStreamCreateFlags,\n    runloop: Option<cf::CFRunLoopRef>,\n}\n""}","{""function_name"": ""start_observing""}",function_naming
fsevent-sys,"{""code"": ""impl FsEvent {\n    pub fn __placeholder__(&mut self) {\n        self.shutdown_observe();\n    }\n}\n"", ""code_context"": ""use fsevent::core_foundation as cf;\n\npub struct FsEvent {\n    paths: Vec<String>,\n    since_when: u64,\n    latency: cf::CFTimeInterval,\n    flags: u32,\n    runloop: Option<cf::CFRunLoopRef>,\n}\n""}","{""function_name"": ""stop_monitoring""}",function_naming
fsevent-sys,"{""code_context"": ""use std::sync::mpsc::Sender;\nuse fsevent_sys as fs;\nuse fsevent_sys::core_foundation as cf;\nuse std::ptr;\n\npub struct FsEvent {\n    paths: Vec<String>,\n    since_when: fs::FSEventStreamEventId,\n    latency: cf::CFTimeInterval,\n    flags: fs::FSEventStreamCreateFlags,\n    runloop: Option<cf::CFRunLoopRef>,\n}\n\n#[derive(Debug)]\npub struct Event {\n    pub event_id: u64,\n    pub flag: StreamFlags,\n    pub path: String,\n}\n\nbitflags! {\n  #[repr(C)]\n  pub struct StreamFlags: u32 {\n    const NONE = 0x00000000;\n    const ITEM_CREATED = 0x00000100;\n    const ITEM_REMOVED = 0x00000200;\n    const ITEM_MODIFIED = 0x00001000;\n    const IS_DIR = 0x00020000;\n    const IS_FILE = 0x00010000;\n  }\n}\n\npub type Result<T> = std::result::Result<T, Error>;\n\n#[derive(Debug)]\npub struct Error {\n    msg: String,\n}\n\nimpl std::error::Error for Error {}\nimpl std::fmt::Display for Error {\n    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {\n        self.msg.fmt(f)\n    }\n}\n\nimpl From<std::sync::mpsc::RecvTimeoutError> for Error {\n    fn from(err: std::sync::mpsc::RecvTimeoutError) -> Error {\n        Error { msg: err.to_string() }\n    }\n}\n\npub struct CFRunLoopSendWrapper(cf::CFRunLoopRef);\nunsafe impl Send for CFRunLoopSendWrapper {}\n\nimpl FsEvent {\n    fn build_native_paths(&self) -> Result<cf::CFMutableArrayRef> { unimplemented!() }\n    fn internal_observe(\n        since_when: fs::FSEventStreamEventId,\n        latency: cf::CFTimeInterval,\n        flags: fs::FSEventStreamCreateFlags,\n        paths: cf::CFMutableArrayRef,\n        event_sender: Sender<Event>,\n        runloop_sender: Option<Sender<CFRunLoopSendWrapper>>,\n    ) -> Result<()> { unimplemented!() }\n}"", ""code_to_test"": ""impl FsEvent {\n    pub fn observe(&self, event_sender: Sender<Event>) {\n        let native_paths = self\n            .build_native_paths()\n            .expect(\""Unable to build CFMutableArrayRef of watched paths.\"");\n        Self::internal_observe(\n            self.since_when,\n            self.latency,\n            self.flags,\n            native_paths,\n            event_sender,\n            None,\n        )\n        .unwrap();\n    }\n}"", ""test_context"": ""use fsevent_sys::core_foundation as cf;\nuse fsevent::*;\nuse std::fs;\nuse std::fs::read_link;\nuse std::fs::OpenOptions;\nuse std::io::Write;\nuse std::path::{Component, PathBuf};\nuse std::thread;\nuse std::time::{Duration, SystemTime};\nuse std::sync::mpsc::{channel, Receiver};\n\nstruct CFRunLoopSendWrapper(cf::CFRunLoopRef);\nunsafe impl Send for CFRunLoopSendWrapper {}\n\nfn validate_recv(rx: Receiver<Event>, evs: Vec<(String, StreamFlags)>) {\n    let timeout: Duration = Duration::new(5, 0);\n    let deadline = SystemTime::now() + timeout;\n    let mut evs = evs.clone();\n    while SystemTime::now() < deadline {\n        if let Ok(actual) = rx.try_recv() {\n            let mut found: Option<usize> = None;\n            for i in 0..evs.len() {\n                let expected = evs.get(i).unwrap();\n                if actual.path == expected.0 && actual.flag == expected.1 {\n                    found = Some(i);\n                    break;\n                }\n            }\n            if let Some(i) = found {\n                evs.remove(i);\n            } else {\n                panic!(\""actual: {:?} not found in expected: {:?}\"", actual, evs);\n            }\n        }\n        if evs.is_empty() {\n            break;\n        }\n    }\n    assert!(evs.is_empty(), \""Some expected events did not occur before the test timedout:\\n\\t\\t{:?}\"", evs);\n}\n\nfn resolve_path(path: &str) -> PathBuf {\n    let mut out = PathBuf::new();\n    let buf = PathBuf::from(path);\n    for p in buf.components() {\n        match p {\n            Component::RootDir => out.push(\""/\""),\n            Component::Normal(osstr) => {\n                out.push(osstr);\n                if let Ok(real) = read_link(&out) {\n                    if real.is_relative() {\n                        out.pop();\n                        out.push(real);\n                    } else {\n                        out = real;\n                    }\n                }\n            }\n            _ => (),\n        }\n    }\n    out\n}\n\nfn internal_observe_folder(run_async: bool) {\n    unimplemented!();\n}\n\nfn internal_validate_watch_single_file(run_async: bool) {\n    unimplemented!();\n}""}","{""test_cases"": [""#[test]\nfn observe_folder_sync() {\n    internal_observe_folder(false);\n}"", ""#[test]\nfn validate_watch_single_file_sync() {\n    internal_validate_watch_single_file(false);\n}""]}",test_generation
fsevent-sys,"{""code_context"": ""use std::sync::mpsc::Sender;\nuse fsevent_sys as fs;\nuse fsevent_sys::core_foundation as cf;\nuse std::ptr;\n\npub struct FsEvent {\n    paths: Vec<String>,\n    since_when: fs::FSEventStreamEventId,\n    latency: cf::CFTimeInterval,\n    flags: fs::FSEventStreamCreateFlags,\n    runloop: Option<cf::CFRunLoopRef>,\n}\n\n#[derive(Debug)]\npub struct Event {\n    pub event_id: u64,\n    pub flag: StreamFlags,\n    pub path: String,\n}\n\nbitflags! {\n  #[repr(C)]\n  pub struct StreamFlags: u32 {\n    const NONE = 0x00000000;\n    const ITEM_CREATED = 0x00000100;\n    const ITEM_REMOVED = 0x00000200;\n    const ITEM_MODIFIED = 0x00001000;\n    const IS_DIR = 0x00020000;\n    const IS_FILE = 0x00010000;\n  }\n}\n\npub type Result<T> = std::result::Result<T, Error>;\n\n#[derive(Debug)]\npub struct Error {\n    msg: String,\n}\n\nimpl std::error::Error for Error {}\nimpl std::fmt::Display for Error {\n    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {\n        self.msg.fmt(f)\n    }\n}\n\nimpl From<std::sync::mpsc::RecvTimeoutError> for Error {\n    fn from(err: std::sync::mpsc::RecvTimeoutError) -> Error {\n        Error { msg: err.to_string() }\n    }\n}\n\npub struct CFRunLoopSendWrapper(cf::CFRunLoopRef);\nunsafe impl Send for CFRunLoopSendWrapper {}\n\nimpl FsEvent {\n    fn build_native_paths(&self) -> Result<cf::CFMutableArrayRef> { unimplemented!() }\n    fn internal_observe(\n        since_when: fs::FSEventStreamEventId,\n        latency: cf::CFTimeInterval,\n        flags: fs::FSEventStreamCreateFlags,\n        paths: cf::CFMutableArrayRef,\n        event_sender: Sender<Event>,\n        runloop_sender: Option<Sender<CFRunLoopSendWrapper>>,\n    ) -> Result<()> { unimplemented!() }\n}"", ""code_to_test"": ""impl FsEvent {\n    pub fn observe_async(&mut self, event_sender: Sender<Event>) -> Result<()> {\n        let (ret_tx, ret_rx) = std::sync::mpsc::channel();\n        let native_paths = self.build_native_paths()?;\n\n        struct CFMutableArraySendWrapper(cf::CFMutableArrayRef);\n        unsafe impl Send for CFMutableArraySendWrapper {}\n        let safe_native_paths = CFMutableArraySendWrapper(native_paths);\n\n        let since_when = self.since_when;\n        let latency = self.latency;\n        let flags = self.flags;\n\n        std::thread::spawn(move || {\n            Self::internal_observe(\n                since_when,\n                latency,\n                flags,\n                safe_native_paths.0,\n                event_sender,\n                Some(ret_tx),\n            )\n        });\n\n        self.runloop = Some(ret_rx.recv().unwrap().0);\n        Ok(())\n    }\n}"", ""test_context"": ""use fsevent_sys::core_foundation as cf;\nuse fsevent::*;\nuse std::fs;\nuse std::fs::read_link;\nuse std::fs::OpenOptions;\nuse std::io::Write;\nuse std::path::{Component, PathBuf};\nuse std::thread;\nuse std::time::{Duration, SystemTime};\nuse std::sync::mpsc::{channel, Receiver};\n\nstruct CFRunLoopSendWrapper(cf::CFRunLoopRef);\nunsafe impl Send for CFRunLoopSendWrapper {}\n\nfn validate_recv(rx: Receiver<Event>, evs: Vec<(String, StreamFlags)>) {\n    let timeout: Duration = Duration::new(5, 0);\n    let deadline = SystemTime::now() + timeout;\n    let mut evs = evs.clone();\n    while SystemTime::now() < deadline {\n        if let Ok(actual) = rx.try_recv() {\n            let mut found: Option<usize> = None;\n            for i in 0..evs.len() {\n                let expected = evs.get(i).unwrap();\n                if actual.path == expected.0 && actual.flag == expected.1 {\n                    found = Some(i);\n                    break;\n                }\n            }\n            if let Some(i) = found {\n                evs.remove(i);\n            } else {\n                panic!(\""actual: {:?} not found in expected: {:?}\"", actual, evs);\n            }\n        }\n        if evs.is_empty() {\n            break;\n        }\n    }\n    assert!(evs.is_empty(), \""Some expected events did not occur before the test timedout:\\n\\t\\t{:?}\"", evs);\n}\n\nfn resolve_path(path: &str) -> PathBuf {\n    let mut out = PathBuf::new();\n    let buf = PathBuf::from(path);\n    for p in buf.components() {\n        match p {\n            Component::RootDir => out.push(\""/\""),\n            Component::Normal(osstr) => {\n                out.push(osstr);\n                if let Ok(real) = read_link(&out) {\n                    if real.is_relative() {\n                        out.pop();\n                        out.push(real);\n                    } else {\n                        out = real;\n                    }\n                }\n            }\n            _ => (),\n        }\n    }\n    out\n}\n\nfn internal_observe_folder(run_async: bool) {\n    unimplemented!();\n}\n\nfn internal_validate_watch_single_file(run_async: bool) {\n    unimplemented!();\n}""}","{""test_cases"": [""#[test]\nfn observe_folder_async() {\n    internal_observe_folder(true);\n}"", ""#[test]\nfn validate_watch_single_file_async() {\n    internal_validate_watch_single_file(true);\n}""]}",test_generation
fsevent-sys,"{""code_context"": ""use std::sync::mpsc::Sender;\nuse fsevent_sys as fs;\nuse fsevent_sys::core_foundation as cf;\nuse std::ptr;\n\npub struct FsEvent {\n    paths: Vec<String>,\n    since_when: fs::FSEventStreamEventId,\n    latency: cf::CFTimeInterval,\n    flags: fs::FSEventStreamCreateFlags,\n    runloop: Option<cf::CFRunLoopRef>,\n}\n\n#[derive(Debug)]\npub struct Event {\n    pub event_id: u64,\n    pub flag: StreamFlags,\n    pub path: String,\n}\n\nbitflags! {\n  #[repr(C)]\n  pub struct StreamFlags: u32 {\n    const NONE = 0x00000000;\n    const ITEM_CREATED = 0x00000100;\n    const ITEM_REMOVED = 0x00000200;\n    const ITEM_MODIFIED = 0x00001000;\n    const IS_DIR = 0x00020000;\n    const IS_FILE = 0x00010000;\n  }\n}\n\npub type Result<T> = std::result::Result<T, Error>;\n\n#[derive(Debug)]\npub struct Error {\n    msg: String,\n}\n\nimpl std::error::Error for Error {}\nimpl std::fmt::Display for Error {\n    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {\n        self.msg.fmt(f)\n    }\n}\n\nimpl From<std::sync::mpsc::RecvTimeoutError> for Error {\n    fn from(err: std::sync::mpsc::RecvTimeoutError) -> Error {\n        Error { msg: err.to_string() }\n    }\n}\n\npub struct CFRunLoopSendWrapper(cf::CFRunLoopRef);\nunsafe impl Send for CFRunLoopSendWrapper {}"", ""code_to_test"": ""impl FsEvent {\n    pub fn append_path(&mut self, source: &str) -> Result<()> {\n        self.paths.push(source.to_string());\n        Ok(())\n    }\n}"", ""test_context"": ""use fsevent_sys::core_foundation as cf;\nuse fsevent::*;\nuse std::fs;\nuse std::fs::read_link;\nuse std::fs::OpenOptions;\nuse std::io::Write;\nuse std::path::{Component, PathBuf};\nuse std::thread;\nuse std::time::{Duration, SystemTime};\nuse std::sync::mpsc::{channel, Receiver};\n\nstruct CFRunLoopSendWrapper(cf::CFRunLoopRef);\nunsafe impl Send for CFRunLoopSendWrapper {}\n\nfn validate_recv(rx: Receiver<Event>, evs: Vec<(String, StreamFlags)>) {\n    let timeout: Duration = Duration::new(5, 0);\n    let deadline = SystemTime::now() + timeout;\n    let mut evs = evs.clone();\n    while SystemTime::now() < deadline {\n        if let Ok(actual) = rx.try_recv() {\n            let mut found: Option<usize> = None;\n            for i in 0..evs.len() {\n                let expected = evs.get(i).unwrap();\n                if actual.path == expected.0 && actual.flag == expected.1 {\n                    found = Some(i);\n                    break;\n                }\n            }\n            if let Some(i) = found {\n                evs.remove(i);\n            } else {\n                panic!(\""actual: {:?} not found in expected: {:?}\"", actual, evs);\n            }\n        }\n        if evs.is_empty() {\n            break;\n        }\n    }\n    assert!(evs.is_empty(), \""Some expected events did not occur before the test timedout:\\n\\t\\t{:?}\"", evs);\n}\n\nfn resolve_path(path: &str) -> PathBuf {\n    let mut out = PathBuf::new();\n    let buf = PathBuf::from(path);\n    for p in buf.components() {\n        match p {\n            Component::RootDir => out.push(\""/\""),\n            Component::Normal(osstr) => {\n                out.push(osstr);\n                if let Ok(real) = read_link(&out) {\n                    if real.is_relative() {\n                        out.pop();\n                        out.push(real);\n                    } else {\n                        out = real;\n                    }\n                }\n            }\n            _ => (),\n        }\n    }\n    out\n}\n\nfn internal_observe_folder(run_async: bool) {\n    unimplemented!();\n}\n\nfn internal_validate_watch_single_file(run_async: bool) {\n    unimplemented!();\n}""}","{""test_cases"": [""#[test]\nfn observe_folder_sync() {\n    internal_observe_folder(false);\n}"", ""#[test]\nfn observe_folder_async() {\n    internal_observe_folder(true);\n}""]}",test_generation
parquet-variant-json,"{""code"": ""pub fn json_to_variant(json: &str, builder: &mut VariantBuilder) -> Result<(), ArrowError> {\n    let json: Value = serde_json::from_str(json)\n        .map_err(|e| ArrowError::InvalidArgumentError(format!(\""JSON format error: {e}\"")))?;\n\n    build_json(&json, builder)?;\n    Ok(())\n}"", ""code_context"": ""use arrow_schema::ArrowError;\nuse parquet_variant::{VariantBuilder, VariantBuilderExt, ListBuilder, ObjectBuilder, Variant};\nuse serde_json::{Value, Number};\n\nfn build_json(json: &Value, builder: &mut VariantBuilder) -> Result<(), ArrowError> {\n    append_json(json, builder)?;\n    Ok(())\n}\n\nfn append_json<'m, 'v>(\n    json: &'v Value,\n    builder: &mut impl VariantBuilderExt<'m, 'v>,\n) -> Result<(), ArrowError> {\n    match json {\n        Value::Null => builder.append_value(Variant::Null),\n        Value::Bool(b) => builder.append_value(*b),\n        Value::Number(n) => {\n            builder.append_value(variant_from_number(n)?);\n        }\n        Value::String(s) => builder.append_value(s.as_str()),\n        Value::Array(arr) => {\n            let mut list_builder = builder.new_list();\n            for val in arr {\n                append_json(val, &mut list_builder)?;\n            }\n            list_builder.finish();\n        }\n        Value::Object(obj) => {\n            let mut obj_builder = builder.new_object();\n            for (key, value) in obj.iter() {\n                let mut field_builder = ObjectFieldBuilder { key, builder: &mut obj_builder };\n                append_json(value, &mut field_builder)?;\n            }\n            obj_builder.finish()?;\n        }\n    };\n    Ok(())\n}\n\nfn variant_from_number<'m, 'v>(n: &Number) -> Result<Variant<'m, 'v>, ArrowError> {\n    if let Some(i) = n.as_i64() {\n        if i as i8 as i64 == i {\n            Ok((i as i8).into())\n        } else if i as i16 as i64 == i {\n            Ok((i as i16).into())\n        } else if i as i32 as i64 == i {\n            Ok((i as i32).into())\n        } else {\n            Ok(i.into())\n        }\n    } else {\n        match n.as_f64() {\n            Some(f) => Ok(f.into()),\n            None => Err(ArrowError::InvalidArgumentError(format!(\""Failed to parse {n} as number\""))),\n        }\n    }\n}\n\nstruct ObjectFieldBuilder<'o, 'v, 's> {\n    key: &'s str,\n    builder: &'o mut ObjectBuilder<'v>,\n}\n\nimpl<'m, 'v> VariantBuilderExt<'m, 'v> for ObjectFieldBuilder<'_, '_, '_> {\n    fn append_value(&mut self, value: impl Into<Variant<'m, 'v>>) {\n        self.builder.insert(self.key, value);\n    }\n    fn new_list(&mut self) -> ListBuilder {\n        self.builder.new_list(self.key)\n    }\n    fn new_object(&mut self) -> ObjectBuilder {\n        self.builder.new_object(self.key)\n    }\n}""}","{""summary"": ""Parses a JSON string and populates a VariantBuilder with the corresponding Variant representation.""}",code_summarization
parquet-variant-json,"{""code"": ""fn variant_from_number<'m, 'v>(n: &Number) -> Result<Variant<'m, 'v>, ArrowError> {\n    if let Some(i) = n.as_i64() {\n        if i as i8 as i64 == i {\n            Ok((i as i8).into())\n        } else if i as i16 as i64 == i {\n            Ok((i as i16).into())\n        } else if i as i32 as i64 == i {\n            Ok((i as i32).into())\n        } else {\n            Ok(i.into())\n        }\n    } else {\n        match n.as_f64() {\n            Some(f) => Ok(f.into()),\n            None => Err(ArrowError::InvalidArgumentError(format!(\""Failed to parse {n} as number\""))),\n        }\n    }\n}"", ""code_context"": ""use arrow_schema::ArrowError;\nuse parquet_variant::Variant;\nuse serde_json::Number;""}","{""summary"": ""Converts a serde_json::Number into the smallest fitting Variant integer type or a double-precision float.""}",code_summarization
parquet-variant-json,"{""code"": ""fn convert_object_to_json(buffer: &mut impl Write, obj: &VariantObject) -> Result<(), ArrowError> {\n    write!(buffer, \""{{\"")?;\n    let mut first = true;\n    for (key, value) in obj.iter() {\n        if !first {\n            write!(buffer, \"",\"")?;\n        }\n        first = false;\n        let json_key = serde_json::to_string(key).map_err(|e| ArrowError::InvalidArgumentError(format!(\""JSON key encoding error: {e}\"")))?;\n        write!(buffer, \""{json_key}:\"")?;\n        variant_to_json(buffer, &value)?;\n    }\n    write!(buffer, \""}}\"")?;\n    Ok(())\n}"", ""code_context"": ""use arrow_schema::ArrowError;\nuse parquet_variant::{Variant, VariantObject};\nuse std::io::Write;\n\nfn variant_to_json(_buf: &mut impl Write, _variant: &Variant) -> Result<(), ArrowError> {\n    // Minimal stub for compilation; real implementation handles all Variant cases.\n    Ok(())\n}""}","{""summary"": ""Writes a VariantObject as a JSON object string, escaping keys and recursively converting values.""}",code_summarization
zvariant_utils,"{""code_context"": null, ""code_to_test"": ""pub fn pascal_or_camel_case(s: &str, is_pascal_case: bool) -> String {\n    let mut result = String::new();\n    let mut capitalize = is_pascal_case;\n    let mut first = true;\n    for ch in s.chars() {\n        if ch == '_' || ch == '-' {\n            capitalize = true;\n        } else if capitalize {\n            result.push(ch.to_ascii_uppercase());\n            capitalize = false;\n        } else if first && !is_pascal_case {\n            result.push(ch.to_ascii_lowercase());\n        } else {\n            result.push(ch);\n        }\n\n        if first {\n            first = false;\n        }\n    }\n    result\n}"", ""test_context"": ""use super::*;""}","{""test_cases"": [""#[test]\nfn test_pascal_case() {\n    assert_eq!(\""FooBar\"", pascal_or_camel_case(\""foo_bar\"", true));\n    assert_eq!(\""FooBar\"", pascal_or_camel_case(\""fooBar\"", true));\n    assert_eq!(\""FooBar\"", pascal_or_camel_case(\""foo-bar\"", true));\n    assert_eq!(\""FooBar\"", pascal_or_camel_case(\""FooBar\"", true));\n}"", ""#[test]\nfn test_camel_case() {\n    assert_eq!(\""fooBar\"", pascal_or_camel_case(\""foo_bar\"", false));\n    assert_eq!(\""fooBar\"", pascal_or_camel_case(\""fooBar\"", false));\n    assert_eq!(\""fooBar\"", pascal_or_camel_case(\""foo-bar\"", false));\n    assert_eq!(\""fooBar\"", pascal_or_camel_case(\""FooBar\"", false));\n}""]}",test_generation
zvariant_utils,"{""code_context"": null, ""code_to_test"": ""pub fn snake_or_kebab_case(s: &str, is_snake_case: bool) -> String {\n    let mut result = String::new();\n    for ch in s.chars() {\n        if ch.is_ascii_uppercase() && !result.is_empty() {\n            if is_snake_case {\n                result.push('_');\n            } else {\n                result.push('-');\n            }\n        };\n\n        if ch == '_' || ch == '-' {\n            if is_snake_case {\n                result.push('_');\n            } else {\n                result.push('-');\n            }\n        } else {\n            result.push(ch.to_ascii_lowercase());\n        }\n    }\n    result\n}"", ""test_context"": ""use super::*;""}","{""test_cases"": [""#[test]\nfn test_snake_case() {\n    assert_eq!(\""foo_bar\"", snake_or_kebab_case(\""foo_bar\"", true));\n    assert_eq!(\""foo_bar\"", snake_or_kebab_case(\""fooBar\"", true));\n    assert_eq!(\""foo_bar\"", snake_or_kebab_case(\""foo-bar\"", true));\n    assert_eq!(\""foo_bar\"", snake_or_kebab_case(\""FooBar\"", true));\n}"", ""#[test]\nfn test_kebab_case() {\n    assert_eq!(\""foo-bar\"", snake_or_kebab_case(\""foo_bar\"", false));\n    assert_eq!(\""foo-bar\"", snake_or_kebab_case(\""fooBar\"", false));\n    assert_eq!(\""foo-bar\"", snake_or_kebab_case(\""foo-bar\"", false));\n    assert_eq!(\""foo-bar\"", snake_or_kebab_case(\""FooBar\"", false));\n}""]}",test_generation
zvariant_utils,"{""code_context"": ""#[derive(Debug, Default, PartialEq, Eq, Copy, Clone)]\npub enum Format {\n    #[default]\n    DBus,\n    #[cfg(feature = \""gvariant\"")]\n    GVariant,\n}"", ""code_to_test"": ""impl std::fmt::Display for Format {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            Format::DBus => write!(f, \""D-Bus\""),\n            #[cfg(feature = \""gvariant\"")]\n            Format::GVariant => write!(f, \""GVariant\""),\n        }\n    }\n}"", ""test_context"": ""use super::*;""}","{""test_cases"": [""#[test]\nfn test_format_display() {\n    assert_eq!(\""D-Bus\"", format!(\""{}\"", Format::DBus));\n}""]}",test_generation
objc2-app-kit,"{""code_before"": ""pub fn main() {\n    let mut data = Vec::new();\n    for i in 0..100 {\n        data.push(i);\n    }\n    println!(\""{}\"", data);\n}"", ""code_context"": null}","{""rationale"": ""Uses an iterator to create the vector, which is more idiomatic and avoids the manual push loop, improving readability and performance."", ""code_after"": ""pub fn main() {\n    let data: Vec<_> = (0..100).collect();\n    println!(\""{}\"", data);\n}""}",code_refactoring
objc2-app-kit,"{""code_before"": ""let mut count = 0;\nwhile count < 100 {\n    count += 1;\n}\nprintln!(\""{}\"", count);"", ""code_context"": null}","{""rationale"": ""Replaces a while loop with a for loop, which is more idiomatic and eliminates manual condition checking."", ""code_after"": ""let mut count = 0;\nfor _ in 0..100 {\n    count += 1;\n}\nprintln!(\""{}\"", count);""}",code_refactoring
objc2-app-kit,"{""code_before"": ""fn format_string(s: &str) -> String {\n    let mut result = String::new();\n    for c in s.chars() {\n        result.push(c);\n    }\n    result\n}"", ""code_context"": null}","{""rationale"": ""Uses `chars().collect()` to build the string, removing the manual loop and allocation, making it more concise and idiomatic."", ""code_after"": ""fn format_string(s: &str) -> String {\n    s.chars().collect()\n}""}",code_refactoring
objc2-app-kit,"{""code_before"": ""fn sum_numbers(numbers: &[i32]) -> i32 {\n    let mut sum = 0;\n    for &num in numbers.iter() {\n        sum += num;\n    }\n    sum\n}"", ""code_context"": null}","{""rationale"": ""Leverages the standard library `sum` iterator adapter, eliminating manual accumulation and improving readability."", ""code_after"": ""fn sum_numbers(numbers: &[i32]) -> i32 {\n    numbers.iter().sum()\n}""}",code_refactoring
objc2-app-kit,"{""code_before"": ""let mut result = String::new();\nfor word in text.split_whitespace() {\n    result.push_str(word);\n}"", ""code_context"": null}","{""rationale"": ""Collects the iterator directly into a `String`, removing the explicit mutable accumulation."", ""code_after"": ""let result: String = text.split_whitespace().collect();""}",code_refactoring
objc2-app-kit,"{""code_before"": ""if let Some(index) = vec.iter().position(|&x| x == value) {\n    vec.remove(index);\n}"", ""code_context"": null}","{""rationale"": ""Uses `swap_remove` to delete the element without preserving order, which is O(1) instead of O(n) for `remove`."", ""code_after"": ""if let Some(index) = vec.iter().position(|&x| x == value) {\n    vec.swap_remove(index);\n}""}",code_refactoring
objc2-app-kit,"{""code_before"": ""let mut result = Vec::new();\nfor number in numbers.iter() {\n    if *number > 0 {\n        result.push(number);\n    }\n}"", ""code_context"": null}","{""rationale"": ""Replaces manual loop with `filter` and `collect`, making the intent clear and avoiding explicit pushes."", ""code_after"": ""let result: Vec<_> = numbers.iter().filter(|&&x| x > 0).cloned().collect();""}",code_refactoring
objc2-app-kit,"{""code_before"": ""let mut result = Vec::new();\nfor i in 0..array.len() {\n    if array[i] % 2 == 0 {\n        result.push(array[i]);\n    }\n}"", ""code_context"": null}","{""rationale"": ""Uses iterator methods to filter even elements, removing manual index handling and improving safety."", ""code_after"": ""let result: Vec<_> = array.iter().filter(|&&x| x % 2 == 0).cloned().collect();""}",code_refactoring
objc2-app-kit,"{""code_before"": ""pub fn some_function() {\n    let mut data = vec![];\n    for i in 0..100 {\n        data.push(i);\n    }\n    // Do something with data\n}"", ""code_context"": null}","{""rationale"": ""Replaces manual vector construction with a direct iterator collection, reducing boilerplate and improving clarity."", ""code_after"": ""pub fn some_function() -> Vec<i32> {\n    (0..100).collect()\n}""}",code_refactoring
objc2-app-kit,"{""code_before"": ""let mut data = Vec::new();\nfor i in 0..100 {\n    data.push(i);\n}\n// Do something with data"", ""code_context"": null}","{""rationale"": ""Creates the vector via iterator collection instead of a manual push loop, making the code more idiomatic."", ""code_after"": ""let data: Vec<_> = (0..100).collect();\n// Do something with data""}",code_refactoring
objc2-app-kit,"{""code_before"": ""use std::string::String;\n\npub fn example() {\n    let mut result = String::new();\n    for i in 0..1000 {\n        result.push_str(&format!(\""Value: {}\"", i));\n    }\n}"", ""code_context"": null}","{""rationale"": ""Pre‑allocates capacity for the string, avoiding repeated reallocations and improving performance for large concatenations."", ""code_after"": ""use std::string::String;\n\npub fn example() {\n    let mut result = String::with_capacity(1000 * 20);\n    for i in 0..1000 {\n        result.push_str(&format!(\""Value: {}\"", i));\n    }\n}""}",code_refactoring
objc2-app-kit,"{""code_before"": ""fn process_data(data: &[i32]) -> i32 {\n    let mut sum = 0;\n    for &x in data {\n        sum += x;\n    }\n    sum\n}"", ""code_context"": null}","{""rationale"": ""Uses the iterator `sum` method to compute the total, removing the mutable accumulator and making the function concise."", ""code_after"": ""fn process_data(data: &[i32]) -> i32 {\n    data.iter().sum()\n}""}",code_refactoring
objc2-app-kit,"{""code_before"": ""fn calculate_area(width: f64, height: f64) -> f64 {\n  let area = width * height;\n  area\n}"", ""code_context"": null}","{""rationale"": ""Eliminates an unnecessary temporary variable, simplifying the function while preserving behavior."", ""code_after"": ""fn calculate_area(width: f64, height: f64) -> f64 {\n  width * height\n}""}",code_refactoring
solana-tpu-client,"{""title"": ""Send a batch of transactions with retry logic"", ""description"": ""A developer wants to send a batch of transactions using the TPU client and ensure reliability by retrying the whole batch a configurable number of times if any send fails."", ""code_context"": ""use solana_tpu_client::TpuClient;\nuse solana_transaction::Transaction;\nuse solana_transaction_error::{TransportResult, TransportError};""}","{""code"": ""pub async fn send_transaction_batch_with_retry(\n    &self,\n    transactions: &[Transaction],\n    max_retries: usize,\n) -> TransportResult<()> {\n    let mut attempt = 0;\n    loop {\n        match self.try_send_transaction_batch(transactions).await {\n            Ok(_) => return Ok(()),\n            Err(e) => {\n                attempt += 1;\n                if attempt > max_retries {\n                    return Err(e);\n                }\n                tokio::time::sleep(std::time::Duration::from_millis(200)).await;\n            }\n        }\n    }\n}""}",code_generation
solana-tpu-client,"{""title"": ""Send a transaction with a custom timeout"", ""description"": ""A user needs to send a transaction via the TPU client but wants to enforce a per‑send timeout to handle environments with high network latency."", ""code_context"": ""use solana_tpu_client::TpuClient;\nuse solana_transaction::Transaction;\nuse solana_transaction_error::{TransportResult, TransportError};\nuse futures_util::future::join_all;""}","{""code"": ""pub async fn send_transaction_with_timeout(\n    &self,\n    transaction: &Transaction,\n    timeout_duration: std::time::Duration,\n) -> TransportResult<()> {\n    let wire = bincode::serialize(transaction).expect(\""serialization should succeed\"");\n    let leaders = self.leader_tpu_service.unique_leader_tpu_sockets(self.fanout_slots);\n    let futures = leaders.iter().map(|addr| {\n        tokio::time::timeout(\n            timeout_duration,\n            send_wire_transaction_to_addr(&self.connection_cache, addr, wire.clone()),\n        )\n    });\n    let results: Vec<TransportResult<()>> = futures_util::future::join_all(futures).await;\n    let mut last_err: Option<TransportError> = None;\n    let mut some_success = false;\n    for r in results {\n        match r {\n            Ok(Ok(())) => some_success = true,\n            Ok(Err(e)) => if last_err.is_none() { last_err = Some(e); },\n            Err(_) => if last_err.is_none() { last_err = Some(TransportError::Custom(\""Timed out\"".into())); },\n        }\n    }\n    if some_success {\n        Ok(())\n    } else {\n        Err(last_err.unwrap_or_else(|| std::io::Error::other(\""No sends attempted\"").into()))\n    }\n}""}",code_generation
solana-tpu-client,"{""title"": ""Monitor transaction confirmations with a progress bar"", ""description"": ""After sending a batch of transactions, a developer wants to track their confirmations using the RPC client and display a progress indicator to give users feedback."", ""code_context"": ""use solana_tpu_client::TpuClient;\nuse solana_transaction::Signature;\nuse solana_transaction_error::TransportResult;\nuse indicatif::{ProgressBar, ProgressStyle};\nuse tokio::time::sleep;\nuse std::time::Duration;""}","{""code"": ""pub async fn monitor_transaction_confirmations(\n    tpu_client: &TpuClient<_, _, _>,\n    signatures: &[Signature],\n) -> TransportResult<()> {\n    let progress = ProgressBar::new(signatures.len() as u64);\n    progress.set_style(ProgressStyle::default_bar()\n        .template(\""{spinner:.green} [{elapsed_precise}] [{wide_bar}] {pos}/{len} ({eta})\"")\n        .progress_chars(\""#>-\""));\n    let rpc = tpu_client.rpc_client();\n    for &sig in signatures {\n        loop {\n            match rpc.get_signature_status(sig).await {\n                Ok(status_opt) => {\n                    if let Some(status) = status_opt {\n                        if status.satisfies_commitment(rpc.commitment()) {\n                            progress.inc(1);\n                            break;\n                        }\n                    }\n                }\n                Err(e) => {\n                    eprintln!(\""Error fetching status: {}\"", e);\n                }\n            }\n            tokio::time::sleep(std::time::Duration::from_secs(2)).await;\n        }\n    }\n    progress.finish_and_clear();\n    Ok(())\n}""}",code_generation
solana-tpu-client,"{""title"": ""Efficient transaction serialization helper"", ""description"": ""A developer wants a small utility that serializes a Solana transaction using bincode without extra allocations, to be reused wherever a wire format is needed."", ""code_context"": ""use bincode;\nuse solana_transaction::Transaction;""}","{""code"": ""pub fn serialize_transaction(tx: &Transaction) -> Result<Vec<u8>, bincode::Error> {\n    bincode::serialize(tx)\n}""}",code_generation
agave-thread-manager,"{""code"": ""impl ThreadManager {\n    pub fn new(config: ThreadManagerConfig) -> anyhow::Result<Self> {\n        let mut core_allocations = HashMap::<String, Vec<usize>>::new();\n        Self::set_process_affinity(&config)?;\n        let mut manager = ThreadManagerInner::default();\n        manager.populate_mappings(&config);\n        for (name, cfg) in config.native_configs.iter() {\n            let nrt = NativeThreadRuntime::new(name.clone(), cfg.clone());\n            manager.native_thread_runtimes.insert(name.clone(), nrt);\n        }\n        for (name, cfg) in config.rayon_configs.iter() {\n            let rrt = RayonRuntime::new(name.clone(), cfg.clone())?;\n            manager.rayon_runtimes.insert(name.clone(), rrt);\n        }\n        for (name, cfg) in config.tokio_configs.iter() {\n            let tokiort = TokioRuntime::new(name.clone(), cfg.clone())?;\n            core_allocations.insert(name.clone(), cfg.core_allocation.as_core_mask_vector());\n            manager.tokio_runtimes.insert(name.clone(), tokiort);\n        }\n        Ok(Self {\n            inner: Arc::new(manager),\n        })\n    }\n}"", ""code_context"": ""use std::collections::HashMap;\nuse std::sync::Arc;\nuse anyhow::Result;\nuse serde::{Serialize, Deserialize};\n\npub const MAX_THREAD_NAME_CHARS: usize = 12;\n\n#[derive(Clone, Debug, Serialize, Deserialize)]\npub struct NativeConfig {\n    pub core_allocation: CoreAllocation,\n    pub max_threads: usize,\n    pub priority: u8,\n    pub policy: String,\n    pub stack_size_bytes: usize,\n}\n\n#[derive(Clone, Debug, Serialize, Deserialize)]\npub struct RayonConfig {\n    pub worker_threads: usize,\n    pub core_allocation: CoreAllocation,\n    pub priority: u8,\n    pub policy: String,\n    pub stack_size_bytes: usize,\n}\n\n#[derive(Clone, Debug, Serialize, Deserialize)]\npub struct TokioConfig {\n    pub worker_threads: usize,\n    pub max_blocking_threads: usize,\n    pub priority: u8,\n    pub policy: String,\n    pub stack_size_bytes: usize,\n    pub event_interval: u32,\n    pub core_allocation: CoreAllocation,\n}\n\n#[derive(Clone, Debug, Serialize, Deserialize)]\npub struct ThreadManagerConfig {\n    pub native_configs: HashMap<String, NativeConfig>,\n    pub native_runtime_mapping: HashMap<String, String>,\n    pub rayon_configs: HashMap<String, RayonConfig>,\n    pub rayon_runtime_mapping: HashMap<String, String>,\n    pub tokio_configs: HashMap<String, TokioConfig>,\n    pub tokio_runtime_mapping: HashMap<String, String>,\n    pub default_core_allocation: CoreAllocation,\n}\n\npub struct ThreadManagerInner {\n    pub tokio_runtimes: HashMap<String, TokioRuntime>,\n    pub tokio_runtime_mapping: HashMap<String, String>,\n    pub native_thread_runtimes: HashMap<String, NativeThreadRuntime>,\n    pub native_runtime_mapping: HashMap<String, String>,\n    pub rayon_runtimes: HashMap<String, RayonRuntime>,\n    pub rayon_runtime_mapping: HashMap<String, String>,\n}\n\npub struct ThreadManager {\n    inner: Arc<ThreadManagerInner>,\n}\n\npub struct NativeThreadRuntime;\npub struct RayonRuntime;\npub struct TokioRuntime;\n\npub enum CoreAllocation {\n    OsDefault,\n    PinnedCores { min: usize, max: usize },\n    DedicatedCoreSet { min: usize, max: usize },\n}""}","{""summary"": ""Creates a new ThreadManager by initializing native, rayon, and tokio runtimes according to the provided configuration.""}",code_summarization
agave-thread-manager,"{""code"": ""impl NativeThreadRuntime {\n    pub fn spawn_named<F, T>(&self, name: String, f: F) -> anyhow::Result<JoinHandle<T>>\n    where\n        F: FnOnce() -> T,\n        F: Send + 'static,\n        T: Send + 'static,\n    {\n        debug_assert!(name.len() < MAX_THREAD_NAME_CHARS, \""Thread name too long\"");\n        let spawned = self.running_count.load(Ordering::Relaxed);\n        if spawned >= self.config.max_threads {\n            bail!(\""All allowed threads in this pool are already spawned\"");\n        }\n\n        let core_alloc = self.config.core_allocation.clone();\n        let priority = self.config.priority;\n        let policy = parse_policy(&self.config.policy);\n        let chosen_cores_mask = Mutex::new(self.config.core_allocation.as_core_mask_vector());\n        let jh = std::thread::Builder::new()\n            .name(name)\n            .stack_size(self.config.stack_size_bytes)\n            .spawn(move || {\n                apply_policy(&core_alloc, policy, priority, &chosen_cores_mask);\n                f()\n            })?;\n        let rc = self.running_count.fetch_add(1, Ordering::Relaxed);\n        datapoint_info!(\""thread-manager-native\"", (\""threads-running\"", rc as i64, i64),);\n        Ok(JoinHandle {\n            std_handle: Some(jh),\n            running_count: self.running_count.clone(),\n        })\n    }\n}"", ""code_context"": ""use std::sync::{Arc, Mutex};\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse anyhow::{Result, bail};\nuse solana_metrics::datapoint_info;\n\npub const MAX_THREAD_NAME_CHARS: usize = 12;\n\n#[derive(Clone, Debug, Serialize, Deserialize)]\npub struct NativeConfig {\n    pub core_allocation: CoreAllocation,\n    pub max_threads: usize,\n    pub priority: u8,\n    pub policy: String,\n    pub stack_size_bytes: usize,\n}\n\npub enum CoreAllocation {\n    OsDefault,\n    PinnedCores { min: usize, max: usize },\n    DedicatedCoreSet { min: usize, max: usize },\n}\n\nfn parse_policy(_p: &str) -> ThreadSchedulePolicy { ThreadSchedulePolicy {} }\nfn apply_policy(_alloc: &CoreAllocation, _policy: ThreadSchedulePolicy, _priority: u8, _mask: &Mutex<Vec<usize>>) {}\n\npub struct ThreadSchedulePolicy;\n\npub struct JoinHandle<T> {\n    std_handle: Option<std::thread::JoinHandle<T>>,\n    running_count: Arc<AtomicUsize>,\n}""}","{""summary"": ""Spawns a new thread with a specified name, applying the configured core allocation, priority, and scheduling policy.""}",code_summarization
agave-thread-manager,"{""code"": ""pub fn workload_main(ports: &[u16], tasks: usize) -> anyhow::Result<Stats> {\n    struct ControlBlock {\n        start_time: std::time::Instant,\n        requests: AtomicUsize,\n        cumulative_latency_us: AtomicUsize,\n    }\n\n    let control_block = Arc::new(ControlBlock {\n        start_time: std::time::Instant::now(),\n        requests: AtomicUsize::new(0),\n        cumulative_latency_us: AtomicUsize::new(0),\n    });\n\n    async fn connection(port: u16, control_block: Arc<ControlBlock>) -> anyhow::Result<()> {\n        let sa = SocketAddr::new(IpAddr::V4(Ipv4Addr::UNSPECIFIED), port);\n        let stream = TcpStream::connect(sa).await?;\n\n        let (mut request_sender, connection) = hyper::client::conn::handshake(stream).await?;\n        tokio::spawn(async move {\n            let _ = connection.await;\n        });\n\n        let path = \""/\"";\n        while control_block.start_time.elapsed() < Duration::from_secs(TEST_SECONDS) {\n            let req = Request::builder()\n                .uri(path)\n                .method(\""GET\"")\n                .body(Body::from(\""\""))?;\n            let start = Instant::now();\n            let res = timeout(Duration::from_millis(100), request_sender.send_request(req)).await;\n            let res = match res {\n                Ok(res) => res?,\n                Err(_) => {\n                    anyhow::bail!(\""Timeout on request!\"")\n                }\n            };\n            let _ = res.body();\n            if res.status() != 200 {\n                anyhow::bail!(\""Got error from server\"");\n            }\n\n            control_block\n                .cumulative_latency_us\n                .fetch_add(start.elapsed().as_micros() as usize, Ordering::Relaxed);\n            control_block.requests.fetch_add(1, Ordering::Relaxed);\n            request_sender.ready().await?;\n        }\n        Ok(())\n    }\n\n    let mut join_set = JoinSet::new();\n    for port in ports {\n        info!(\""Starting load generation on port {port}\"");\n        for _t in 0..tasks {\n            join_set.spawn(connection(*port, control_block.clone()));\n        }\n    }\n\n    while let Some(jr) = join_set.join_next().await {\n        jr??;\n    }\n\n    let requests = control_block.requests.load(Ordering::Relaxed);\n    let latency_accumulator_us = control_block.cumulative_latency_us.load(Ordering::Relaxed);\n    Ok(Stats {\n        requests_per_second: requests as f32 / TEST_SECONDS as f32,\n        #[allow(clippy::arithmetic_side_effects)]\n        latency_s: (latency_accumulator_us / requests) as f32 / 1e6,\n    })\n}"", ""code_context"": ""use std::sync::Arc;\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse std::time::Duration;\nuse anyhow::Result;\nuse hyper::{Body, Request};\nuse tokio::net::TcpStream;\nuse tokio::time::timeout;\nuse tokio::task::JoinSet;\nuse std::net::{IpAddr, Ipv4Addr, SocketAddr};\nuse std::time::Instant;\n\nconst TEST_SECONDS: u64 = 10;\n\npub struct Stats {\n    pub latency_s: f32,\n    pub requests_per_second: f32,\n}""}","{""summary"": ""Generates HTTP load on given ports, measures request latency and throughput, and returns aggregated statistics.""}",code_summarization
solana-remote-wallet,"{""code"": ""pub fn is_valid_ledger(vendor_id: u16, product_id: u16) -> bool {\n    let product_ids = [\n        LEDGER_NANO_S_PIDS,\n        LEDGER_NANO_X_PIDS,\n        LEDGER_NANO_S_PLUS_PIDS,\n        LEDGER_STAX_PIDS,\n        LEDGER_FLEX_PIDS,\n    ];\n    vendor_id == LEDGER_VID && product_ids.iter().any(|pids| pids.contains(&product_id))\n}"", ""code_context"": ""const LEDGER_VID: u16 = 0x2c97;\nconst LEDGER_NANO_S_PIDS: [u16; 33] = [\n    0x0001, 0x1000, 0x1001, 0x1002, 0x1003, 0x1004, 0x1005, 0x1006, 0x1007, 0x1008, 0x1009, 0x100a,\n    0x100b, 0x100c, 0x100d, 0x100e, 0x100f, 0x1010, 0x1011, 0x1012, 0x1013, 0x1014, 0x1015, 0x1016,\n    0x1017, 0x1018, 0x1019, 0x101a, 0x101b, 0x101c, 0x101d, 0x101e, 0x101f,\n];\nconst LEDGER_NANO_X_PIDS: [u16; 33] = [\n    0x0004, 0x4000, 0x4001, 0x4002, 0x4003, 0x4004, 0x4005, 0x4006, 0x4007, 0x4008, 0x4009, 0x400a,\n    0x400b, 0x400c, 0x400d, 0x400e, 0x400f, 0x4010, 0x4011, 0x4012, 0x4013, 0x4014, 0x4015, 0x4016,\n    0x4017, 0x4018, 0x4019, 0x401a, 0x401b, 0x401c, 0x401d, 0x401e, 0x401f,\n];\nconst LEDGER_NANO_S_PLUS_PIDS: [u16; 33] = [\n    0x0005, 0x5000, 0x5001, 0x5002, 0x5003, 0x5004, 0x5005, 0x5006, 0x5007, 0x5008, 0x5009, 0x500a,\n    0x500b, 0x500c, 0x500d, 0x500e, 0x500f, 0x5010, 0x5011, 0x5012, 0x5013, 0x5014, 0x5015, 0x5016,\n    0x5017, 0x5018, 0x5019, 0x501a, 0x501b, 0x501c, 0x501d, 0x501e, 0x501f,\n];\nconst LEDGER_STAX_PIDS: [u16; 33] = [\n    0x0006, 0x6000, 0x6001, 0x6002, 0x6003, 0x6004, 0x6005, 0x6006, 0x6007, 0x6008, 0x6009, 0x600a,\n    0x600b, 0x600c, 0x600d, 0x600e, 0x600f, 0x6010, 0x6011, 0x6012, 0x6013, 0x6014, 0x6015, 0x6016,\n    0x6017, 0x6018, 0x6019, 0x601a, 0x601b, 0x601c, 0x601d, 0x601e, 0x601f,\n];\nconst LEDGER_FLEX_PIDS: [u16; 33] = [\n    0x0007, 0x7000, 0x7001, 0x7002, 0x7003, 0x7004, 0x7005, 0x7006, 0x7007, 0x7008, 0x7009, 0x700a,\n    0x700b, 0x700c, 0x700d, 0x700e, 0x700f, 0x7010, 0x7011, 0x7012, 0x7013, 0x7014, 0x7015, 0x7016,\n    0x7017, 0x7018, 0x7019, 0x701a, 0x701b, 0x701c, 0x701d, 0x701e, 0x701f,\n];""}","{""docstring"": ""Check if the detected device is a valid `Ledger device` by checking both the product ID and the vendor ID""}",docstring_generation
solana-remote-wallet,"{""code"": ""pub fn is_valid_hid_device(usage_page: u16, interface_number: i32) -> bool {\n    usage_page == HID_GLOBAL_USAGE_PAGE || interface_number == HID_USB_DEVICE_CLASS as i32\n}"", ""code_context"": ""const HID_GLOBAL_USAGE_PAGE: u16 = 0xFF00;\nconst HID_USB_DEVICE_CLASS: u8 = 0;""}","{""docstring"": ""Helper to determine if a device is a valid HID""}",docstring_generation
solana-remote-wallet,"{""code"": ""impl RemoteWalletInfo {\n    pub fn get_pretty_path(&self) -> String {\n        format!(\""usb://{}/{:?}\"", self.manufacturer, self.pubkey,)\n    }\n}"", ""code_context"": ""#[derive(Clone, Copy, Debug, PartialEq, Eq)]\npub enum Manufacturer {\n    Unknown,\n    Ledger,\n}\n\n#[derive(Debug, Default, Clone)]\npub struct RemoteWalletInfo {\n    pub model: String,\n    pub manufacturer: Manufacturer,\n    pub serial: String,\n    pub host_device_path: String,\n    pub pubkey: solana_pubkey::Pubkey,\n    pub error: Option<RemoteWalletError>,\n}\n\n#[derive(thiserror::Error, Debug, Clone)]\npub enum RemoteWalletError {\n    #[error(\""no device found\"")]\n    NoDeviceFound,\n    #[error(\""invalid input: {0}\"")]\n    InvalidInput(String),\n    #[error(\""protocol error: {0}\"")]\n    Protocol(&'static str),\n    #[error(\""ledger error\"")]\n    LedgerError,\n}""}","{""docstring"": ""Get a pretty path string for the remote wallet info""}",docstring_generation
solana-storage-proto,"{""code"": ""impl From<generated::Reward> for Reward {\n    fn from(reward: generated::Reward) -> Self {\n        Self {\n            pubkey: reward.pubkey,\n            lamports: reward.lamports,\n            post_balance: reward.post_balance,\n            reward_type: match reward.reward_type {\n                0 => None,\n                1 => Some(RewardType::Fee),\n                2 => Some(RewardType::Rent),\n                3 => Some(RewardType::Staking),\n                4 => Some(RewardType::Voting),\n                _ => None,\n            },\n            commission: reward.commission.parse::<u8>().ok(),\n        }\n    }\n}"", ""code_context"": null}","{""summary"": ""Converts a generated protobuf Reward into the native Reward struct, mapping fields and translating the reward type enum.""}",code_summarization
solana-storage-proto,"{""code"": ""impl From<Reward> for generated::Reward {\n    fn from(reward: Reward) -> Self {\n        Self {\n            pubkey: reward.pubkey,\n            lamports: reward.lamports,\n            post_balance: reward.post_balance,\n            reward_type: match reward.reward_type {\n                None => generated::RewardType::Unspecified,\n                Some(RewardType::Fee) => generated::RewardType::Fee,\n                Some(RewardType::Rent) => generated::RewardType::Rent,\n                Some(RewardType::Staking) => generated::RewardType::Staking,\n                Some(RewardType::Voting) => generated::RewardType::Voting,\n            } as i32,\n            commission: reward.commission.map(|c| c.to_string()).unwrap_or_default(),\n        }\n    }\n}"", ""code_context"": null}","{""summary"": ""Converts a native Reward into its protobuf representation, encoding the reward type as an integer and formatting the commission.""}",code_summarization
solana-storage-proto,"{""code"": ""impl From<generated::MessageHeader> for MessageHeader {\n    fn from(value: generated::MessageHeader) -> Self {\n        Self {\n            num_required_signatures: value.num_required_signatures as u8,\n            num_readonly_signed_accounts: value.num_readonly_signed_accounts as u8,\n            num_readonly_unsigned_accounts: value.num_readonly_unsigned_accounts as u8,\n        }\n    }\n}"", ""code_context"": null}","{""summary"": ""Transforms a protobuf MessageHeader into the native MessageHeader by casting its numeric fields to u8.""}",code_summarization
slab,"{""code"": ""impl<T> Slab<T> {\n    pub const fn new() -> Self {\n        Self {\n            entries: Vec::new(),\n            next: 0,\n            len: 0,\n        }\n    }\n}"", ""code_context"": ""use alloc::vec::Vec;\n\npub struct Slab<T> {\n    entries: Vec<Entry<T>>, \n    len: usize,\n    next: usize,\n}\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}""}","{""docstring"": ""Construct a new, empty `Slab`.\n\n# Examples\n\n```rust\n# use slab::*;\nlet slab: Slab<i32> = Slab::new();\n```""}",docstring_generation
slab,"{""code"": ""impl<T> Slab<T> {\n    pub fn with_capacity(capacity: usize) -> Slab<T> {\n        Slab {\n            entries: Vec::with_capacity(capacity),\n            len: 0,\n            next: 0,\n        }\n    }\n}"", ""code_context"": ""use alloc::vec::Vec;\n\npub struct Slab<T> {\n    entries: Vec<Entry<T>>, \n    len: usize,\n    next: usize,\n}\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}""}","{""docstring"": ""Construct a new, empty `Slab` with the specified capacity.\n\nThe returned slab will be able to store exactly `capacity` without reallocating. If `capacity` is 0, the slab will not allocate.\n\nIt is important to note that this function does not specify the *length* of the returned slab, but only the capacity. For an explanation of the difference between length and capacity, see the module documentation.""}",docstring_generation
slab,"{""code"": ""impl<T> Slab<T> {\n    pub fn capacity(&self) -> usize {\n        self.entries.capacity()\n    }\n}"", ""code_context"": ""use alloc::vec::Vec;\n\npub struct Slab<T> {\n    entries: Vec<Entry<T>>, \n    len: usize,\n    next: usize,\n}\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}""}","{""docstring"": ""Return the number of values the slab can store without reallocating.\n\n# Examples\n\n```rust\n# use slab::*;\nlet slab: Slab<i32> = Slab::with_capacity(10);\nassert_eq!(slab.capacity(), 10);\n```""}",docstring_generation
slab,"{""code"": ""impl<T> Slab<T> {\n    pub fn get(&self, key: usize) -> Option<&T> {\n        match self.entries.get(key) {\n            Some(Entry::Occupied(val)) => Some(val),\n            _ => None,\n        }\n    }\n}"", ""code_context"": ""use alloc::vec::Vec;\n\npub struct Slab<T> {\n    entries: Vec<Entry<T>>, \n    len: usize,\n    next: usize,\n}\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}""}","{""docstring"": ""Return a reference to the value associated with the given key.\n\nIf the given key is not associated with a value, then `None` is returned.\n\n# Examples\n\n```rust\n# use slab::*;\nlet mut slab = Slab::new();\nlet key = slab.insert(1);\nassert_eq!(slab.get(key), Some(&1));\n```""}",docstring_generation
slab,"{""code"": ""impl<'a, T> VacantEntry<'a, T> {\n    pub fn insert(self, val: T) -> &'a mut T {\n        self.slab.insert_at(self.key, val);\n        match self.slab.entries.get_mut(self.key) {\n            Some(&mut Entry::Occupied(ref mut v)) => v,\n            _ => unreachable!(),\n        }\n    }\n}"", ""code_context"": ""use alloc::vec::Vec;\n\npub struct Slab<T> {\n    entries: Vec<Entry<T>>, \n    len: usize,\n    next: usize,\n}\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}\n\npub struct VacantEntry<'a, T> {\n    slab: &'a mut Slab<T>,\n    key: usize,\n}""}","{""docstring"": ""Insert a value in the entry, returning a mutable reference to the value.\n\nTo get the key associated with the value, use `key` prior to calling `insert`.\n\n# Examples\n\n```rust\n# use slab::*;\nlet mut slab = Slab::new();\nlet entry = slab.vacant_entry();\nlet key = entry.key();\nentry.insert((key, \""hello\""));\nassert_eq!(slab[key].1, \""hello\"");\n```""}",docstring_generation
strsim,"{""code"": ""let a = \""hamming\"";"", ""code_context"": ""pub enum StrSimError { DifferentLengthArgs, }\nimpl std::fmt::Display for StrSimError { fn fmt(&self, fmt: &mut std::fmt::Formatter<'_>) -> Result<(), std::fmt::Error> { let text = match self { StrSimError::DifferentLengthArgs => \""Differing length arguments provided\"", }; write!(fmt, \""{}\"", text) } }\nimpl std::error::Error for StrSimError {}\npub type HammingResult = Result<usize, StrSimError>;\nfn generic_hamming<Iter1, Iter2, Elem1, Elem2>(a: Iter1, b: Iter2) -> HammingResult\nwhere\n    Iter1: IntoIterator<Item = Elem1>,\n    Iter2: IntoIterator<Item = Elem2>,\n    Elem1: PartialEq<Elem2>,\n{\n    let (mut ita, mut itb) = (a.into_iter(), b.into_iter());\n    let mut count = 0;\n    loop {\n        match (ita.next(), itb.next()) {\n            (Some(x), Some(y)) => {\n                if x != y { count += 1; }\n            }\n            (None, None) => return Ok(count),\n            _ => return Err(StrSimError::DifferentLengthArgs),\n        }\n    }\n}\nfn hamming(a: &str, b: &str) -> HammingResult { generic_hamming(a.chars(), b.chars()) }""}","{""next_api_call"": ""strsim::hamming(a, \""hammers\"");""}",api_usage_prediction
strsim,"{""code"": ""let s1 = \""Friedrich Nietzsche\"";"", ""code_context"": ""use std::cmp::{max, min};\npub struct StringWrapper<'a>(&'a str);\nimpl<'a, 'b> std::iter::IntoIterator for &'a StringWrapper<'b> { type Item = char; type IntoIter = std::str::Chars<'b>; fn into_iter(self) -> Self::IntoIter { self.0.chars() } }\nfn generic_jaro<'a, 'b, Iter1, Iter2, Elem1, Elem2>(a: &'a Iter1, b: &'b Iter2) -> f64\nwhere\n    &'a Iter1: IntoIterator<Item = Elem1>,\n    &'b Iter2: IntoIterator<Item = Elem2>,\n    Elem1: PartialEq<Elem2>,\n{\n    let a_len = a.into_iter().count();\n    let b_len = b.into_iter().count();\n    if a_len == 0 && b_len == 0 { return 1.0; } else if a_len == 0 || b_len == 0 { return 0.0; }\n    let mut search_range = max(a_len, b_len) / 2;\n    search_range = search_range.saturating_sub(1);\n    let mut flags_memory = vec![false; a_len + b_len];\n    let (a_flags, b_flags) = flags_memory.split_at_mut(a_len);\n    let mut matches = 0_usize;\n    for (i, a_elem) in a.into_iter().enumerate() {\n        let min_bound = if i > search_range { i - search_range } else { 0 };\n        let max_bound = min(b_len, i + search_range + 1);\n        for (j, b_elem) in b.into_iter().enumerate().take(max_bound) {\n            if min_bound <= j && a_elem == b_elem && !b_flags[j] {\n                a_flags[i] = true;\n                b_flags[j] = true;\n                matches += 1;\n                break;\n            }\n        }\n    }\n    let mut transpositions = 0_usize;\n    if matches != 0 {\n        let mut b_iter = b_flags.iter().zip(b);\n        for (a_flag, ch1) in a_flags.iter().zip(a) {\n            if *a_flag {\n                loop {\n                    if let Some((b_flag, ch2)) = b_iter.next() {\n                        if !*b_flag { continue; }\n                        if ch1 != ch2 { transpositions += 1; }\n                        break;\n                    }\n                }\n            }\n        }\n        transpositions /= 2;\n    }\n    if matches == 0 { 0.0 } else { ((matches as f64 / a_len as f64) + (matches as f64 / b_len as f64) + ((matches - transpositions) as f64 / matches as f64)) / 3.0 }\n}\nfn jaro(a: &str, b: &str) -> f64 { generic_jaro(&StringWrapper(a), &StringWrapper(b)) }""}","{""next_api_call"": ""strsim::jaro(s1, \""Jean-Paul Sartre\"");""}",api_usage_prediction
strsim,"{""code"": ""let s = \""kitten\"";"", ""code_context"": ""use std::cmp::min;\npub struct StringWrapper<'a>(&'a str);\nimpl<'a, 'b> std::iter::IntoIterator for &'a StringWrapper<'b> { type Item = char; type IntoIter = std::str::Chars<'b>; fn into_iter(self) -> Self::IntoIter { self.0.chars() } }\nfn generic_levenshtein<'a, 'b, Iter1, Iter2, Elem1, Elem2>(a: &'a Iter1, b: &'b Iter2) -> usize\nwhere\n    &'a Iter1: IntoIterator<Item = Elem1>,\n    &'b Iter2: IntoIterator<Item = Elem2>,\n    Elem1: PartialEq<Elem2>,\n{\n    let b_len = b.into_iter().count();\n    let mut cache: Vec<usize> = (1..b_len + 1).collect();\n    let mut result = b_len;\n    for (i, a_elem) in a.into_iter().enumerate() {\n        result = i + 1;\n        let mut distance_b = i;\n        for (j, b_elem) in b.into_iter().enumerate() {\n            let cost = usize::from(a_elem != b_elem);\n            let distance_a = distance_b + cost;\n            distance_b = cache[j];\n            result = min(result + 1, min(distance_a, distance_b + 1));\n            cache[j] = result;\n        }\n    }\n    result\n}\nfn levenshtein(a: &str, b: &str) -> usize { generic_levenshtein(&StringWrapper(a), &StringWrapper(b)) }""}","{""next_api_call"": ""strsim::levenshtein(s, \""sitting\"");""}",api_usage_prediction
strsim,"{""code"": ""let a = \""french\"";"", ""code_context"": ""use std::collections::HashMap;\nuse std::str::Chars;\nfn bigrams(s: &str) -> impl Iterator<Item = (char, char)> + '_ { s.chars().zip(s.chars().skip(1)) }\nfn sorensen_dice(a: &str, b: &str) -> f64 {\n    let a: String = a.chars().filter(|&x| !char::is_whitespace(x)).collect();\n    let b: String = b.chars().filter(|&x| !char::is_whitespace(x)).collect();\n    if a == b { return 1.0; }\n    if a.len() < 2 || b.len() < 2 { return 0.0; }\n    let mut a_bigrams: HashMap<(char, char), usize> = HashMap::new();\n    for bigram in bigrams(&a) { *a_bigrams.entry(bigram).or_insert(0) += 1; }\n    let mut intersection_size = 0_usize;\n    for bigram in bigrams(&b) {\n        a_bigrams.entry(bigram).and_modify(|bi| {\n            if *bi > 0 { *bi -= 1; intersection_size += 1; }\n        });\n    }\n    (2 * intersection_size) as f64 / (a.len() + b.len() - 2) as f64\n}""}","{""next_api_call"": ""strsim::sorensen_dice(a, \""quebec\"");""}",api_usage_prediction
strsim,"{""code"": ""pub fn hamming(a: &str, b: &str) -> HammingResult {\n    generic_hamming(a.chars(), b.chars())\n}"", ""code_context"": ""pub type HammingResult = Result<usize, StrSimError>;\n\n#[derive(Debug, PartialEq)]\npub enum StrSimError {\n    DifferentLengthArgs,\n}\n\nimpl std::fmt::Display for StrSimError {\n    fn fmt(&self, fmt: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let text = match self {\n            StrSimError::DifferentLengthArgs => \""Differing length arguments provided\"",\n        };\n        write!(fmt, \""{}\"", text)\n    }\n}\n\nimpl std::error::Error for StrSimError {}\n\npub fn generic_hamming<Iter1, Iter2, Elem1, Elem2>(a: Iter1, b: Iter2) -> HammingResult\nwhere\n    Iter1: IntoIterator<Item = Elem1>,\n    Iter2: IntoIterator<Item = Elem2>,\n    Elem1: PartialEq<Elem2>,\n{\n    let (mut ita, mut itb) = (a.into_iter(), b.into_iter());\n    let mut count = 0;\n    loop {\n        match (ita.next(), itb.next()) {\n            (Some(x), Some(y)) => {\n                if x != y {\n                    count += 1;\n                }\n            }\n            (None, None) => return Ok(count),\n            _ => return Err(StrSimError::DifferentLengthArgs),\n        }\n    }\n}""}","{""docstring"": ""Calculates the number of positions in the two strings where the characters differ. Returns an error if the strings have different lengths.\n\n```rust\nuse strsim::{hamming, StrSimError::DifferentLengthArgs};\n\nassert_eq!(Ok(3), hamming(\""hamming\"", \""hammers\""));\n\nassert_eq!(Err(DifferentLengthArgs), hamming(\""hamming\"", \""ham\""));\n```""}",docstring_generation
strsim,"{""code"": ""pub fn jaro(a: &str, b: &str) -> f64 {\n    generic_jaro(&StringWrapper(a), &StringWrapper(b))\n}"", ""code_context"": ""struct StringWrapper<'a>(&'a str);\n\nimpl<'a, 'b> std::iter::IntoIterator for &'a StringWrapper<'b> {\n    type Item = char;\n    type IntoIter = std::str::Chars<'b>;\n\n    fn into_iter(self) -> Self::IntoIter {\n        self.0.chars()\n    }\n}\n\npub fn generic_jaro<'a, 'b, Iter1, Iter2, Elem1, Elem2>(a: &'a Iter1, b: &'b Iter2) -> f64\nwhere\n    &'a Iter1: IntoIterator<Item = Elem1>,\n    &'b Iter2: IntoIterator<Item = Elem2>,\n    Elem1: PartialEq<Elem2>,\n{\n    let a_len = a.into_iter().count();\n    let b_len = b.into_iter().count();\n\n    if a_len == 0 && b_len == 0 {\n        return 1.0;\n    } else if a_len == 0 || b_len == 0 {\n        return 0.0;\n    }\n\n    let mut search_range = std::cmp::max(a_len, b_len) / 2;\n    search_range = search_range.saturating_sub(1);\n\n    let mut flags_memory = vec![false; a_len + b_len];\n    let (a_flags, b_flags) = flags_memory.split_at_mut(a_len);\n\n    let mut matches = 0_usize;\n\n    for (i, a_elem) in a.into_iter().enumerate() {\n        let min_bound = if i > search_range { i - search_range } else { 0 };\n        let max_bound = std::cmp::min(b_len, i + search_range + 1);\n\n        for (j, b_elem) in b.into_iter().enumerate().take(max_bound) {\n            if min_bound <= j && a_elem == b_elem && !b_flags[j] {\n                a_flags[i] = true;\n                b_flags[j] = true;\n                matches += 1;\n                break;\n            }\n        }\n    }\n\n    let mut transpositions = 0_usize;\n    if matches != 0 {\n        let mut b_iter = b_flags.iter().zip(b);\n        for (a_flag, ch1) in a_flags.iter().zip(a) {\n            if *a_flag {\n                loop {\n                    if let Some((b_flag, ch2)) = b_iter.next() {\n                        if !*b_flag {\n                            continue;\n                        }\n                        if ch1 != ch2 {\n                            transpositions += 1;\n                        }\n                        break;\n                    }\n                }\n            }\n        }\n    }\n    transpositions /= 2;\n\n    if matches == 0 {\n        0.0\n    } else {\n        ((matches as f64 / a_len as f64)\n            + (matches as f64 / b_len as f64)\n            + ((matches - transpositions) as f64 / matches as f64))\n            / 3.0\n    }\n}""}","{""docstring"": ""Calculates the Jaro similarity between two strings. The returned value is between 0.0 and 1.0 (higher value means more similar).\n\n```rust\nuse strsim::jaro;\n\nassert!((0.392 - jaro(\""Friedrich Nietzsche\"", \""Jean-Paul Sartre\"")).abs() < 0.001);\n```""}",docstring_generation
strsim,"{""code"": ""pub fn normalized_levenshtein(a: &str, b: &str) -> f64 {\n    if a.is_empty() && b.is_empty() {\n        return 1.0;\n    }\n    1.0 - (levenshtein(a, b) as f64) / (a.chars().count().max(b.chars().count()) as f64)\n}"", ""code_context"": ""pub fn levenshtein(a: &str, b: &str) -> usize {\n    generic_levenshtein(&StringWrapper(a), &StringWrapper(b))\n}\n\nstruct StringWrapper<'a>(&'a str);\n\nimpl<'a, 'b> std::iter::IntoIterator for &'a StringWrapper<'b> {\n    type Item = char;\n    type IntoIter = std::str::Chars<'b>;\n\n    fn into_iter(self) -> Self::IntoIter {\n        self.0.chars()\n    }\n}\n\npub fn generic_levenshtein<'a, 'b, Iter1, Iter2, Elem1, Elem2>(a: &'a Iter1, b: &'b Iter2) -> usize\nwhere\n    &'a Iter1: IntoIterator<Item = Elem1>,\n    &'b Iter2: IntoIterator<Item = Elem2>,\n    Elem1: PartialEq<Elem2>,\n{\n    let b_len = b.into_iter().count();\n\n    let mut cache: Vec<usize> = (1..b_len + 1).collect();\n\n    let mut result = b_len;\n\n    for (i, a_elem) in a.into_iter().enumerate() {\n        result = i + 1;\n        let mut distance_b = i;\n\n        for (j, b_elem) in b.into_iter().enumerate() {\n            let cost = usize::from(a_elem != b_elem);\n            let distance_a = distance_b + cost;\n            distance_b = cache[j];\n            result = std::cmp::min(result + 1, std::cmp::min(distance_a, distance_b + 1));\n            cache[j] = result;\n        }\n    }\n\n    result\n}""}","{""docstring"": ""Calculates a normalized score of the Levenshtein algorithm between 0.0 and 1.0 (inclusive), where 1.0 means the strings are the same.\n\n```rust\nuse strsim::normalized_levenshtein;\n\nassert!((normalized_levenshtein(\""kitten\"", \""sitting\"") - 0.57142).abs() < 0.00001);\nassert!((normalized_levenshtein(\""\"", \""\"") - 1.0).abs() < 0.00001);\nassert!(normalized_levenshtein(\""\"", \""second\"").abs() < 0.00001);\nassert!(normalized_levenshtein(\""first\"", \""\"").abs() < 0.00001);\nassert!((normalized_levenshtein(\""string\"", \""string\"") - 1.0).abs() < 0.00001);\n```""}",docstring_generation
strsim,"{""code"": ""pub fn sorensen_dice(a: &str, b: &str) -> f64 {\n    let a: String = a.chars().filter(|&x| !char::is_whitespace(x)).collect();\n    let b: String = b.chars().filter(|&x| !char::is_whitespace(x)).collect();\n\n    if a == b {\n        return 1.0;\n    }\n\n    if a.len() < 2 || b.len() < 2 {\n        return 0.0;\n    }\n\n    let mut a_bigrams: HashMap<(char, char), usize> = HashMap::new();\n\n    for bigram in bigrams(&a) {\n        *a_bigrams.entry(bigram).or_insert(0) += 1;\n    }\n\n    let mut intersection_size = 0_usize;\n\n    for bigram in bigrams(&b) {\n        a_bigrams.entry(bigram).and_modify(|bi| {\n            if *bi > 0 {\n                *bi -= 1;\n                intersection_size += 1;\n            }\n        });\n    }\n\n    (2 * intersection_size) as f64 / (a.len() + b.len() - 2) as f64\n}"", ""code_context"": ""fn bigrams(s: &str) -> impl Iterator<Item = (char, char)> + '_ {\n    s.chars().zip(s.chars().skip(1))\n}\n\nuse std::collections::HashMap;""}","{""docstring"": ""Calculates a Sørensen-Dice similarity distance using bigrams. See <https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient>.\n\n```rust\nuse strsim::sorensen_dice;\n\nassert_eq!(1.0, sorensen_dice(\""\"", \""\""));\nassert_eq!(0.0, sorensen_dice(\""\"", \""a\""));\nassert_eq!(0.0, sorensen_dice(\""french\"", \""quebec\""));\nassert_eq!(1.0, sorensen_dice(\""ferris\"", \""ferris\""));\nassert_eq!(0.8888888888888888, sorensen_dice(\""feris\"", \""ferris\""));\n```""}",docstring_generation
memoffset,"{""query"": ""How can I get the byte offset of a struct field using the memoffset crate?"", ""code_context"": null}","{""code_snippet"": ""use memoffset::offset_of;\n\n#[repr(C)]\nstruct Header {\n    id: u32,\n    length: u16,\n    flags: u8,\n}\n\nfn main() {\n    let offset = offset_of!(Header, length);\n    println!(\""Offset of length: {}\"", offset);\n}""}",code_search
memoffset,"{""query"": ""How do I obtain the span of a field in a packed struct with memoffset?"", ""code_context"": null}","{""code_snippet"": ""use memoffset::span_of;\n\n#[repr(C, packed)]\nstruct Packet {\n    start: u8,\n    payload: [u8; 128],\n    checksum: u16,\n}\n\nfn main() {\n    let range = span_of!(Packet, payload);\n    println!(\""Payload span: {:?} bytes\"", range);\n}""}",code_search
memoffset,"{""query"": ""How can I calculate the offset of a field in a tuple struct using memoffset?"", ""code_context"": ""#[repr(C)]\nstruct Point(i32, i32);""}","{""code_snippet"": ""use memoffset::offset_of_tuple;\n\nfn main() {\n    let offset = offset_of_tuple!(Point, 1);\n    println!(\""Offset of y: {}\"", offset);\n}""}",code_search
memoffset,"{""query"": ""How do I get the offset of a member in a C-repr union using memoffset?"", ""code_context"": ""#[repr(C)]\nunion Data {\n    i: u32,\n    f64: f64,\n    bytes: [u8; 8],\n}""}","{""code_snippet"": ""use memoffset::offset_of_union;\n\nfn main() {\n    let offset = offset_of_union!(Data, f64);\n    println!(\""Offset of f64: {}\"", offset);\n}""}",code_search
strsim,"{""code_before"": ""pub fn generic_hamming<Iter1, Iter2, Elem1, Elem2>(a: Iter1, b: Iter2) -> HammingResult\nwhere\n    Iter1: IntoIterator<Item = Elem1>,\n    Iter2: IntoIterator<Item = Elem2>,\n    Elem1: PartialEq<Elem2>,\n{\n    let (mut ita, mut itb) = (a.into_iter(), b.into_iter());\n    let mut count = 0;\n    loop {\n        match (ita.next(), itb.next()) {\n            (Some(x), Some(y)) => {\n                if x != y {\n                    count += 1;\n                }\n            }\n            (None, None) => return Ok(count),\n            _ => return Err(StrSimError::DifferentLengthArgs),\n        }\n    }\n}"", ""code_context"": ""use std::char;\nuse std::collections::HashMap;\n\n#[derive(Debug, PartialEq)]\npub enum StrSimError { DifferentLengthArgs }\n\nimpl std::fmt::Display for StrSimError {\n    fn fmt(&self, fmt: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let text = match self { StrSimError::DifferentLengthArgs => \""Differing length arguments provided\"", };\n        write!(fmt, \""{}\"", text)\n    }\n}\n\nimpl std::error::Error for StrSimError {}\n\npub type HammingResult = Result<usize, StrSimError>;\n\nfn bigrams(s: &str) -> impl Iterator<Item = (char, char)> + '_ {\n    s.chars().zip(s.chars().skip(1))\n}\n\nfn generic_levenshtein<'a, 'b, Iter1, Iter2, Elem1, Elem2>(a: &'a Iter1, b: &'b Iter2) -> usize\nwhere\n    &'a Iter1: IntoIterator<Item = Elem1>,\n    &'b Iter2: IntoIterator<Item = Elem2>,\n    Elem1: PartialEq<Elem2>,\n{\n    0\n}\n\nfn levenshtein(a: &str, b: &str) -> usize {\n    generic_levenshtein(&StringWrapper(a), &StringWrapper(b))\n}\n\nstruct StringWrapper<'a>(&'a str);\nimpl<'a, 'b> IntoIterator for &'a StringWrapper<'b> {\n    type Item = char;\n    type IntoIter = std::str::Chars<'b>;\n    fn into_iter(self) -> Self::IntoIter { self.0.chars() }\n}""}","{""code_after"": ""pub fn generic_hamming<Iter1, Iter2, Elem1, Elem2>(a: Iter1, b: Iter2) -> HammingResult\nwhere\n    Iter1: IntoIterator<Item = Elem1>,\n    Iter2: IntoIterator<Item = Elem2>,\n    Elem1: PartialEq<Elem2>,\n{\n    let mut ita = a.into_iter();\n    let mut itb = b.into_iter();\n    let mut count = 0;\n    for (x, y) in ita.by_ref().zip(itb.by_ref()) {\n        if x != y {\n            count += 1;\n        }\n    }\n    if ita.next().is_some() || itb.next().is_some() {\n        Err(StrSimError::DifferentLengthArgs)\n    } else {\n        Ok(count)\n    }\n}"", ""review_comment"": ""Replaced the manual loop with a zip iterator, making the logic clearer and reducing boilerplate. The post‑loop length check now uses iterator state to detect mismatched lengths, improving readability without changing behavior.""}",code_review
strsim,"{""code_before"": ""pub fn sorensen_dice(a: &str, b: &str) -> f64 {\n    let a: String = a.chars().filter(|&x| !char::is_whitespace(x)).collect();\n    let b: String = b.chars().filter(|&x| !char::is_whitespace(x)).collect();\n\n    if a == b {\n        return 1.0;\n    }\n\n    if a.len() < 2 || b.len() < 2 {\n        return 0.0;\n    }\n\n    let mut a_bigrams: HashMap<(char, char), usize> = HashMap::new();\n\n    for bigram in bigrams(&a) {\n        *a_bigrams.entry(bigram).or_insert(0) += 1;\n    }\n\n    let mut intersection_size = 0_usize;\n\n    for bigram in bigrams(&b) {\n        a_bigrams.entry(bigram).and_modify(|bi| {\n            if *bi > 0 {\n                *bi -= 1;\n                intersection_size += 1;\n            }\n        });\n    }\n\n    (2 * intersection_size) as f64 / (a.len() + b.len() - 2) as f64\n}"", ""code_context"": ""use std::char;\nuse std::collections::HashMap;\n\n#[derive(Debug, PartialEq)]\npub enum StrSimError { DifferentLengthArgs }\n\nimpl std::fmt::Display for StrSimError {\n    fn fmt(&self, fmt: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let text = match self { StrSimError::DifferentLengthArgs => \""Differing length arguments provided\"", };\n        write!(fmt, \""{}\"", text)\n    }\n}\n\nimpl std::error::Error for StrSimError {}\n\npub type HammingResult = Result<usize, StrSimError>;\n\nfn bigrams(s: &str) -> impl Iterator<Item = (char, char)> + '_ {\n    s.chars().zip(s.chars().skip(1))\n}\n\nfn generic_levenshtein<'a, 'b, Iter1, Iter2, Elem1, Elem2>(a: &'a Iter1, b: &'b Iter2) -> usize\nwhere\n    &'a Iter1: IntoIterator<Item = Elem1>,\n    &'b Iter2: IntoIterator<Item = Elem2>,\n    Elem1: PartialEq<Elem2>,\n{\n    0\n}\n\nfn levenshtein(a: &str, b: &str) -> usize {\n    generic_levenshtein(&StringWrapper(a), &StringWrapper(b))\n}\n\nstruct StringWrapper<'a>(&'a str);\nimpl<'a, 'b> IntoIterator for &'a StringWrapper<'b> {\n    type Item = char;\n    type IntoIter = std::str::Chars<'b>;\n    fn into_iter(self) -> Self::IntoIter { self.0.chars() }\n}""}","{""code_after"": ""pub fn sorensen_dice(a: &str, b: &str) -> f64 {\n    let a_chars: Vec<char> = a.chars().filter(|c| !c.is_whitespace()).collect();\n    let b_chars: Vec<char> = b.chars().filter(|c| !c.is_whitespace()).collect();\n\n    if a_chars == b_chars {\n        return 1.0;\n    }\n\n    if a_chars.len() < 2 || b_chars.len() < 2 {\n        return 0.0;\n    }\n\n    let mut a_bigrams: HashMap<(char, char), usize> = HashMap::new();\n\n    for i in 0..a_chars.len() - 1 {\n        let bigram = (a_chars[i], a_chars[i + 1]);\n        *a_bigrams.entry(bigram).or_insert(0) += 1;\n    }\n\n    let mut intersection_size = 0_usize;\n\n    for i in 0..b_chars.len() - 1 {\n        let bigram = (b_chars[i], b_chars[i + 1]);\n        if let Some(count) = a_bigrams.get_mut(&bigram) {\n            if *count > 0 {\n                *count -= 1;\n                intersection_size += 1;\n            }\n        }\n    }\n\n    (2 * intersection_size) as f64 / (a_chars.len() + b_chars.len() - 2) as f64\n}"", ""review_comment"": ""Switched from allocating two intermediate `String`s to `Vec<char>` buffers, eliminating unnecessary UTF‑8 to UTF‑8 conversions. The bigram loops now work directly on the character vectors, reducing heap allocations and improving cache locality.""}",code_review
strsim,"{""code_before"": ""pub fn normalized_levenshtein(a: &str, b: &str) -> f64 {\n    if a.is_empty() && b.is_empty() {\n        return 1.0;\n    }\n    1.0 - (levenshtein(a, b) as f64) / (a.chars().count().max(b.chars().count()) as f64)\n}"", ""code_context"": ""use std::char;\nuse std::collections::HashMap;\n\n#[derive(Debug, PartialEq)]\npub enum StrSimError { DifferentLengthArgs }\n\nimpl std::fmt::Display for StrSimError {\n    fn fmt(&self, fmt: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let text = match self { StrSimError::DifferentLengthArgs => \""Differing length arguments provided\"", };\n        write!(fmt, \""{}\"", text)\n    }\n}\n\nimpl std::error::Error for StrSimError {}\n\npub type HammingResult = Result<usize, StrSimError>;\n\nfn bigrams(s: &str) -> impl Iterator<Item = (char, char)> + '_ {\n    s.chars().zip(s.chars().skip(1))\n}\n\nfn generic_levenshtein<'a, 'b, Iter1, Iter2, Elem1, Elem2>(a: &'a Iter1, b: &'b Iter2) -> usize\nwhere\n    &'a Iter1: IntoIterator<Item = Elem1>,\n    &'b Iter2: IntoIterator<Item = Elem2>,\n    Elem1: PartialEq<Elem2>,\n{\n    0\n}\n\nfn levenshtein(a: &str, b: &str) -> usize {\n    generic_levenshtein(&StringWrapper(a), &StringWrapper(b))\n}\n\nstruct StringWrapper<'a>(&'a str);\nimpl<'a, 'b> IntoIterator for &'a StringWrapper<'b> {\n    type Item = char;\n    type IntoIter = std::str::Chars<'b>;\n    fn into_iter(self) -> Self::IntoIter { self.0.chars() }\n}""}","{""code_after"": ""pub fn normalized_levenshtein(a: &str, b: &str) -> f64 {\n    if a.is_empty() && b.is_empty() {\n        return 1.0;\n    }\n    let max_len = a.chars().count().max(b.chars().count()) as f64;\n    1.0 - (levenshtein(a, b) as f64) / max_len\n}"", ""review_comment"": ""Cached the maximum length in a local variable to avoid calling `chars().count()` twice, which reduces redundant iteration over the input strings and slightly improves performance.""}",code_review
strsim,"{""code"": ""let mut flags_memory = vec![false; a_len + b_len];"", ""code_context"": ""pub fn generic_jaro<'a, 'b, Iter1, Iter2, Elem1, Elem2>(a: &'a Iter1, b: &'b Iter2) -> f64\nwhere\n    &'a Iter1: IntoIterator<Item = Elem1>,\n    &'b Iter2: IntoIterator<Item = Elem2>,\n    Elem1: PartialEq<Elem2>,\n{\n    let a_len = a.into_iter().count();\n    let b_len = b.into_iter().count();\n\n    if a_len == 0 && b_len == 0 {\n        return 1.0;\n    } else if a_len == 0 || b_len == 0 {\n        return 0.0;\n    }\n\n    let mut search_range = std::cmp::max(a_len, b_len) / 2;\n    search_range = search_range.saturating_sub(1);\n\n    // combine memory allocations to reduce runtime\n    let mut flags_memory = vec![false; a_len + b_len];\n    let (a_flags, b_flags) = flags_memory.split_at_mut(a_len);\n\n    let mut matches = 0_usize;\n\n    for (i, a_elem) in a.into_iter().enumerate() {\n        let min_bound = if i > search_range { i - search_range } else { 0 };\n        let max_bound = std::cmp::min(b_len, i + search_range + 1);\n        for (j, b_elem) in b.into_iter().enumerate().take(max_bound) {\n            if min_bound <= j && a_elem == b_elem && !b_flags[j] {\n                a_flags[i] = true;\n                b_flags[j] = true;\n                matches += 1;\n                break;\n            }\n        }\n    }\n\n    let mut transpositions = 0_usize;\n    if matches != 0 {\n        let mut b_iter = b_flags.iter().zip(b);\n        for (a_flag, ch1) in a_flags.iter().zip(a) {\n            if *a_flag {\n                loop {\n                    if let Some((b_flag, ch2)) = b_iter.next() {\n                        if !*b_flag {\n                            continue;\n                        }\n                        if ch1 != ch2 {\n                            transpositions += 1;\n                        }\n                        break;\n                    }\n                }\n            }\n        }\n    }\n    transpositions /= 2;\n\n    if matches == 0 {\n        0.0\n    } else {\n        ((matches as f64 / a_len as f64)\n            + (matches as f64 / b_len as f64)\n            + ((matches - transpositions) as f64 / matches as f64))\n            / 3.0\n    }\n}""}","{""commented_code"": ""let mut flags_memory = vec![false; a_len + b_len]; // combine memory allocations to reduce runtime""}",comment_generation
strsim,"{""code"": ""let mut transpositions = 0_usize;\nif matches != 0 {\n    let mut b_iter = b_flags.iter().zip(b);\n    for (a_flag, ch1) in a_flags.iter().zip(a) {\n        if *a_flag {\n            loop {\n                if let Some((b_flag, ch2)) = b_iter.next() {\n                    if !*b_flag {\n                        continue;\n                    }\n\n                    if ch1 != ch2 {\n                        transpositions += 1;\n                    }\n                    break;\n                }\n            }\n        }\n    }\n}\ntranspositions /= 2;"", ""code_context"": ""pub fn generic_jaro<'a, 'b, Iter1, Iter2, Elem1, Elem2>(a: &'a Iter1, b: &'b Iter2) -> f64\nwhere\n    &'a Iter1: IntoIterator<Item = Elem1>,\n    &'b Iter2: IntoIterator<Item = Elem2>,\n    Elem1: PartialEq<Elem2>,\n{\n    let a_len = a.into_iter().count();\n    let b_len = b.into_iter().count();\n\n    if a_len == 0 && b_len == 0 {\n        return 1.0;\n    } else if a_len == 0 || b_len == 0 {\n        return 0.0;\n    }\n\n    let mut search_range = std::cmp::max(a_len, b_len) / 2;\n    search_range = search_range.saturating_sub(1);\n\n    let mut flags_memory = vec![false; a_len + b_len];\n    let (a_flags, b_flags) = flags_memory.split_at_mut(a_len);\n\n    let mut matches = 0_usize;\n\n    for (i, a_elem) in a.into_iter().enumerate() {\n        let min_bound = if i > search_range { i - search_range } else { 0 };\n        let max_bound = std::cmp::min(b_len, i + search_range + 1);\n        for (j, b_elem) in b.into_iter().enumerate().take(max_bound) {\n            if min_bound <= j && a_elem == b_elem && !b_flags[j] {\n                a_flags[i] = true;\n                b_flags[j] = true;\n                matches += 1;\n                break;\n            }\n        }\n    }\n\n    // transpositions block will be inserted here in the data point\n    // ...\n\n    if matches == 0 {\n        0.0\n    } else {\n        ((matches as f64 / a_len as f64)\n            + (matches as f64 / b_len as f64)\n            + ((matches - transpositions) as f64 / matches as f64))\n            / 3.0\n    }\n}""}","{""commented_code"": ""let mut transpositions = 0_usize; // Count transpositions\nif matches != 0 { // Only compute when there are matches\n    let mut b_iter = b_flags.iter().zip(b); // Iterate over both flags and characters\n    for (a_flag, ch1) in a_flags.iter().zip(a) {\n        if *a_flag { // Only consider matched positions in a\n            loop {\n                if let Some((b_flag, ch2)) = b_iter.next() {\n                    if !*b_flag { // Skip unmatched positions in b\n                        continue;\n                    }\n\n                    if ch1 != ch2 { // Different characters indicate a transposition\n                        transpositions += 1; // Increment transposition count\n                    }\n                    break;\n                }\n            }\n        }\n    }\n}\ntranspositions /= 2; // Divide by 2 since each transposition is counted twice""}",comment_generation
strsim,"{""code"": ""prev_distances[b_len]"", ""code_context"": ""pub fn osa_distance(a: &str, b: &str) -> usize {\n    let b_len = b.chars().count();\n    let mut prev_two_distances: Vec<usize> = (0..b_len + 1).collect();\n    let mut prev_distances: Vec<usize> = (0..b_len + 1).collect();\n    let mut curr_distances: Vec<usize> = vec![0; b_len + 1];\n\n    let mut prev_a_char = std::char::MAX;\n    let mut prev_b_char = std::char::MAX;\n\n    for (i, a_char) in a.chars().enumerate() {\n        curr_distances[0] = i + 1;\n\n        for (j, b_char) in b.chars().enumerate() {\n            let cost = usize::from(a_char != b_char);\n            curr_distances[j + 1] = std::cmp::min(\n                curr_distances[j] + 1,\n                std::cmp::min(prev_distances[j + 1] + 1, prev_distances[j] + cost),\n            );\n            if i > 0 && j > 0 && a_char != b_char && a_char == prev_b_char && b_char == prev_a_char {\n                curr_distances[j + 1] = std::cmp::min(curr_distances[j + 1], prev_two_distances[j - 1] + 1);\n            }\n\n            prev_b_char = b_char;\n        }\n\n        std::mem::swap(&mut prev_two_distances, &mut prev_distances);\n        std::mem::swap(&mut prev_distances, &mut curr_distances);\n        prev_a_char = a_char;\n    }\n\n    // access prev_distances instead of curr_distances since we swapped\n    // them above. In case a is empty this would still contain the correct value\n    // from initializing the last element to b_len\n    prev_distances[b_len]\n}""}","{""commented_code"": ""prev_distances[b_len] // access prev_distances instead of curr_distances since we swapped them above""}",comment_generation
slab,"{""code_before"": ""pub fn reserve(&mut self, additional: usize) {\n    if self.capacity() - self.len >= additional {\n        return;\n    }\n    let need_add = additional - (self.entries.len() - self.len);\n    self.entries.reserve(need_add);\n}"", ""code_context"": ""use alloc::vec::Vec;\n\npub struct Slab<T> {\n    entries: Vec<Entry<T>>,\n    len: usize,\n    next: usize,\n}\n\nimpl<T> Slab<T> {\n    pub fn capacity(&self) -> usize {\n        self.entries.capacity()\n    }\n}\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}""}","{""rationale"": ""Using `saturating_sub` prevents potential underflow when calculating the additional capacity needed, making the method safer without changing its behavior."", ""code_after"": ""pub fn reserve(&mut self, additional: usize) {\n    if self.capacity() - self.len >= additional {\n        return;\n    }\n    let need_add = additional.saturating_sub(self.entries.len() - self.len);\n    self.entries.reserve(need_add);\n}""}",code_refactoring
slab,"{""code_before"": ""pub fn try_remove(&mut self, key: usize) -> Option<T> {\n    if let Some(entry) = self.entries.get_mut(key) {\n        let prev = core::mem::replace(entry, Entry::Vacant(self.next));\n        match prev {\n            Entry::Occupied(val) => {\n                self.len -= 1;\n                self.next = key;\n                return val.into();\n            }\n            _ => {\n                *entry = prev;\n            }\n        }\n    }\n    None\n}"", ""code_context"": ""use alloc::vec::Vec;\n\npub struct Slab<T> {\n    entries: Vec<Entry<T>>,\n    len: usize,\n    next: usize,\n}\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}""}","{""rationale"": ""Replacing the `match` with an `if let` eliminates an unnecessary branch and the explicit `return`, resulting in clearer control flow and avoiding the superfluous `Into` conversion."", ""code_after"": ""pub fn try_remove(&mut self, key: usize) -> Option<T> {\n    if let Some(entry) = self.entries.get_mut(key) {\n        let prev = core::mem::replace(entry, Entry::Vacant(self.next));\n        if let Entry::Occupied(val) = prev {\n            self.len -= 1;\n            self.next = key;\n            Some(val)\n        } else {\n            *entry = prev;\n            None\n        }\n    } else {\n        None\n    }\n}""}",code_refactoring
slab,"{""code_before"": ""fn next_back(&mut self) -> Option<Self::Item> {\n    while let Some((key, entry)) = self.entries.next_back() {\n        if let Entry::Occupied(v) = entry {\n            self.len -= 1;\n            return Some((key, v));\n        }\n    }\n    debug_assert_eq!(self.len, 0);\n    None\n}"", ""code_context"": ""use core::iter;\nuse alloc::vec::Vec;\n\npub struct IntoIter<T> {\n    entries: iter::Enumerate<vec::IntoIter<Entry<T>>>,\n    len: usize,\n}\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}""}","{""rationale"": ""Using `and_then` with the iterator removes the explicit loop and early return, making the implementation more concise and idiomatic."", ""code_after"": ""fn next_back(&mut self) -> Option<Self::Item> {\n    self.entries.next_back().and_then(|(key, entry)| {\n        if let Entry::Occupied(v) = entry {\n            self.len -= 1;\n            Some((key, v))\n        } else {\n            None\n        }\n    })\n}""}",code_refactoring
http-body,"{""code"": ""pub struct Frame<T> {\n    kind: Kind<T>,\n}"", ""code_context"": ""use http::HeaderMap;\n\nenum Kind<T> {\n    Data(T),\n    Trailers(HeaderMap),\n}""}","{""docstring"": ""A frame of any kind related to an HTTP stream (body).""}",docstring_generation
http-body,"{""code"": ""#[derive(Debug, Default, Clone)]\npub struct SizeHint {\n    lower: u64,\n    upper: Option<u64>,\n}"", ""code_context"": null}","{""docstring"": ""A `Body` size hint""}",docstring_generation
http-body,"{""code"": ""pub trait Body {\n    type Data: Buf;\n    type Error;\n\n    fn poll_frame(\n        self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n    ) -> Poll<Option<Result<Frame<Self::Data>, Self::Error>>>;\n\n    fn is_end_stream(&self) -> bool {\n        false\n    }\n\n    fn size_hint(&self) -> SizeHint {\n        SizeHint::default()\n    }\n}"", ""code_context"": ""use http::HeaderMap;\n\nenum Kind<T> {\n    Data(T),\n    Trailers(HeaderMap),\n}\n\npub struct Frame<T> {\n    kind: Kind<T>,\n}\n\n#[derive(Debug, Default, Clone)]\npub struct SizeHint {\n    lower: u64,\n    upper: Option<u64>,\n}""}","{""docstring"": ""Trait representing a streaming body of a Request or Response.""}",docstring_generation
http-body,"{""code"": ""pub struct Channel<D, E = std::convert::Infallible> {\n    rx_frame: mpsc::Receiver<Frame<D>>,\n    #[pin]\n    rx_error: oneshot::Receiver<E>,\n}"", ""code_context"": ""use http::HeaderMap;\n\nenum Kind<T> {\n    Data(T),\n    Trailers(HeaderMap),\n}\n\npub struct Frame<T> {\n    kind: Kind<T>,\n}""}","{""docstring"": ""A body backed by a channel.""}",docstring_generation
slab,"{""code"": ""pub(crate) fn pair(&mut self, key: usize, value: T) {\n    let slab = &mut self.slab;\n    if key < slab.entries.len() {\n        if let Entry::Vacant(_) = slab.entries[key] {\n            self.vacant_list_broken = true;\n            slab.len += 1;\n        }\n        slab.entries[key] = Entry::Occupied(value);\n    } else {\n        if self.first_vacant_index.is_none() && slab.entries.len() < key {\n            self.first_vacant_index = Some(slab.entries.len());\n        }\n        while slab.entries.len() < key {\n            let next = slab.next;\n            slab.next = slab.entries.len();\n            slab.entries.push(Entry::Vacant(next));\n        }\n        slab.entries.push(Entry::Occupied(value));\n        slab.len += 1;\n    }\n}"", ""code_context"": ""use std::vec::Vec;\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}\n\npub struct Slab<T> {\n    entries: Vec<Entry<T>>,\n    len: usize,\n    next: usize,\n}\n\npub struct Builder<T> {\n    slab: Slab<T>,\n    vacant_list_broken: bool,\n    first_vacant_index: Option<usize>,\n}\n\nimpl<T> Builder<T> {\n    // other methods omitted for brevity\n}""}","{""commented_code"": ""pub(crate) fn pair(&mut self, key: usize, value: T) {\n    let slab = &mut self.slab;\n    if key < slab.entries.len() {\n        // iterator is not sorted, might need to recreate vacant list\n        if let Entry::Vacant(_) = slab.entries[key] {\n            self.vacant_list_broken = true;\n            slab.len += 1;\n        }\n        // if an element with this key already exists, replace it.\n        // This is consistent with HashMap and BtreeMap\n        slab.entries[key] = Entry::Occupied(value);\n    } else {\n        if self.first_vacant_index.is_none() && slab.entries.len() < key {\n            self.first_vacant_index = Some(slab.entries.len());\n        }\n        // insert holes as necessary\n        while slab.entries.len() < key {\n            // add the entry to the start of the vacant list\n            let next = slab.next;\n            slab.next = slab.entries.len();\n            slab.entries.push(Entry::Vacant(next));\n        }\n        slab.entries.push(Entry::Occupied(value));\n        slab.len += 1;\n    }\n}""}",comment_generation
slab,"{""code"": ""pub fn shrink_to_fit(&mut self) {\n    let len_before = self.entries.len();\n    while let Some(&Entry::Vacant(_)) = self.entries.last() {\n        self.entries.pop();\n    }\n    if self.entries.len() != len_before {\n        self.recreate_vacant_list();\n    }\n    self.entries.shrink_to_fit();\n}"", ""code_context"": ""use std::vec::Vec;\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}\n\npub struct Slab<T> {\n    entries: Vec<Entry<T>>,\n    len: usize,\n    next: usize,\n}\n\nimpl<T> Slab<T> {\n    fn recreate_vacant_list(&mut self) {\n        // implementation omitted for brevity\n    }\n    // shrink_to_fit method defined above\n}""}","{""commented_code"": ""pub fn shrink_to_fit(&mut self) {\n    // Remove all vacant entries after the last occupied one, so that\n    // the capacity can be reduced to what is actually needed.\n    let len_before = self.entries.len();\n    while let Some(&Entry::Vacant(_)) = self.entries.last() {\n        self.entries.pop();\n    }\n    // Removing entries breaks the list of vacant entries,\n    // so it must be repaired\n    if self.entries.len() != len_before {\n        self.recreate_vacant_list();\n    }\n    self.entries.shrink_to_fit();\n}""}",comment_generation
slab,"{""code"": ""for (i, &key) in keys.iter().enumerate() {\n    if key >= entries_cap {\n        return Err(GetDisjointMutError::IndexOutOfBounds);\n    }\n    match unsafe { &mut *entries_ptr.add(key) } {\n        Entry::Vacant(_) => return Err(GetDisjointMutError::IndexVacant),\n        Entry::Occupied(entry) => {\n            unsafe { res_ptr.add(i).write(entry) };\n        }\n    }\n}"", ""code_context"": ""use std::mem::MaybeUninit;\n\nenum Entry<T> {\n    Vacant(usize),\n    Occupied(T),\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\nenum GetDisjointMutError {\n    IndexVacant,\n    IndexOutOfBounds,\n    OverlappingIndices,\n}\n\npub struct Slab<T> {\n    entries: Vec<Entry<T>>,\n    len: usize,\n    next: usize,\n}\n\nimpl<T> Slab<T> {\n    pub fn get_disjoint_mut<const N: usize>(&mut self, keys: [usize; N]) -> Result<[&mut T; N], GetDisjointMutError> {\n        // preceding checks omitted for brevity\n        let entries_ptr = self.entries.as_mut_ptr();\n        let entries_cap = self.entries.capacity();\n        let mut res = MaybeUninit::<[&mut T; N]>::uninit();\n        let res_ptr = res.as_mut_ptr() as *mut &mut T;\n        // loop body is the snippet above\n        for (i, &key) in keys.iter().enumerate() {\n            if key >= entries_cap {\n                return Err(GetDisjointMutError::IndexOutOfBounds);\n            }\n            match unsafe { &mut *entries_ptr.add(key) } {\n                Entry::Vacant(_) => return Err(GetDisjointMutError::IndexVacant),\n                Entry::Occupied(entry) => {\n                    unsafe { res_ptr.add(i).write(entry) };\n                }\n            }\n        }\n        // rest omitted\n        Ok(unsafe { res.assume_init() })\n    }\n}""}","{""commented_code"": ""for (i, &key) in keys.iter().enumerate() {\n    if key >= entries_cap {\n        return Err(GetDisjointMutError::IndexOutOfBounds);\n    }\n    // SAFETY: we made sure above that this key is in bounds.\n    match unsafe { &mut *entries_ptr.add(key) } {\n        Entry::Vacant(_) => return Err(GetDisjointMutError::IndexVacant),\n        Entry::Occupied(entry) => {\n            // SAFETY: `res` and `keys` both have N elements so `i` must be in bounds.\n            // We checked above that all selected `entry`s are distinct.\n            unsafe { res_ptr.add(i).write(entry) };\n        }\n    }\n}""}",comment_generation
async-stream,"{""title"": ""Generate a stream of even numbers up to a limit"", ""description"": ""A developer needs a stream that yields only the even numbers from 0 to a given inclusive limit. The stream will be used in a data‑processing pipeline where only even values are required."", ""code_context"": ""use async_stream::stream;\nuse futures_core::stream::Stream;""}","{""code"": ""fn even_numbers(limit: u32) -> impl futures_core::stream::Stream<Item = u32> {\n    async_stream::stream! {\n        for i in 0..=limit {\n            if i % 2 == 0 {\n                yield i;\n            }\n        }\n    }\n}""}",code_generation
async-stream,"{""title"": ""Filter and transform a stream of log lines"", ""description"": ""A developer wants to process a stream of log strings, keeping only those that start with a specific prefix and converting the retained lines to uppercase before yielding them downstream."", ""code_context"": ""use async_stream::stream;\nuse futures_util::stream::StreamExt;\nuse futures_util::pin_mut;""}","{""code"": ""fn filter_and_uppercase<S>(input: S, prefix: &str) -> impl futures_core::stream::Stream<Item = String>\nwhere\n    S: futures_core::stream::Stream<Item = String> + Unpin,\n{\n    async_stream::stream! {\n        pin_mut!(input);\n        while let Some(line) = input.next().await {\n            if line.starts_with(prefix) {\n                yield line.to_uppercase();\n            }\n        }\n    }\n}""}",code_generation
async-stream,"{""title"": ""Retry an asynchronous operation with a bounded number of attempts"", ""description"": ""A developer needs a stream that repeatedly invokes an async operation until it succeeds or a maximum number of retries is reached. Successful results are yielded, and the final error is propagated as a stream item using `try_stream!`."", ""code_context"": ""use async_stream::try_stream;\nuse std::time::Duration;\nuse tokio::time::sleep;""}","{""code"": ""fn retry_operation<F, Fut, T, E>(mut op: F, max_retries: usize) -> impl futures_core::stream::Stream<Item = Result<T, E>>\nwhere\n    F: FnMut() -> Fut,\n    Fut: std::future::Future<Output = Result<T, E>>, \n{\n    async_stream::try_stream! {\n        let mut attempts = 0;\n        loop {\n            match op().await {\n                Ok(v) => {\n                    yield v;\n                    break;\n                }\n                Err(e) => {\n                    attempts += 1;\n                    if attempts >= max_retries {\n                        Err(e)?;\n                    } else {\n                        tokio::time::sleep(std::time::Duration::from_millis(100)).await;\n                    }\n                }\n            }\n        }\n    }\n}""}",code_generation
async-stream,"{""title"": ""Merge two streams into a single interleaved stream"", ""description"": ""A developer wants to combine two independent streams so that each iteration yields a pair containing the next item from each stream (or `None` if a stream is exhausted). This is useful for synchronising data from two sources."", ""code_context"": ""use async_stream::stream;\nuse futures_util::stream::StreamExt;""}","{""code"": ""fn merge_streams<S1, S2>(mut stream1: S1, mut stream2: S2) -> impl futures_core::stream::Stream<Item = (Option<S1::Item>, Option<S2::Item>)>\nwhere\n    S1: futures_core::stream::Stream + Unpin,\n    S2: futures_core::stream::Stream + Unpin,\n{\n    async_stream::stream! {\n        loop {\n            let item1 = stream1.next().await;\n            let item2 = stream2.next().await;\n            if item1.is_none() && item2.is_none() {\n                break;\n            }\n            yield (item1, item2);\n        }\n    }\n}""}",code_generation
async-stream,"{""code_before"": ""fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {\n        let me = self.project();\n\n        if *me.done {\n            return Poll::Ready(None);\n        }\n\n        let mut dst = None;\n        let res = {\n            let _enter = me.rx.enter(&mut dst);\n            me.generator.poll(cx)\n        };\n\n        *me.done = res.is_ready();\n\n        if dst.is_some() {\n            return Poll::Ready(dst.take());\n        }\n\n        if *me.done {\n            Poll::Ready(None)\n        } else {\n            Poll::Pending\n        }\n    }"", ""code_context"": ""use crate::yielder::Receiver;\nuse futures_core::{FusedStream, Stream};\nuse pin_project_lite::pin_project;\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\n\npin_project! {\n    #[derive(Debug)]\n    pub struct AsyncStream<T, U> {\n        rx: Receiver<T>,\n        done: bool,\n        #[pin]\n        generator: U,\n    }\n}\n\nimpl<T, U> AsyncStream<T, U> {\n    pub fn new(rx: Receiver<T>, generator: U) -> AsyncStream<T, U> {\n        AsyncStream { rx, done: false, generator }\n    }\n}\n\nimpl<T, U> FusedStream for AsyncStream<T, U>\nwhere\n    U: Future<Output = ()>,\n{\n    fn is_terminated(&self) -> bool {\n        self.done\n    }\n}\n\nimpl<T, U> Stream for AsyncStream<T, U>\nwhere\n    U: Future<Output = ()>,\n{\n    type Item = T;\n}""}","{""rationale"": ""Replaces the series of if/else checks with a match on `dst`, making the control flow clearer and more idiomatic. This reduces boilerplate and improves readability while preserving the original behavior."", ""code_after"": ""fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {\n        let me = self.project();\n\n        if *me.done {\n            return Poll::Ready(None);\n        }\n\n        let mut dst = None;\n        let res = {\n            let _enter = me.rx.enter(&mut dst);\n            me.generator.poll(cx)\n        };\n\n        *me.done = res.is_ready();\n\n        match dst {\n            Some(value) => Poll::Ready(Some(value)),\n            None => {\n                if *me.done {\n                    Poll::Ready(None)\n                } else {\n                    Poll::Pending\n                }\n            }\n        }\n    }""}",code_refactoring
async-stream,"{""code_before"": ""#[tokio::test]\nasync fn test() {\n    let s = stream! {\n        yield \""hello\"";\n        yield \""world\"";\n    };\n    let s = stream! {\n        for await x in s {\n            yield x.to_owned() + \""!\"";\n        }\n    };\n    let values: Vec<_> = s.collect().await;\n    assert_eq!(2, values.len());\n    assert_eq!(\""hello\"", values[0]);\n    assert_eq!(\""world\"", values[1]);\n}"", ""code_context"": ""use async_stream::stream;\nuse futures_util::stream::StreamExt;\nuse tokio::test;""}","{""rationale"": ""Uses the iterator adapter `map` instead of a nested `for await` stream, resulting in a more concise and idiomatic transformation pipeline while keeping the same semantics."", ""code_after"": ""#[tokio::test]\nasync fn test() {\n    let s = stream! {\n        yield \""hello\"";\n        yield \""world\"";\n    };\n    let transformed = s.map(|x| x.to_owned() + \""!\"");\n    let values: Vec<_> = transformed.collect().await;\n    assert_eq!(2, values.len());\n    assert_eq!(\""hello!\"", values[0]);\n    assert_eq!(\""world!\"", values[1]);\n}""}",code_refactoring
async-stream,"{""code_before"": ""use async_stream::stream;\nuse futures_util::pin_mut;\nuse futures_util::stream::StreamExt;\nuse tokio::net::TcpListener;\n\n#[tokio::main]\nasync fn main() {\n    let listener = TcpListener::bind(\""127.0.0.1:0\"").await.unwrap();\n\n    let incoming = stream! {\n        loop {\n            let (socket, _) = listener.accept().await.unwrap();\n            yield socket;\n        }\n    };\n    pin_mut!(incoming);\n\n    while let Some(v) = incoming.next().await {\n        println!(\""handle = {:?}\"", v);\n    }\n}"", ""code_context"": ""use async_stream::stream;\nuse futures_util::pin_mut;\nuse futures_util::stream::StreamExt;\nuse tokio::net::TcpListener;""}","{""rationale"": ""Replaces the manual `stream!` construction with the built‑in `TcpListener::incoming()` iterator, removing unnecessary macro usage and simplifying the code while preserving functionality."", ""code_after"": ""use async_stream::stream;\nuse futures_util::pin_mut;\nuse futures_util::stream::StreamExt;\nuse tokio::net::TcpListener;\n\n#[tokio::main]\nasync fn main() {\n    let listener = TcpListener::bind(\""127.0.0.1:0\"").await.unwrap();\n\n    let incoming = listener.incoming();\n    pin_mut!(incoming);\n\n    while let Some(v) = incoming.next().await {\n        println!(\""handle = {:?}\"", v);\n    }\n}""}",code_refactoring
ansi_term,"{""code"": ""let base = if light_bg { Colour::Black } else { Colour::White };"", ""code_context"": ""pub enum Colour {\n    Black,\n    Red,\n    Green,\n    Yellow,\n    Blue,\n    Purple,\n    Cyan,\n    White,\n    Fixed(u8),\n    RGB(u8, u8, u8),\n}\n\npub struct Style {\n    pub foreground: Option<Colour>,\n    pub background: Option<Colour>,\n    pub is_bold: bool,\n    pub is_dimmed: bool,\n    pub is_italic: bool,\n    pub is_underline: bool,\n    pub is_blink: bool,\n    pub is_reverse: bool,\n    pub is_hidden: bool,\n    pub is_strikethrough: bool,\n}\n\nimpl Colour {\n    pub fn on(self, background: Colour) -> Style {\n        Style { foreground: Some(self), background: Some(background), .. Style::default() }\n    }\n}""}","{""next_api_call"": ""let style = base.on(Colour::Fixed(c));""}",api_usage_prediction
ansi_term,"{""code"": ""let mut written_anything = false;"", ""code_context"": ""pub struct Style {\n    pub foreground: Option<Colour>,\n    pub background: Option<Colour>,\n    pub is_bold: bool,\n    pub is_dimmed: bool,\n    pub is_italic: bool,\n    pub is_underline: bool,\n    pub is_blink: bool,\n    pub is_reverse: bool,\n    pub is_hidden: bool,\n    pub is_strikethrough: bool,\n}""}","{""next_api_call"": ""let mut write_char = |c| { if written_anything { write!(f, \"";\"")?; } written_anything = true; write!(f, \""{}\"", c)?; Ok(()) };""}",api_usage_prediction
ansi_term,"{""code"": ""let first = match self.0.first() { None => return Ok(()), Some(f) => f, };"", ""code_context"": ""use std::borrow::Cow;\nuse std::fmt;\n\npub struct Style {\n    pub foreground: Option<Colour>,\n    pub background: Option<Colour>,\n    pub is_bold: bool,\n    pub is_dimmed: bool,\n    pub is_italic: bool,\n    pub is_underline: bool,\n    pub is_blink: bool,\n    pub is_reverse: bool,\n    pub is_hidden: bool,\n    pub is_strikethrough: bool,\n}\n\npub struct ANSIGenericString<'a, S: 'a + ToOwned + ?Sized>\nwhere <S as ToOwned>::Owned: fmt::Debug {\n    style: Style,\n    string: Cow<'a, S>,\n}\n\npub struct ANSIGenericStrings<'a, S: 'a + ToOwned + ?Sized>\n    (pub &'a [ANSIGenericString<'a, S>])\n    where <S as ToOwned>::Owned: fmt::Debug, S: PartialEq;""}","{""next_api_call"": ""write!(w, \""{}\"", first.style.prefix())?;""}",api_usage_prediction
convert_case,"{""query"": ""How can I convert a camelCase string to snake_case using the convert_case crate?"", ""code_context"": null}","{""code_snippet"": ""use convert_case::{Case, Casing};\n\nfn main() {\n    let camel = \""myVariableName\"";\n    let snake = camel.to_case(Case::Snake);\n    println!(\""{}\"", snake);\n}""}",code_search
convert_case,"{""query"": ""How do I define a custom case that splits on periods and uses a lowercase pattern?"", ""code_context"": null}","{""code_snippet"": ""use convert_case::{Case, Casing, Boundary, pattern};\n\nfn main() {\n    let dot_case = Case::Custom {\n        boundaries: &[Boundary::from_delim(\"".\"")],\n        pattern: pattern::lowercase,\n        delim: \"".\"",\n    };\n    let input = \""My.Custom.Case\"";\n    let result = input.to_case(dot_case);\n    println!(\""{}\"", result);\n}""}",code_search
convert_case,"{""query"": ""How can I remove digit boundaries when converting a string with numbers to snake_case?"", ""code_context"": null}","{""code_snippet"": ""use convert_case::{Case, Casing, Boundary};\n\nfn main() {\n    let s = \""scale2DVersion3\"";\n    let snake = s\n        .from_case(Case::Camel)\n        .without_boundaries(&[Boundary::DIGIT_UPPER, Boundary::DIGIT_LOWER])\n        .to_case(Case::Snake);\n    println!(\""{}\"", snake);\n}""}",code_search
convert_case,"{""query"": ""How do I use the Converter struct to convert a string with custom boundaries and a capital pattern?"", ""code_context"": null}","{""code_snippet"": ""use convert_case::{Boundary, Converter, pattern};\n\nfn main() {\n    let conv = Converter::new()\n        .set_boundaries(&[Boundary::UNDERSCORE, Boundary::LOWER_UPPER])\n        .set_pattern(pattern::capital)\n        .set_delim(\"" \"");\n    let result = conv.convert(\""my_customString\"");\n    println!(\""{}\"", result);\n}""}",code_search
convert_case,"{""query"": ""How can I convert a hyphenated string to Title case while preserving the hyphens?"", ""code_context"": null}","{""code_snippet"": ""use convert_case::{Case, Casing};\n\nfn main() {\n    let s = \""my-hyphenated-string\"";\n    let title = s.from_case(Case::Kebab).to_case(Case::Title);\n    println!(\""{}\"", title);\n}""}",code_search
tap,"{""title"": ""Logging and validating a configuration object"", ""description"": ""A developer needs to log the configuration object before validating it, ensuring that all fields are properly set. They want to perform these actions in a single expression without intermediate variables."", ""code_context"": ""use tap::prelude::*;\n\nstruct Config {\n    field1: String,\n    field2: i32,\n}\n\nimpl Config {\n    fn new() -> Self {\n        Config {\n            field1: \""default\"".to_string(),\n            field2: 0,\n        }\n    }\n\n    fn validate(&self) -> bool {\n        !self.field1.is_empty()\n    }\n}\n\nfn log_config(config: &Config) {\n    println!(\""Config: field1 = {}, field2 = {}\"", config.field1, config.field2);\n}""}","{""code"": ""let config = Config::new().tap(|c| log_config(c)).validate();""}",code_generation
tap,"{""title"": ""Processing a Result with error logging using tap_err"", ""description"": ""A developer is processing a Result type and wants to log the error if it exists without changing the flow of the program. They need a way to inspect the error value conditionally."", ""code_context"": ""use tap::prelude::*;""}","{""code"": ""let result: Result<i32, String> = Err(\""invalid input\"".to_string());\nresult.tap_err(|e| println!(\""Error occurred: {}\"", e));""}",code_generation
tap,"{""title"": ""Sorting a mutable array inline with tap_mut"", ""description"": ""A developer is working with a mutable collection and needs to sort it as part of a processing pipeline without breaking the chain of operations. They want to perform this mutation inline."", ""code_context"": ""use tap::prelude::*;""}","{""code"": ""let sorted = [5, 3, 1, 4, 2].tap_mut(|arr| arr.sort());""}",code_generation
tap,"{""title"": ""Chaining multiple transformations with pipe"", ""description"": ""A developer needs to apply a series of arithmetic transformations to a value using the pipe method, keeping the code concise and readable without intermediate variables."", ""code_context"": ""use tap::prelude::*;""}","{""code"": ""let result = 5.pipe(|x| x * 2).pipe(|x| x + 3).pipe(|x| x * 4);""}",code_generation
tap,"{""title"": ""Converting a value to String with logging using tap"", ""description"": ""A developer wants a helper function that converts any value implementing ToString into a String while logging the conversion result for debugging purposes."", ""code_context"": ""use tap::prelude::*;""}","{""code"": ""pub fn to_string_with_log<T: ToString>(value: T) -> String {\n    value.to_string().tap(|s| println!(\""Converted to string: {}\"", s))\n}""}",code_generation
async-stream,"{""code"": ""pub fn next<S>(stream: &mut S) -> impl Future<Output = Option<S::Item>> + '_' where S: Stream + Unpin { Next { stream } }\n\nstruct Next<'a, S> { stream: &'a mut S, }\n\nimpl<S> Unpin for Next<'_, S> where S: Unpin {}\n\nimpl<S> Future for Next<'_, S> where S: Stream + Unpin { type Output = Option<S::Item>; fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> { Pin::new(&mut self.stream).poll_next(cx) } }"", ""code_context"": ""use futures_core::Stream;\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};""}","{""summary"": ""Provides a `next` function that returns a future polling the next item of a stream.""}",code_summarization
async-stream,"{""code"": ""impl<T, U> AsyncStream<T, U> { pub fn new(rx: Receiver<T>, generator: U) -> AsyncStream<T, U> { AsyncStream { rx, done: false, generator, } } }"", ""code_context"": ""use crate::yielder::Receiver;\nuse futures_core::{FusedStream, Stream};\nuse pin_project_lite::pin_project;\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\n\npin_project! { #[derive(Debug)] pub struct AsyncStream<T, U> { rx: Receiver<T>, done: bool, #[pin] generator: U, } }""}","{""summary"": ""Creates a new asynchronous stream with a receiver and a generator future.""}",code_summarization
async-stream,"{""code"": ""impl<T, U> Stream for AsyncStream<T, U> where U: Future<Output = ()> { type Item = T; fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> { let me = self.project(); if *me.done { return Poll::Ready(None); } let mut dst = None; let res = { let _enter = me.rx.enter(&mut dst); me.generator.poll(cx) }; *me.done = res.is_ready(); if dst.is_some() { return Poll::Ready(dst.take()); } if *me.done { Poll::Ready(None) } else { Poll::Pending } } }"", ""code_context"": ""use crate::yielder::Receiver;\nuse futures_core::{FusedStream, Stream};\nuse pin_project_lite::pin_project;\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\n\npin_project! { #[derive(Debug)] pub struct AsyncStream<T, U> { rx: Receiver<T>, done: bool, #[pin] generator: U, } }""}","{""summary"": ""Implements the `Stream` trait for `AsyncStream`, handling polling and yielding of items.""}",code_summarization
async-stream,"{""code"": ""macro_rules! stream { ($($tt:tt)*) => { $crate::__private::stream_inner!(($crate) $($tt)*) }; }\n\nmacro_rules! try_stream { ($($tt:tt)*) => { $crate::__private::try_stream_inner!(($crate) $($tt)*) }; }"", ""code_context"": null}","{""summary"": ""Defines the `stream!` and `try_stream!` macros that delegate to internal implementations for creating asynchronous streams.""}",code_summarization
tap,"{""code"": ""pub trait Pipe {\n    #[inline(always)]\n    fn pipe<R>(self, func: impl FnOnce(Self) -> R) -> R\n    where\n        Self: Sized,\n        R: Sized,\n    {\n        func(self)\n    }\n}"", ""code_context"": null}","{""summary"": ""Transforms a value by passing it to a provided function and returns the function's result.""}",code_summarization
tap,"{""code"": ""pub trait Tap\nwhere\n    Self: Sized,\n{\n    #[inline(always)]\n    fn tap_mut(mut self, func: impl FnOnce(&mut Self)) -> Self {\n        func(&mut self);\n        self\n    }\n}"", ""code_context"": null}","{""summary"": ""Allows mutable inspection of a value by applying a side‑effect function and then returns the original value.""}",code_summarization
tap,"{""code"": ""pub trait Conv\nwhere\n    Self: Sized,\n{\n    #[inline(always)]\n    fn conv<T>(self) -> T\n    where\n        Self: Into<T>,\n        T: Sized,\n    {\n        Into::<T>::into(self)\n    }\n}"", ""code_context"": null}","{""summary"": ""Converts a value into another type using the `Into` trait, enabling method‑call style conversion.""}",code_summarization
tap,"{""code"": ""pub trait TapOptional\nwhere\n    Self: Sized,\n{\n    type Val: ?Sized;\n\n    #[inline(always)]\n    fn tap_some(self, func: impl FnOnce(&Self::Val)) -> Self {\n        if let Some(ref val) = self {\n            func(val);\n        }\n        self\n    }\n}"", ""code_context"": null}","{""summary"": ""Runs a side‑effect function on the contained value of an `Option` when it is `Some`, otherwise leaves the option unchanged.""}",code_summarization
async-stream,"{""code"": ""macro_rules! stream {\n    ($($tt:tt)*) => {\n        $crate::__private::stream_inner!(($crate) $($tt)*)\n    };\n}"", ""code_context"": null}","{""docstring"": ""Asynchronous stream\n\nSee [crate](index.html) documentation for more details.\n\n# Examples\n\n```rust\nuse async_stream::stream;\n\nuse futures_util::pin_mut;\nuse futures_util::stream::StreamExt;\n\n#[tokio::main]\nasync fn main() {\n    let s = stream! {\n        for i in 0..3 {\n            yield i;\n        }\n    };\n\n    pin_mut!(s); // needed for iteration\n\n    while let Some(value) = s.next().await {\n        println!(\""got {}\"", value);\n    }\n}\n```""}",docstring_generation
async-stream,"{""code"": ""macro_rules! try_stream {\n    ($($tt:tt)*) => {\n        $crate::__private::try_stream_inner!(($crate) $($tt)*)\n    };\n}"", ""code_context"": null}","{""docstring"": ""Asynchronous fallible stream\n\nSee [crate](index.html) documentation for more details.\n\n# Examples\n\n```rust\nuse tokio::net::{TcpListener, TcpStream};\n\nuse async_stream::try_stream;\nuse futures_core::stream::Stream;\n\nuse std::io;\nuse std::net::SocketAddr;\n\nfn bind_and_accept(addr: SocketAddr)\n    -> impl Stream<Item = io::Result<TcpStream>>\n{\n    try_stream! {\n        let mut listener = TcpListener::bind(addr).await?;\n\n        loop {\n            let (stream, addr) = listener.accept().await?;\n            println!(\""received on {:?}\"", addr);\n            yield stream;\n        }\n    }\n}\n```""}",docstring_generation
tap,"{""code"": ""pub trait Conv\nwhere\n    Self: Sized,\n{\n    #[inline(always)]\n    fn conv<T>(self) -> T\n    where\n        Self: Into<T>,\n        T: Sized,\n    {\n        Into::<T>::into(self)\n    }\n}"", ""code_context"": null}","{""explanation"": ""The `conv` method converts `self` into another type `T` using the standard `Into<T>` implementation. By placing the destination type as a method generic, it can be used in suffix position (`value.conv::<Target>()`), enabling seamless chaining in expression pipelines.""}",code_explanation
tap,"{""code"": ""pub trait Pipe {\n    #[inline(always)]\n    fn pipe<R>(self, func: impl FnOnce(Self) -> R) -> R\n    where\n        Self: Sized,\n        R: Sized,\n    {\n        func(self)\n    }\n}"", ""code_context"": null}","{""explanation"": ""The `pipe` method forwards the value it receives (`self`) into the supplied closure `func` and returns the closure's result. This allows any function to be called in suffix position, turning `value.pipe(f)` into a fluent transformation step.""}",code_explanation
tap,"{""code"": ""pub trait Tap\nwhere\n    Self: Sized,\n{\n    #[inline(always)]\n    fn tap(self, func: impl FnOnce(&Self)) -> Self {\n        func(&self);\n        self\n    }\n}"", ""code_context"": null}","{""explanation"": ""The `tap` method gives read‑only access to the value by passing an immutable reference to a closure, then returns the original value unchanged. It is useful for inserting logging, assertions, or other side‑effects without altering the surrounding expression.""}",code_explanation
tap,"{""code"": ""pub trait TapOptional\nwhere\n    Self: Sized,\n{\n    type Val: ?Sized;\n\n    #[inline(always)]\n    fn tap_some(self, func: impl FnOnce(&Self::Val)) -> Self {\n        if let Some(ref val) = self {\n            func(val);\n        }\n        self\n    }\n}"", ""code_context"": null}","{""explanation"": ""The `tap_some` method runs the provided closure only when the `Option` is `Some`, passing a reference to the contained value. It returns the original `Option`, enabling conditional inspection without changing the option's state.""}",code_explanation
tap,"{""code"": ""pub trait TapFallible\nwhere\n    Self: Sized,\n{\n    type Ok: ?Sized;\n    type Err: ?Sized;\n\n    #[inline(always)]\n    fn tap_ok(self, func: impl FnOnce(&Self::Ok)) -> Self {\n        if let Ok(ref val) = self {\n            func(val);\n        }\n        self\n    }\n}"", ""code_context"": null}","{""explanation"": ""The `tap_ok` method executes the closure only when a `Result` is `Ok`, providing an immutable reference to the success value. It leaves the `Result` unchanged, allowing side‑effects such as logging successful outcomes in a pipeline.""}",code_explanation
parquet-variant-json,"{""code_before"": ""fn process_data(data: &[Vec<u32>]) -> Vec<Vec<u32>> {\n    let mut result = Vec::new();\n    for item in data {\n        let mut temp = Vec::new();\n        for val in item {\n            temp.push(*val);\n        }\n        result.push(temp);\n    }\n    result\n}"", ""code_context"": null}","{""rationale"": ""Replaced explicit nested loops with an iterator map, reducing boilerplate and avoiding manual vector allocation. The iterator version is more concise, idiomatic, and lets the compiler optimize the collection process."", ""code_after"": ""fn process_data(data: &[Vec<u32>]) -> Vec<Vec<u32>> {\n    data.iter().map(|item| item.clone()).collect()\n}""}",code_refactoring
parquet-variant-json,"{""code_before"": ""fn build_json(json: &Value, builder: &mut VariantBuilder) -> Result<(), ArrowError> {\n    append_json(json, builder)?;\n    Ok(())\n}"", ""code_context"": ""use serde_json::Value;\nuse arrow_schema::ArrowError;\n\ntrait VariantBuilderExt<'m, 'v> {}\n\nstruct VariantBuilder;\n\nfn append_json<'m, 'v>(_: &'v Value, _: &mut impl VariantBuilderExt<'m, 'v>) -> Result<(), ArrowError> { Ok(()) }""}","{""rationale"": ""The function only forwards its arguments to `append_json`. Returning the result of `append_json` directly removes the unnecessary `Ok(())` wrapper, making the code shorter and clearer."", ""code_after"": ""fn build_json(json: &Value, builder: &mut VariantBuilder) -> Result<(), ArrowError> {\n    append_json(json, builder)\n}""}",code_refactoring
parquet-variant-json,"{""code_before"": ""Variant::Binary(bytes) => {\n    let base64_str = format_binary_base64(bytes);\n    let json_str = serde_json::to_string(&base64_str).map_err(|e| ArrowError::InvalidArgumentError(format!(\""JSON encoding error: {e}\"")))?;\n    write!(json_buffer, \""{json_str}\"")?\n},"", ""code_context"": ""use std::io::Write;\nuse arrow_schema::ArrowError;\n\nfn format_binary_base64(bytes: &[u8]) -> String { base64::engine::general_purpose::STANDARD.encode(bytes) }\n\nenum Variant<'a, 'b> {\n    Binary(&'b [u8]),\n    // other variants omitted\n}\n\nfn variant_to_json<W: Write>(json_buffer: &mut W, variant: &Variant) -> Result<(), ArrowError> { Ok(()) }""}","{""rationale"": ""Removed the intermediate `base64_str` variable. The refactored code calls `format_binary_base64` directly inside `serde_json::to_string`, reducing an allocation and simplifying the control flow."", ""code_after"": ""Variant::Binary(bytes) => {\n    let json_str = serde_json::to_string(&format_binary_base64(bytes)).map_err(|e| ArrowError::InvalidArgumentError(format!(\""JSON encoding error: {e}\"")))?;\n    write!(json_buffer, \""{json_str}\"")?\n},""}",code_refactoring
async-stream,"{""code_before"": ""use async_stream::stream;\n\n#[tokio::main]\nasync fn main() {\n    let s = stream! {\n        yield \""hello\"";\n        yield \""world\"";\n    };\n    \n    let values: Vec<_> = s.collect().await;\n    assert_eq!(2, values.len());\n    assert_eq!(\""hello\"", values[0]);\n    assert_eq!(\""world\"", values[1]);\n}"", ""code_context"": null}","{""code_after"": ""use async_stream::stream;\n\n#[tokio::main]\nasync fn main() {\n    let s = stream! {\n        for await x in [\""hello\"", \""world\""] {\n            yield x;\n        }\n    };\n    \n    let values: Vec<_> = s.collect().await;\n    assert_eq!(2, values.len());\n    assert_eq!(\""hello\"", values[0]);\n    assert_eq!(\""world\"", values[1]);\n}"", ""review_comment"": ""The original version manually yields each element, which is verbose. Using `for await` over a collection makes the intent clearer and reduces boilerplate, resulting in more idiomatic and readable async code.""}",code_review
async-stream,"{""code_before"": ""use async_stream::stream;\nuse tokio::net::TcpListener;\nuse std::io;\n\n#[tokio::main]\nasync fn main() {\n    let listener = TcpListener::bind(\""127.0.0.1:8080\"").await.unwrap();\n\n    let incoming = stream! {\n        loop {\n            let (socket, _) = listener.accept().await.unwrap();\n            yield socket;\n        }\n    };\n    // Normally would process incoming...\n}"", ""code_context"": null}","{""code_after"": ""use async_stream::try_stream;\nuse tokio::net::TcpListener;\nuse std::io;\n\n#[tokio::main]\nasync fn main() -> io::Result<()> {\n    let listener = TcpListener::bind(\""127.0.0.1:8080\"").await?;\n\n    let incoming = try_stream! {\n        loop {\n            let (socket, _) = listener.accept().await?;\n            yield socket;\n        }\n    };\n    // Process incoming...\n    Ok(())\n}"", ""review_comment"": ""Replacing `unwrap` with the `?` operator and using `try_stream!` propagates I/O errors instead of panicking, making the server robust and its error handling explicit. The function now returns `io::Result<()>`, aligning with conventional async I/O patterns.""}",code_review
async-stream,"{""code_before"": ""use async_stream::stream;\nuse futures_util::pin_mut;\nuse futures_util::stream::StreamExt;\n\n#[tokio::main]\nasync fn main() {\n    let s = stream! {\n        for i in 0..5 {\n            yield i;\n        }\n    };\n    pin_mut!(s);\n\n    while let Some(v) = s.next().await {\n        println!(\""{}\"", v);\n    }\n}"", ""code_context"": null}","{""code_after"": ""use async_stream::stream;\nuse futures_util::pin_mut;\nuse futures_util::stream::StreamExt;\n\n#[tokio::main]\nasync fn main() {\n    let s = stream! {\n        for i in 0..5 {\n            yield i;\n        }\n    };\n    pin_mut!(s);\n\n    for await v in s {\n        println!(\""{}\"", v);\n    }\n}"", ""review_comment"": ""Using `for await` eliminates the explicit `while let Some` loop and the call to `.next().await`, resulting in cleaner and more concise code while preserving the same functionality.""}",code_review
ansi_term,"{""title"": ""Generate a colored progress bar"", ""description"": ""A developer wants a progress bar that shows the current completion percentage and changes its colour based on how much work is done. The function should return an ANSIString that can be printed directly."", ""code_context"": ""use ansi_term::{Style, Colour};""}","{""code"": ""pub fn generate_progress_bar(percent: f32) -> ansi_term::ANSIString<'static> {\n    let bar_len = 20;\n    let filled = (percent * bar_len as f32).round() as usize;\n    let empty = bar_len - filled;\n    let mut bar = String::new();\n    for _ in 0..filled {\n        bar.push('#');\n    }\n    for _ in 0..empty {\n        bar.push('-');\n    }\n    let colour = if percent >= 0.8 {\n        ansi_term::Colour::Green\n    } else if percent >= 0.5 {\n        ansi_term::Colour::Yellow\n    } else {\n        ansi_term::Colour::Red\n    };\n    let style = ansi_term::Style::default().fg(colour);\n    style.paint(format!(\""[{}] {:.0}%\"", bar, percent * 100.0))\n}""}",code_generation
ansi_term,"{""title"": ""Format log entries with level‑specific colours"", ""description"": ""A logging system needs each entry to show the severity level and a timestamp in a colour that matches the level (green for INFO, yellow for WARN, red for ERROR). The helper should return an ANSIString ready for printing."", ""code_context"": ""use ansi_term::{Style, Colour};""}","{""code"": ""pub fn format_log_entry(level: &str, message: &str) -> ansi_term::ANSIString<'static> {\n    let level_style = match level {\n        \""INFO\"" => ansi_term::Style::default().fg(ansi_term::Colour::Green),\n        \""WARN\"" => ansi_term::Style::default().fg(ansi_term::Colour::Yellow),\n        \""ERROR\"" => ansi_term::Style::default().fg(ansi_term::Colour::Red),\n        _ => ansi_term::Style::default(),\n    };\n    let timestamp = \""[2023-01-01 12:00:00]\"";\n    let formatted = format!(\""{} {} {}\"", level_style.paint(level), level_style.paint(timestamp), message);\n    ansi_term::Style::default().paint(formatted)\n}""}",code_generation
ansi_term,"{""title"": ""Highlight query matches inside a line"", ""description"": ""When displaying search results, the matching words should be highlighted in yellow while the rest of the line stays unstyled. The function returns a vector of ANSIString pieces that can be concatenated or printed sequentially."", ""code_context"": ""use ansi_term::{Style, Colour};""}","{""code"": ""pub fn highlight_matches(line: &str, query: &str) -> Vec<ansi_term::ANSIString<'static>> {\n    let mut result = Vec::new();\n    let mut start = 0;\n    for word in query.split_whitespace() {\n        if let Some(pos) = line[start..].find(word) {\n            let absolute = start + pos;\n            if absolute > start {\n                result.push(ansi_term::Style::default().paint(&line[start..absolute]));\n            }\n            result.push(ansi_term::Style::default().fg(ansi_term::Colour::Yellow).paint(word));\n            start = absolute + word.len();\n        }\n    }\n    if start < line.len() {\n        result.push(ansi_term::Style::default().paint(&line[start..]));\n    }\n    result\n}""}",code_generation
ansi_term,"{""title"": ""Create a rainbow gradient for a string"", ""description"": ""A developer wants to display a piece of text where each character has a different hue, forming a rainbow effect. The helper returns a vector of ANSIString values, one per character, using the RGB colour variant."", ""code_context"": ""use ansi_term::{Colour};""}","{""code"": ""pub fn rainbow_gradient(text: &str) -> Vec<ansi_term::ANSIString<'static>> {\n    fn hue_to_rgb(hue: f32) -> (u8, u8, u8) {\n        let h = hue % 360.0;\n        let c = 1.0;\n        let x = c * (1.0 - ((h / 60.0) % 2.0 - 1.0).abs());\n        let (r1, g1, b1) = if h < 60.0 {\n            (c, x, 0.0)\n        } else if h < 120.0 {\n            (x, c, 0.0)\n        } else if h < 180.0 {\n            (0.0, c, x)\n        } else if h < 240.0 {\n            (0.0, x, c)\n        } else if h < 300.0 {\n            (x, 0.0, c)\n        } else {\n            (c, 0.0, x)\n        };\n        ((r1 * 255.0) as u8, (g1 * 255.0) as u8, (b1 * 255.0) as u8)\n    }\n\n    let mut result = Vec::new();\n    let step = 360.0 / text.chars().count() as f32;\n    for (i, ch) in text.chars().enumerate() {\n        let hue = i as f32 * step;\n        let (r, g, b) = hue_to_rgb(hue);\n        let colour = ansi_term::Colour::RGB(r, g, b);\n        result.push(colour.paint(ch.to_string()));\n    }\n    result\n}""}",code_generation
async-stream,"{""code"": ""pin_mut!(s);"", ""code_context"": ""use async_stream::stream;\nuse futures_util::pin_mut;\nuse futures_util::stream::StreamExt;\n\n#[tokio::main]\nasync fn main() {\n    let s = stream! {\n        for i in 0..3 {\n            yield i;\n        }\n    };\n    // pin_mut! is used here (the line above is the target snippet)\n    while let Some(v) = s.next().await {\n        println!(\""{}\"", v);\n    }\n}""}","{""commented_code"": ""pin_mut!(s); // needed for iteration""}",comment_generation
async-stream,"{""code"": ""yield socket;"", ""code_context"": ""use async_stream::stream;\nuse futures_util::pin_mut;\nuse futures_util::stream::StreamExt;\nuse tokio::net::TcpListener;\n\n#[tokio::main]\nasync fn main() {\n    let listener = TcpListener::bind(\""127.0.0.1:0\"").await.unwrap();\n    let incoming = stream! {\n        loop {\n            let (socket, _) = listener.accept().await.unwrap();\n            // yield socket; // the target snippet appears here\n        }\n    };\n    pin_mut!(incoming);\n    while let Some(v) = incoming.next().await {\n        println!(\""handle = {:?}\"", v);\n    }\n}""}","{""commented_code"": ""yield socket; // Yield the accepted socket for processing""}",comment_generation
async-stream,"{""code"": ""let mut dst = None;"", ""code_context"": ""use crate::yielder::Receiver;\nuse futures_core::{FusedStream, Stream};\nuse pin_project_lite::pin_project;\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\n\npin_project! {\n    #[derive(Debug)]\n    pub struct AsyncStream<T, U> {\n        rx: Receiver<T>,\n        done: bool,\n        #[pin]\n        generator: U,\n    }\n}\n\nimpl<T, U> AsyncStream<T, U> {\n    pub fn new(rx: Receiver<T>, generator: U) -> AsyncStream<T, U> {\n        AsyncStream { rx, done: false, generator }\n    }\n}\n\nimpl<T, U> Stream for AsyncStream<T, U>\nwhere\n    U: Future<Output = ()>,\n{\n    type Item = T;\n\n    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {\n        let me = self.project();\n        if *me.done {\n            return Poll::Ready(None);\n        }\n        // let mut dst = None; // the target snippet appears here\n        let res = {\n            let _enter = me.rx.enter(&mut dst);\n            me.generator.poll(cx)\n        };\n        *me.done = res.is_ready();\n        if dst.is_some() {\n            return Poll::Ready(dst.take());\n        }\n        if *me.done { Poll::Ready(None) } else { Poll::Pending }\n    }\n}\n""}","{""commented_code"": ""let mut dst = None; // Destination for the yielded value""}",comment_generation
async-stream,"{""code"": ""let _enter = me.rx.enter(&mut dst);"", ""code_context"": ""use crate::yielder::Receiver;\nuse futures_core::{FusedStream, Stream};\nuse pin_project_lite::pin_project;\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\n\npin_project! {\n    #[derive(Debug)]\n    pub struct AsyncStream<T, U> {\n        rx: Receiver<T>,\n        done: bool,\n        #[pin]\n        generator: U,\n    }\n}\n\nimpl<T, U> Stream for AsyncStream<T, U>\nwhere\n    U: Future<Output = ()>,\n{\n    type Item = T;\n    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {\n        let me = self.project();\n        if *me.done {\n            return Poll::Ready(None);\n        }\n        let mut dst = None;\n        // let _enter = me.rx.enter(&mut dst); // the target snippet appears here\n        let res = {\n            let _enter = me.rx.enter(&mut dst);\n            me.generator.poll(cx)\n        };\n        *me.done = res.is_ready();\n        if dst.is_some() { Poll::Ready(dst.take()) } else if *me.done { Poll::Ready(None) } else { Poll::Pending }\n    }\n}\n""}","{""commented_code"": ""let _enter = me.rx.enter(&mut dst); // Enter the receiver to capture the yielded value""}",comment_generation
aws-smithy-xml,"{""code_context"": ""use std::borrow::Cow;\nuse std::error::Error;\nuse std::fmt::{Display, Formatter};\n\nuse xmlparser::{Token, Tokenizer};\n\npub type Depth = usize;\n\n#[derive(Debug)]\npub struct XmlToken<'inp>(Token<'inp>);\n\n#[derive(Debug)]\npub struct XmlDecodeError {\n    kind: XmlDecodeErrorKind,\n}\n\n#[derive(Debug)]\nenum XmlDecodeErrorKind {\n    InvalidXml(xmlparser::Error),\n    InvalidEscape { esc: String },\n    Custom(Cow<'static, str>),\n    Unhandled(Box<dyn Error + Send + Sync + 'static>),\n}\n\nimpl XmlDecodeError {\n    pub fn custom(msg: impl Into<Cow<'static, str>>) -> Self {\n        Self {\n            kind: XmlDecodeErrorKind::Custom(msg.into()),\n        }\n    }\n}\n\npub(crate) fn unescape(s: &str) -> Result<Cow<'_, str>, XmlDecodeError> {\n    // placeholder implementation for context\n    unimplemented!();\n}"", ""code_to_test"": ""pub fn try_data<'a, 'inp>(\n    tokens: &mut impl Iterator<Item = Result<(XmlToken<'inp>, Depth)>>,\n) -> Result<Cow<'inp, str>, XmlDecodeError> {\n    loop {\n        match tokens.next().map(|opt| opt.map(|opt| opt.0)) {\n            None => return Ok(Cow::Borrowed(\""\"")),\n            Some(Ok(XmlToken(Token::Text { text }))) => return unescape(text.as_str()),\n            Some(Ok(e @ XmlToken(Token::ElementStart { .. }))) => {\n                return Err(XmlDecodeError::custom(format!(\n                    \""looking for a data element, found: {:?}\"",\n                    e\n                )))\n            }\n            Some(Err(e)) => return Err(e),\n            _ => {}\n        }\n    }\n}"", ""test_context"": null}","{""test_cases"": [""#[test]\nfn read_data_invalid() {\n    let xml = r#\""<Response><A></A></Response>\""#;\n    let mut doc = Document::new(xml);\n    let mut resp = doc.root_element().unwrap();\n    try_data(&mut resp).expect_err(\""no data\"");\n}"", ""#[test]\nfn read_data() {\n    let xml = r#\""<Response>hello</Response>\""#;\n    let mut doc = Document::new(xml);\n    let mut scoped = doc.root_element().unwrap();\n    assert_eq!(try_data(&mut scoped).unwrap(), \""hello\"");\n}"", ""#[test]\nfn read_data_whitespace() {\n    let xml = r#\""<Response> hello </Response>\""#;\n    let mut doc = Document::new(xml);\n    let mut scoped = doc.root_element().unwrap();\n    assert_eq!(try_data(&mut scoped).unwrap(), \"" hello \"");\n}""]}",test_generation
aws-smithy-xml,"{""code_context"": ""const ESCAPES: &[char] = &[\n    '&', '\\'', '\""', '<', '>', '\\u{00D}', '\\u{00A}', '\\u{0085}', '\\u{2028}',\n];"", ""code_to_test"": ""pub(crate) fn escape(s: &str) -> Cow<'_, str> {\n    let mut remaining = s;\n    if !s.contains(ESCAPES) {\n        return Cow::Borrowed(s);\n    }\n    let mut out = String::new();\n    while let Some(idx) = remaining.find(ESCAPES) {\n        out.push_str(&remaining[..idx]);\n        remaining = &remaining[idx..];\n        let mut idxs = remaining.char_indices();\n        let (_, chr) = idxs.next().expect(\""must not be none\"");\n        match chr {\n            '>' => out.push_str(\""&gt;\""),\n            '<' => out.push_str(\""&lt;\""),\n            '\\'' => out.push_str(\""&apos;\""),\n            '\""' => out.push_str(\""&quot;\""),\n            '&' => out.push_str(\""&amp;\""),\n            other => {\n                write!(&mut out, \""&#x{:X};\"", other as u32).expect(\""write to string cannot fail\"")\n            }\n        };\n        match idxs.next() {\n            None => remaining = \""\"",\n            Some((idx, _)) => remaining = &remaining[idx..],\n        }\n    }\n    out.push_str(remaining);\n    Cow::Owned(out)\n}"", ""test_context"": ""use crate::escape::escape;\nuse base64;\nuse proptest::prelude::*;\n""}","{""test_cases"": [""#[test]\nfn escape_basic() {\n    let inp = \""<helo>&\\\""'\"";\n    assert_eq!(escape(inp), \""&lt;helo&gt;&amp;&quot;&apos;\"");\n}"", ""#[test]\nfn escape_eol_encoding_sep() {\n    let test_cases = vec![\n        (\""CiAK\"", \""&#xA; &#xA;\""),\n        (\""YQ0KIGIKIGMN\"", \""a&#xD;&#xA; b&#xA; c&#xD;\""),\n        (\""YQ3ChSBiwoU\"", \""a&#xD;&#x85; b&#x85;\""),\n        (\""YQ3igKggYsKFIGPigKg=\"", \""a&#xD;&#x2028; b&#x85; c&#x2028;\""),\n    ];\n    for (base64_encoded, expected_xml_output) in test_cases {\n        let bytes = base64::decode(base64_encoded).expect(\""valid base64\"");\n        let input = String::from_utf8(bytes).expect(\""valid utf-8\"");\n        assert_eq!(escape(&input), expected_xml_output);\n    }\n}""]}",test_generation
aws-smithy-xml,"{""code_context"": ""use std::borrow::Cow;\nuse std::error::Error;\nuse std::fmt::{Display, Formatter};\n\n#[derive(Debug)]\npub struct XmlDecodeError {\n    kind: XmlDecodeErrorKind,\n}\n\n#[derive(Debug)]\nenum XmlDecodeErrorKind {\n    InvalidXml(xmlparser::Error),\n    InvalidEscape { esc: String },\n    Custom(Cow<'static, str>),\n    Unhandled(Box<dyn Error + Send + Sync + 'static>),\n}\n\nimpl XmlDecodeError {\n    pub fn invalid_escape(esc: impl Into<String>) -> Self {\n        Self {\n            kind: XmlDecodeErrorKind::InvalidEscape { esc: esc.into() },\n        }\n    }\n}"", ""code_to_test"": ""pub(crate) fn unescape(s: &str) -> Result<Cow<'_, str>, XmlDecodeError> {\n    if !s.contains('&') {\n        return Ok(Cow::Borrowed(s));\n    }\n    let mut res = String::with_capacity(s.len());\n    let mut sections = s.split('&');\n    if let Some(prefix) = sections.next() {\n        res.push_str(prefix);\n    }\n    for section in sections {\n        match section.find(';') {\n            Some(idx) => {\n                let entity = &section[..idx];\n                match entity {\n                    \""lt\"" => res.push('<'),\n                    \""gt\"" => res.push('>'),\n                    \""amp\"" => res.push('&'),\n                    \""quot\"" => res.push('\""'),\n                    \""apos\"" => res.push('\\''),\n                    entity => {\n                        let (entity, radix) = if let Some(entity) = entity.strip_prefix(\""#x\"") {\n                            (entity, 16)\n                        } else if let Some(entity) = entity.strip_prefix('#') {\n                            (entity, 10)\n                        } else {\n                            return Err(XmlDecodeError::invalid_escape(entity));\n                        };\n                        let char_code = u32::from_str_radix(entity, radix).map_err(|_| {\n                            XmlDecodeError::invalid_escape(format!(\n                                \""expected numeric escape in base {}; got: {}\"",\n                                radix, &entity\n                            ))\n                        })?;\n                        let chr = std::char::from_u32(char_code).ok_or_else(|| {\n                            XmlDecodeError::invalid_escape(format!(\n                                \""invalid char code: {}\"",\n                                char_code\n                            ))\n                        })?;\n                        res.push(chr);\n                    }\n                }\n                res.push_str(&section[idx + 1..]);\n            }\n            None => return Err(XmlDecodeError::invalid_escape(\""unterminated pattern\"")),\n        }\n    }\n    Ok(Cow::Owned(res))\n}"", ""test_context"": ""use crate::unescape::unescape;\nuse std::borrow::Cow;\nuse proptest::prelude::*;\n""}","{""test_cases"": [""#[test]\nfn basic_unescape() {\n    assert_eq!(\n        unescape(\""&lt; &gt; &apos; &quot; &amp;\"").unwrap(),\n        \""< > ' \\\"" &\""\n    );\n    assert_eq!(\n        unescape(\""Since a &gt; b, b is less than a\"").unwrap(),\n        \""Since a > b, b is less than a\""\n    );\n}"", ""#[test]\nfn no_need_to_escape() {\n    assert_eq!(unescape(\""hello 🍕!\"").unwrap(), Cow::Borrowed(\""hello 🍕!\""));\n}"", ""#[test]\nfn complex_unescape() {\n    assert_eq!(\n        unescape(\""a&lt;b&gt;c\\\""d&apos;e&amp;f;;\"").unwrap(),\n        \""a<b>c\\\""d'e&f;;\""\n    );\n    assert_eq!(unescape(\""&amp;lt;\"").unwrap(), \""&lt;\"");\n}"", ""#[test]\nfn newline_encoding() {\n    assert_eq!(unescape(\""&#10;\"").unwrap(), \""\\n\"");\n    assert_eq!(unescape(\""&#xD;\"").unwrap(), \""\\r\"");\n}"", ""#[test]\nfn xml_eol_encoding() {\n    assert_eq!(unescape(\""&#xA; &#xA;\"").unwrap(), \""\\n \\n\"");\n    assert_eq!(\n        unescape(\""a&#xD;&#xA; b&#xA; c&#xD;\"").unwrap(),\n        \""a\\r\\n b\\n c\\r\""\n    );\n    assert_eq!(\n        unescape(\""a&#xD;&#x85; b&#x85;\"").unwrap(),\n        \""a\\r\\u{0085} b\\u{0085}\""\n    );\n    assert_eq!(\n        unescape(\""a&#xD;&#x2028; b&#x85; c&#x2028;\"").unwrap(),\n        \""a\\r\\u{2028} b\\u{0085} c\\u{2028}\""\n    );\n}"", ""#[test]\nfn invalid_escapes() {\n    unescape(\""&lte;\"").expect_err(\""lte does not make a ≤\"");\n    unescape(\""&lt\"").expect_err(\""unterminated escape sequence\"");\n    unescape(\""&#Q1234;\"").expect_err(\""Q does not began a numeric sequence\"");\n    unescape(\""&#3.14;\"").expect_err(\""decimal escape\"");\n    unescape(\""&#xZZ\"").expect_err(\""Z is not hex\"");\n    unescape(\""here is a & but without an escape sequence...\"").expect_err(\""naked &\"");\n}"", ""#[test]\nfn no_panics() {\n    proptest::prop_assert!(matches!(unescape(\""test\""), Ok(_)));\n}""]}",test_generation
jsonrpsee-client-transport,"{""code_before"": ""let headers: Vec<_> = match &target.basic_auth {\n    Some(basic_auth) if !self.headers.contains_key(http::header::AUTHORIZATION) => {\n        let it1 = self.headers.iter().map(|(key, value)| Header { name: key.as_str(), value: value.as_bytes() });\n        let it2 = std::iter::once(Header { name: http::header::AUTHORIZATION.as_str(), value: basic_auth.as_bytes() });\n        it1.chain(it2).collect()\n    }\n    _ => {\n        self.headers.iter().map(|(key, value)| Header { name: key.as_str(), value: value.as_bytes() }).collect()\n    }\n};"", ""code_context"": ""use http::header::HeaderValue;\nuse soketto::handshake::client::Header;\n\npub struct Target {\n    pub basic_auth: Option<HeaderValue>,\n}\n\npub struct Builder {\n    pub headers: http::HeaderMap,\n}\n\nimpl Builder {\n    pub fn build_headers(&self, target: &Target) -> Vec<Header> {\n        // placeholder for the refactored code\n        vec![]\n    }\n}""}","{""rationale"": ""Collects the base headers once and then conditionally appends the Authorization header, avoiding the creation of two separate iterator chains and improving readability."", ""code_after"": ""let mut headers: Vec<Header> = self.headers.iter()\n    .map(|(key, value)| Header { name: key.as_str(), value: value.as_bytes() })\n    .collect();\nif let Some(basic_auth) = &target.basic_auth {\n    if !self.headers.contains_key(http::header::AUTHORIZATION) {\n        headers.push(Header { name: http::header::AUTHORIZATION.as_str(), value: basic_auth.as_bytes() });\n    }\n}""}",code_refactoring
jsonrpsee-client-transport,"{""code_before"": ""match client.handshake().await {\n    Ok(ServerResponse::Accepted { .. }) => {\n        tracing::debug!(target: LOG_TARGET, \""Connection established to target: {:?}\"", target);\n        let mut builder = client.into_builder();\n        builder.set_max_message_size(self.max_response_size as usize);\n        if let Some(max_frame_size) = self.max_frame_size {\n            builder.set_max_frame_size(max_frame_size as usize);\n        }\n        let (sender, receiver) = builder.finish();\n        Ok((Sender { inner: sender, max_request_size: self.max_request_size }, Receiver { inner: receiver }))\n    }\n    Ok(ServerResponse::Rejected { status_code }) => {\n        tracing::debug!(target: LOG_TARGET, \""Connection rejected: {:?}\"", status_code);\n        Err(WsHandshakeError::Rejected { status_code })\n    }\n    Ok(ServerResponse::Redirect { status_code, location }) => {\n        tracing::debug!(target: LOG_TARGET, \""Redirection: status_code: {}, location: {}\"", status_code, location);\n        Err(WsHandshakeError::Redirected { status_code, location })\n    }\n    Err(e) => Err(e.into()),\n}\n"", ""code_context"": ""use std::time::Duration;\nuse http::HeaderMap;\nuse soketto::handshake::client::{Client as WsHandshakeClient, ServerResponse};\nuse sokettle::handshake::client::Header;\nuse url::Url;\n\npub struct WsTransportClientBuilder {\n    pub max_response_size: u32,\n    pub max_frame_size: Option<u32>,\n    pub max_request_size: u32,\n    pub connection_timeout: Duration,\n    pub headers: HeaderMap,\n    // other fields omitted\n}\n\npub struct Target {\n    // fields omitted\n}\n\npub struct Sender<T> { pub inner: T, pub max_request_size: u32 }\npub struct Receiver<T> { pub inner: T }\n\npub enum WsHandshakeError {\n    Rejected { status_code: u16 },\n    Redirected { status_code: u16, location: String },\n    // other variants omitted\n}\n""}","{""rationale"": ""Extracts the redirection handling into a dedicated async helper, reducing the size of the match arm and making the main handshake flow easier to read and maintain."", ""code_after"": ""match client.handshake().await {\n    Ok(ServerResponse::Accepted { .. }) => {\n        tracing::debug!(target: LOG_TARGET, \""Connection established to target: {:?}\"", target);\n        let mut builder = client.into_builder();\n        builder.set_max_message_size(self.max_response_size as usize);\n        if let Some(max_frame_size) = self.max_frame_size {\n            builder.set_max_frame_size(max_frame_size as usize);\n        }\n        let (sender, receiver) = builder.finish();\n        Ok((Sender { inner: sender, max_request_size: self.max_request_size }, Receiver { inner: receiver }))\n    }\n    Ok(ServerResponse::Rejected { status_code }) => {\n        tracing::debug!(target: LOG_TARGET, \""Connection rejected: {:?}\"", status_code);\n        Err(WsHandshakeError::Rejected { status_code })\n    }\n    Ok(ServerResponse::Redirect { status_code, location }) => {\n        handle_redirection(self, target, status_code, location).await\n    }\n    Err(e) => Err(e.into()),\n}\n\nasync fn handle_redirection<T>(builder: &WsTransportClientBuilder, target: &mut Target, status_code: u16, location: String) -> Result<(Sender<T>, Receiver<T>), WsHandshakeError>\nwhere\n    T: futures_util::AsyncRead + futures_util::AsyncWrite + Unpin,\n{\n    tracing::debug!(target: LOG_TARGET, \""Redirection: status_code: {}, location: {}\"", status_code, location);\n    // Existing redirection handling logic would be moved here.\n    Err(WsHandshakeError::Redirected { status_code, location })\n}""}",code_refactoring
jsonrpsee-client-transport,"{""code_before"": ""fn send_ping(&mut self) -> impl Future<Output = Result<(), Self::Error>> + Send {\n    async {\n        tracing::debug!(target: LOG_TARGET, \""Send ping\"");\n        // Submit empty slice as \""optional\"" parameter.\n        let slice: &[u8] = &[];\n        // Byte slice fails if the provided slice is larger than 125 bytes.\n        let byte_slice = ByteSlice125::try_from(slice).expect(\""Empty slice should fit into ByteSlice125\"");\n\n        self.inner.send_ping(byte_slice).await?;\n        self.inner.flush().await?;\n        Ok(())\n    }\n}\n"", ""code_context"": ""use soketto::handshake::client::ByteSlice125;\n\npub struct Sender<T> {\n    pub inner: T,\n}\n\nimpl<T> Sender<T>\nwhere\n    T: futures_util::io::AsyncWrite + Unpin,\n{\n    pub type Error = std::io::Error; // placeholder\n    pub fn send_ping(&mut self) -> impl std::future::Future<Output = Result<(), Self::Error>> {\n        // placeholder implementation\n        async { Ok(()) }\n    }\n    pub fn flush(&mut self) -> impl std::future::Future<Output = Result<(), Self::Error>> {\n        async { Ok(()) }\n    }\n}\n""}","{""rationale"": ""Eliminates the unnecessary intermediate variable `slice` by constructing the empty byte slice inline, making the code more concise without changing behavior."", ""code_after"": ""fn send_ping(&mut self) -> impl Future<Output = Result<(), Self::Error>> + Send {\n    async {\n        tracing::debug!(target: LOG_TARGET, \""Send ping\"");\n        // Empty slice fits into ByteSlice125, so we can construct it directly.\n        let byte_slice = ByteSlice125::try_from(&[] as &[u8]).expect(\""Empty slice should fit into ByteSlice125\"");\n        self.inner.send_ping(byte_slice).await?;\n        self.inner.flush().await?;\n        Ok(())\n    }\n}\n""}",code_refactoring
jsonrpsee-ws-client,"{""query"": ""How do I create a JSON-RPC WebSocket client with custom headers and a request timeout of 30 seconds using jsonrpsee-ws-client?"", ""code_context"": null}","{""code_snippet"": ""use jsonrpsee_ws_client::{WsClientBuilder};\nuse std::time::Duration;\nuse http::{HeaderMap, HeaderValue};\n\n#[tokio::main]\nasync fn main() {\n    let mut headers = HeaderMap::new();\n    headers.insert(\""Authorization\"", HeaderValue::from_static(\""Bearer my_token\""));\n    let client = WsClientBuilder::default()\n        .set_headers(headers)\n        .request_timeout(Duration::from_secs(30))\n        .build(\""wss://api.example.com/socket\"")\n        .await\n        .unwrap();\n    // use client...\n}""}",code_search
jsonrpsee-ws-client,"{""query"": ""How can I configure the maximum request size for the JSON-RPC WebSocket client?"", ""code_context"": null}","{""code_snippet"": ""use jsonrpsee_ws_client::WsClientBuilder;\n\n#[tokio::main]\nasync fn main() {\n    let client = WsClientBuilder::default()\n        .max_request_size(2 * 1024 * 1024) // 2 MB\n        .build(\""wss://example.com\"")\n        .await\n        .unwrap();\n    // use client...\n}""}",code_search
jsonrpsee-ws-client,"{""query"": ""How do I subscribe to a JSON-RPC method and handle incoming messages with jsonrpsee-ws-client?"", ""code_context"": null}","{""code_snippet"": ""use jsonrpsee_ws_client::{WsClientBuilder, Subscription};\nuse jsonrpsee_core::rpc_params;\nuse futures::StreamExt;\n\n#[tokio::main]\nasync fn main() {\n    let client = WsClientBuilder::default()\n        .build(\""ws://example.com\"")\n        .await\n        .unwrap();\n\n    let mut sub: Subscription<String> = client\n        .subscribe(\""new_message\"", rpc_params![], \""unsubscribe_message\"")\n        .await\n        .unwrap()\n        .unwrap();\n\n    while let Some(msg) = sub.next().await {\n        match msg {\n            Ok(text) => println!(\""Received: {}\"", text),\n            Err(e) => eprintln!(\""Subscription error: {:?}\"", e),\n        }\n    }\n}""}",code_search
jsonrpsee-ws-client,"{""query"": ""How can I set a custom TLS certificate store for a JSON-RPC WebSocket client using jsonrpsee-ws-client?"", ""code_context"": null}","{""code_snippet"": ""use jsonrpsee_ws_client::{WsClientBuilder, CustomCertStore};\nuse std::sync::Arc;\nuse rustls::client::danger::ServerCertVerifier;\nuse rustls::{Certificate, ServerName, Error};\n\nstruct NoCertVerification;\n\nimpl ServerCertVerifier for NoCertVerification {\n    fn verify_server_cert(\n        &self,\n        _cert: &Certificate,\n        _chain: &[Certificate],\n        _servername: &ServerName,\n        _ocsp: &[u8],\n        _now: std::time::SystemTime,\n    ) -> Result<rustls::client::danger::ServerCertVerified, Error> {\n        Ok(rustls::client::danger::ServerCertVerified::assertion())\n    }\n\n    fn supported_verify_schemes(&self) -> Vec<rustls::SignatureScheme> {\n        vec![rustls::SignatureScheme::ECDSA_NISTP256_SHA256]\n    }\n}\n\n#[tokio::main]\nasync fn main() {\n    let cert_store = CustomCertStore::builder()\n        .dangerous()\n        .with_custom_certificate_verifier(Arc::new(NoCertVerification))\n        .with_no_client_auth()\n        .build();\n\n    let client = WsClientBuilder::default()\n        .with_custom_cert_store(cert_store)\n        .build(\""wss://secure.example.com\"")\n        .await\n        .unwrap();\n\n    // use client...\n}""}",code_search
jsonrpsee-ws-client,"{""query"": ""How do I send a JSON-RPC notification without expecting a response using jsonrpsee-ws-client?"", ""code_context"": null}","{""code_snippet"": ""use jsonrpsee_ws_client::WsClientBuilder;\nuse jsonrpsee_core::rpc_params;\n\n#[tokio::main]\nasync fn main() {\n    let client = WsClientBuilder::default()\n        .build(\""wss://example.com\"")\n        .await\n        .unwrap();\n\n    client.notification(\""new_event\"", rpc_params![]).await.unwrap();\n    // No response expected\n}""}",code_search